{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CDA_env_RLlib_tune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAqVG2cqjLXM",
        "colab_type": "code",
        "outputId": "8e4654b4-6dd9-42c9-8c7a-6f9653c6b063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Needed to switch directory in Google drive so as to import MARL env.\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "%cd \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/\"\n",
        "!pwd\n",
        "!pip install -r requirements.txt\n",
        "!pip show tensorflow\n",
        "!pip show ray"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction\n",
            "/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction\n",
            "Requirement already satisfied: absl-py==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.9.0)\n",
            "Collecting aiohttp==3.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/39/7eb5f98d24904e0f6d3edb505d4aa60e3ef83c0a58d6fe18244a51757247/aiohttp-3.6.2-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.8.1)\n",
            "Collecting async-timeout==3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: atari-py==0.2.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.2.6)\n",
            "Requirement already satisfied: attrs==19.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (19.3.0)\n",
            "Collecting beautifulsoup4==4.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/a1/c698cf319e9cfed6b17376281bd0efc6bfc8465698f54170ef60a485ab5d/beautifulsoup4-4.8.2-py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 59.2MB/s \n",
            "\u001b[?25hCollecting cachetools==4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: certifi==2019.11.28 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (2019.11.28)\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (3.0.4)\n",
            "Collecting Click==7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle==1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (1.3.0)\n",
            "Collecting colorama==0.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (3.0.12)\n",
            "Collecting funcsigs==1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Collecting future==0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (0.2.2)\n",
            "Requirement already satisfied: google==2.0.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (2.0.3)\n",
            "Collecting google-auth==1.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib==0.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (0.4.1)\n",
            "Requirement already satisfied: google-pasta==0.1.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 21)) (0.1.8)\n",
            "Collecting grpcio==1.27.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/df/1f8a284a5e5819ae07d50bd76996d6f7208afef7533e4896fa1c6445574f/grpcio-1.27.2-cp36-cp36m-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 37.0MB/s \n",
            "\u001b[?25hCollecting gym==0.17.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/81/2924b60e2befc192c7e43279ff388c68104515228b865506f13b4f18c338/gym-0.17.0.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 48.2MB/s \n",
            "\u001b[?25hObtaining gym_continuousDoubleAuction from git+https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction.git@c897137cbcc93ca71cbd51c27e683c3298f6562d#egg=gym_continuousDoubleAuction (from -r requirements.txt (line 24))\n",
            "  Skipping because already up-to-date.\n",
            "Collecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 36.8MB/s \n",
            "\u001b[?25hCollecting idna==2.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 27)) (1.5.0)\n",
            "Requirement already satisfied: joblib==0.14.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 28)) (0.14.1)\n",
            "Collecting jsonschema==3.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 30)) (1.0.8)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 31)) (1.1.0)\n",
            "Collecting lz4==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/81/011fef8766fb0ef681037ad6fee96168ee03a864464986cbaa23e5357704/lz4-3.0.2-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Markdown==3.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 33)) (3.2.1)\n",
            "Requirement already satisfied: more-itertools==8.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 34)) (8.2.0)\n",
            "Collecting multidict==4.7.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/2e/3ab2f1fb72571f75013db323a3799d505d99f3bc203513604f1ffb9b7858/multidict-4.7.5-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 58.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy==1.18.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 36)) (1.18.1)\n",
            "Requirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 37)) (3.1.0)\n",
            "Collecting opencv-python==4.2.0.32\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/c5/09a1b82f940805c2cee30c3c42786651edcfd0710a0283eb09c6bc959340/opencv_python-4.2.0.32-cp36-cp36m-manylinux1_x86_64.whl (28.2MB)\n",
            "\u001b[K     |████████████████████████████████| 28.2MB 1.4MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless==4.2.0.32\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/23/5f10b30a48b218a4884bc84188c14381ac71288b210f6f8079a54f7a05e8/opencv_python_headless-4.2.0.32-cp36-cp36m-manylinux1_x86_64.whl (21.6MB)\n",
            "\u001b[K     |████████████████████████████████| 21.6MB 1.4MB/s \n",
            "\u001b[?25hCollecting opt-einsum==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
            "\u001b[?25hCollecting packaging==20.1\n",
            "  Downloading https://files.pythonhosted.org/packages/98/42/87c585dd3b113c775e65fd6b8d9d0a43abe1819c471d7af702d4e01e9b20/packaging-20.1-py2.py3-none-any.whl\n",
            "Collecting pandas==1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/ec/b5dd8cfb078380fb5ae9325771146bccd4e8cad2d3e4c72c7433010684eb/pandas-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 21.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 43)) (7.0.0)\n",
            "Collecting pluggy==0.13.1\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Collecting protobuf==3.11.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/02/5432412c162989260fab61fa65e0a490c1872739eb91a659896e4d554b26/protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: py==1.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 46)) (1.8.1)\n",
            "Collecting py-spy==0.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/a7/ab45c9ee3c4654edda3efbd6b8e2fa4962226718a7e3e3be6e3926bf3617/py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 48)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 49)) (0.2.8)\n",
            "Requirement already satisfied: pyglet==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 50)) (1.5.0)\n",
            "Requirement already satisfied: pyparsing==2.4.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 51)) (2.4.6)\n",
            "Requirement already satisfied: pyrsistent==0.15.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 52)) (0.15.7)\n",
            "Collecting pytest==5.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c0/34033b2df7718b91c667bd259d5ce632ec3720198b7068c0ba6f6104ff89/pytest-5.3.5-py3-none-any.whl (235kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 52.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 54)) (2.8.1)\n",
            "Collecting pytz==2019.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 50.0MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d9/ea9816aea31beeadccd03f1f8b625ecf8f645bd66744484d162d84803ce5/PyYAML-5.3.tar.gz (268kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 51.1MB/s \n",
            "\u001b[?25hCollecting ray==0.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/47/7bc688d2c06c1d0fbd388b4e2725028b2792e1f652a28b848462a724c972/ray-0.8.2-cp36-cp36m-manylinux1_x86_64.whl (19.1MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1MB 29.9MB/s \n",
            "\u001b[?25hCollecting redis==3.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.2MB/s \n",
            "\u001b[?25hCollecting requests==2.23.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 60)) (1.3.0)\n",
            "Requirement already satisfied: rsa==4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 61)) (4.0)\n",
            "Collecting scikit-learn==0.22.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/7f/366dcba1ba076a88a50bea732dbc033c0c5bbf7876010e6edc67948579d5/scikit_learn-0.22.2-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 59.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 63)) (1.4.1)\n",
            "Collecting six==1.14.0\n",
            "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 65)) (0.0)\n",
            "Requirement already satisfied: sortedcontainers==2.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 66)) (2.1.0)\n",
            "Collecting soupsieve==2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/05/cf/ea245e52f55823f19992447b008bcbb7f78efc5960d77f6c34b5b45b36dd/soupsieve-2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tabulate==0.8.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 68)) (0.8.6)\n",
            "Collecting tensorboard==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 50.6MB/s \n",
            "\u001b[?25hCollecting tensorboardX==2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 51.6MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 34kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 73)) (1.1.0)\n",
            "Collecting urllib3==1.25.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth==0.1.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 75)) (0.1.8)\n",
            "Requirement already satisfied: Werkzeug==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 76)) (1.0.0)\n",
            "Collecting wrapt==1.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/bc/7993faa8084b5a5dbabb07a197ae1b7590da4752dc80455d878573553e2f/wrapt-1.12.0.tar.gz\n",
            "Collecting yarl==1.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 43.9MB/s \n",
            "\u001b[?25hCollecting zipp==3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/6d/a55f6e81ac213942b9a19cbc05b560c726c3e16f8fb17555f059c17d65f2/zipp-3.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp==3.6.2->-r requirements.txt (line 2)) (3.6.6)\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth==1.11.2->-r requirements.txt (line 19)) (45.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0->-r requirements.txt (line 69)) (0.34.2)\n",
            "Building wheels for collected packages: future, gym, opt-einsum, PyYAML, wrapt, idna-ssl\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=f422317ddf2e3fe5f908bca394721890e917ae4e7b3cdd8ac1790cb42a60879b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.17.0-cp36-none-any.whl size=1648707 sha256=c31ab1ac9d9830bdef342a6b16784eab448eede97520c064a155dc94950bf4ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/9b/33/416e7f0b999c7136a464bb6e71c41d8208b43bf63fc01bee39\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp36-none-any.whl size=61682 sha256=968ee385c3241355a999bc0882e9d2b3a0f9bdf50567257a90cf01ec56838a89\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3-cp36-cp36m-linux_x86_64.whl size=44229 sha256=ee50e71ab5a2e2a48883762ebe9ee6d328a5e26f48d1a22e39caec93dcd54541\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/76/4d/a95b8dd7b452b69e8ed4f68b69e1b55e12c9c9624dd962b191\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.0-cp36-cp36m-linux_x86_64.whl size=67504 sha256=3bb20b1e9aa2da1f3c7ecd69d7fba83b77bce5e91bd8da2cc0a506383663e3ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/f9/95/099544e9f879f719b14cf567fabb5aa7984263df0f025f3eef\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3162 sha256=43438204225ed49cee2685cb2d15ee5713a1ec0616311759da9f042ce02ab584\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "Successfully built future gym opt-einsum PyYAML wrapt idna-ssl\n",
            "\u001b[31mERROR: tensorflow-model-optimization 0.2.1 requires enum34~=1.1, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement cachetools~=3.1.1, but you'll have cachetools 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement grpcio~=1.24.3, but you'll have grpcio 1.27.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.8 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.7.2, but you'll have google-auth 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.25.0; python_version >= \"3.0\", but you'll have pandas 1.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: multidict, idna, idna-ssl, async-timeout, yarl, aiohttp, soupsieve, beautifulsoup4, cachetools, Click, colorama, funcsigs, future, six, google-auth, grpcio, gym, gym-continuousDoubleAuction, h5py, jsonschema, lz4, opencv-python, opencv-python-headless, opt-einsum, packaging, pytz, pandas, pluggy, protobuf, py-spy, pytest, PyYAML, redis, ray, urllib3, requests, scikit-learn, tensorboard, tensorboardX, wrapt, tensorflow-estimator, tensorflow, zipp\n",
            "  Found existing installation: idna 2.8\n",
            "    Uninstalling idna-2.8:\n",
            "      Successfully uninstalled idna-2.8\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: cachetools 3.1.1\n",
            "    Uninstalling cachetools-3.1.1:\n",
            "      Successfully uninstalled cachetools-3.1.1\n",
            "  Found existing installation: click 7.1.1\n",
            "    Uninstalling click-7.1.1:\n",
            "      Successfully uninstalled click-7.1.1\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: google-auth 1.7.2\n",
            "    Uninstalling google-auth-1.7.2:\n",
            "      Successfully uninstalled google-auth-1.7.2\n",
            "  Found existing installation: grpcio 1.24.3\n",
            "    Uninstalling grpcio-1.24.3:\n",
            "      Successfully uninstalled grpcio-1.24.3\n",
            "  Found existing installation: gym 0.17.1\n",
            "    Uninstalling gym-0.17.1:\n",
            "      Successfully uninstalled gym-0.17.1\n",
            "  Running setup.py develop for gym-continuousDoubleAuction\n",
            "  Found existing installation: h5py 2.8.0\n",
            "    Uninstalling h5py-2.8.0:\n",
            "      Successfully uninstalled h5py-2.8.0\n",
            "  Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Found existing installation: opt-einsum 3.2.0\n",
            "    Uninstalling opt-einsum-3.2.0:\n",
            "      Successfully uninstalled opt-einsum-3.2.0\n",
            "  Found existing installation: packaging 20.3\n",
            "    Uninstalling packaging-20.3:\n",
            "      Successfully uninstalled packaging-20.3\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 0.25.3\n",
            "    Uninstalling pandas-0.25.3:\n",
            "      Successfully uninstalled pandas-0.25.3\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: protobuf 3.10.0\n",
            "    Uninstalling protobuf-3.10.0:\n",
            "      Successfully uninstalled protobuf-3.10.0\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: wrapt 1.12.1\n",
            "    Uninstalling wrapt-1.12.1:\n",
            "      Successfully uninstalled wrapt-1.12.1\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "  Found existing installation: zipp 3.1.0\n",
            "    Uninstalling zipp-3.1.0:\n",
            "      Successfully uninstalled zipp-3.1.0\n",
            "Successfully installed Click-7.0 PyYAML-5.3 aiohttp-3.6.2 async-timeout-3.0.1 beautifulsoup4-4.8.2 cachetools-4.0.0 colorama-0.4.3 funcsigs-1.0.2 future-0.18.2 google-auth-1.11.2 grpcio-1.27.2 gym-0.17.0 gym-continuousDoubleAuction h5py-2.10.0 idna-2.9 idna-ssl-1.1.0 jsonschema-3.2.0 lz4-3.0.2 multidict-4.7.5 opencv-python-4.2.0.32 opencv-python-headless-4.2.0.32 opt-einsum-3.1.0 packaging-20.1 pandas-1.0.1 pluggy-0.13.1 protobuf-3.11.3 py-spy-0.3.3 pytest-5.3.5 pytz-2019.3 ray-0.8.2 redis-3.4.1 requests-2.23.0 scikit-learn-0.22.2 six-1.14.0 soupsieve-2.0 tensorboard-2.1.1 tensorboardX-2.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 urllib3-1.25.8 wrapt-1.12.0 yarl-1.4.2 zipp-3.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cachetools",
                  "google",
                  "grpc",
                  "idna",
                  "pandas",
                  "pytz",
                  "requests",
                  "six",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.1.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: wrapt, google-pasta, grpcio, wheel, tensorflow-estimator, gast, absl-py, numpy, termcolor, protobuf, six, astor, opt-einsum, scipy, keras-preprocessing, keras-applications, tensorboard\n",
            "Required-by: tensorflow-federated, stable-baselines, magenta, fancyimpute\n",
            "Name: ray\n",
            "Version: 0.8.2\n",
            "Summary: A system for parallel and distributed Python that unifies the ML ecosystem.\n",
            "Home-page: https://github.com/ray-project/ray\n",
            "Author: Ray Team\n",
            "Author-email: ray-dev@googlegroups.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: filelock, pytest, protobuf, funcsigs, click, py-spy, packaging, pyyaml, aiohttp, grpcio, google, redis, colorama, six, cloudpickle, jsonschema, numpy\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UW3INjDipTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "os.environ['RAY_DEBUG_DISABLE_MEMORY_MONITOR'] = \"True\"\n",
        "\n",
        "import argparse\n",
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.rllib.utils import try_import_tf\n",
        "from ray.tune.registry import register_env\n",
        "from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n",
        "from ray.rllib.models.tf.fcnet_v2 import FullyConnectedNetwork\n",
        "from ray.rllib.models import Model, ModelCatalog\n",
        "from ray.rllib.policy.policy import Policy\n",
        "from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
        "from ray.rllib.agents.ppo.ppo_tf_policy import PPOTFPolicy\n",
        "\n",
        "import sys\n",
        "if \"../\" not in sys.path:\n",
        "    sys.path.append(\"../\")\n",
        "\n",
        "from gym_continuousDoubleAuction.envs.continuousDoubleAuction_env import continuousDoubleAuctionEnv\n",
        "\n",
        "tf = try_import_tf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIYT1UTxiQcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomModel_1(Model):\n",
        "    def _lstm(self, Inputs, cell_size):\n",
        "        s = tf.expand_dims(Inputs, axis=1, name='time_major')  # [time_step, feature] => [time_step, batch, feature]\n",
        "        lstm_cell = tf.nn.rnn_cell.LSTMCell(cell_size)\n",
        "        self.init_state = lstm_cell.zero_state(batch_size=1, dtype=tf.float32)\n",
        "        # time_major means [time_step, batch, feature] while batch major means [batch, time_step, feature]\n",
        "        outputs, self.final_state = tf.nn.dynamic_rnn(cell=lstm_cell, inputs=s, initial_state=self.init_state, time_major=True)\n",
        "        lstm_out = tf.reshape(outputs, [-1, cell_size], name='flatten_rnn_outputs')  # joined state representation\n",
        "        return lstm_out\n",
        "\n",
        "    def _build_layers_v2(self, input_dict, num_outputs, options):\n",
        "        hidden = 512\n",
        "        cell_size = 256\n",
        "        S = tf.layers.flatten(input_dict[\"obs\"]) # input_dict[\"obs\"] is the state\n",
        "        with tf.variable_scope(tf.VariableScope(tf.AUTO_REUSE, \"shared\"),\n",
        "                               reuse=tf.AUTO_REUSE,\n",
        "                               auxiliary_name_scope=False):\n",
        "            last_layer = tf.layers.dense(S, hidden, activation=tf.nn.relu, name=\"fc1\")\n",
        "        last_layer = tf.layers.dense(last_layer, hidden, activation=tf.nn.relu, name=\"fc2\")\n",
        "        last_layer = tf.layers.dense(last_layer, hidden, activation=tf.nn.relu, name=\"fc3\")\n",
        "\n",
        "        last_layer = self._lstm(last_layer, cell_size)\n",
        "\n",
        "        output = tf.layers.dense(last_layer, num_outputs, activation=tf.nn.softmax, name=\"mu\")\n",
        "\n",
        "        return output, last_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cijiMv-ti1SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_RandomPolicy(_seed):\n",
        "\n",
        "    class RandomPolicy(Policy):\n",
        "        \"\"\"\n",
        "        Hand-coded policy that returns random actions in the env \n",
        "        (doesn't learn).\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(self, observation_space, action_space, config):\n",
        "            self.observation_space = observation_space\n",
        "            self.action_space = action_space\n",
        "            self.action_space.seed(_seed)\n",
        "\n",
        "        def compute_actions(self,\n",
        "                            obs_batch,\n",
        "                            state_batches,\n",
        "                            prev_action_batch=None,\n",
        "                            prev_reward_batch=None,\n",
        "                            info_batch=None,\n",
        "                            episodes=None,\n",
        "                            **kwargs):\n",
        "            \"\"\"Compute actions on a batch of observations.\"\"\"\n",
        "            return [self.action_space.sample() for _ in obs_batch], [], {}\n",
        "\n",
        "        def learn_on_batch(self, samples):\n",
        "            \"\"\"No learning.\"\"\"\n",
        "            #return {}\n",
        "            pass\n",
        "\n",
        "        def get_weights(self):\n",
        "            pass\n",
        "\n",
        "        def set_weights(self, weights):\n",
        "            pass\n",
        "\n",
        "    return RandomPolicy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ASMamrPoh3",
        "colab_type": "code",
        "outputId": "c5737eb7-ba25-4d5b-ec73-3cae12bdf7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "ray.init(ignore_reinit_error=True, log_to_driver=False, webui_host='127.0.0.1', num_cpus=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-18 09:26:30,811\tWARNING services.py:586 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
            "2020-03-18 09:26:30,814\tINFO resource_spec.py:212 -- Starting Ray with 6.74 GiB memory available for workers and up to 3.38 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
            "2020-03-18 09:26:31,278\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32m127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'node_ip_address': '172.28.0.2',\n",
              " 'object_store_address': '/tmp/ray/session_2020-03-18_09-26-30_810775_124/sockets/plasma_store',\n",
              " 'raylet_socket_name': '/tmp/ray/session_2020-03-18_09-26-30_810775_124/sockets/raylet',\n",
              " 'redis_address': '172.28.0.2:29445',\n",
              " 'session_dir': '/tmp/ray/session_2020-03-18_09-26-30_810775_124',\n",
              " 'webui_url': '127.0.0.1:8265'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqzjVWUsPykm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_agents = 4\n",
        "num_policies = num_agents\n",
        "num_iters = 3\n",
        "simple = False #store_true\n",
        "num_of_traders = num_agents\n",
        "tape_display_length = 10\n",
        "tick_size = 1\n",
        "init_cash = 1000000\n",
        "max_step = 700 # per episode\n",
        "episode = 5 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To995IZanbGx",
        "colab_type": "code",
        "outputId": "b700b6ed-21aa-4bdf-d50a-e08f0debb032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "single_CDA_env = continuousDoubleAuctionEnv(num_of_traders, init_cash, tick_size, tape_display_length, max_step)\n",
        "obs_space = single_CDA_env.observation_space\n",
        "act_space = single_CDA_env.action_space\n",
        "register_env(\"continuousDoubleAuction-v0\", lambda _: continuousDoubleAuctionEnv(num_of_traders, init_cash, tick_size, tape_display_length, max_step))\n",
        "ModelCatalog.register_custom_model(\"model_disc\", CustomModel_1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN5IfMMvP4VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Each policy can have a different configuration (including custom model)\n",
        "def gen_policy(i):\n",
        "    config = {\"model\": {\"custom_model\": \"model_disc\"},\n",
        "              \"gamma\": 0.99,}\n",
        "    return (None, obs_space, act_space, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7KFjAxGP6en",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def policy_mapper(agent_id):\n",
        "    for i in range(num_agents):\n",
        "        if agent_id == i:\n",
        "            return \"policy_{}\".format(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXrTPRQDP8of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary of policies\n",
        "policies = {\"policy_{}\".format(i): gen_policy(i) for i in range(num_policies)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsbblOn-P_eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# override policy with random policy\n",
        "\n",
        "def set_RandomPolicy(policies):\n",
        "    \"\"\"\n",
        "    Set 1st policy as PPO & override all other policies as RandomPolicy with\n",
        "    different seed.\n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(num_agents):\n",
        "        if i == num_agents-1:\n",
        "            break\n",
        "        x = i + 1\n",
        "        policies[\"policy_{}\".format(num_policies-x)] = (make_RandomPolicy(num_policies-x), obs_space, act_space, {})\n",
        "\n",
        "    print('policies:', policies)\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DYOuZeb8NPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ff3e4fb6-5dfe-468f-d8b8-c477e7c47eff"
      },
      "source": [
        "set_RandomPolicy(policies)\n",
        "\n",
        "policy_ids = list(policies.keys())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "policies: {'policy_0': (None, Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), {'model': {'custom_model': 'model_disc'}, 'gamma': 0.99}), 'policy_1': (<class '__main__.make_RandomPolicy.<locals>.RandomPolicy'>, Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), {}), 'policy_2': (<class '__main__.make_RandomPolicy.<locals>.RandomPolicy'>, Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), {}), 'policy_3': (<class '__main__.make_RandomPolicy.<locals>.RandomPolicy'>, Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), {})}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qubsXzPrBsuU",
        "colab_type": "code",
        "outputId": "c34e5172-d03f-4d82-c207-b05551663546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "analysis_obj = tune.run(PPOTrainer,\n",
        "                        local_dir=\"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/\",\n",
        "                        checkpoint_freq=10, # iterations\n",
        "                        checkpoint_at_end=True,\n",
        "                        max_failures=5,\n",
        "                        resume=False,\n",
        "                        #restore='/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO/PPO_continuousDoubleAuction-v0_2d1f5a70_0_2020-03-17_16-27-21o402ocja/checkpoint_28/checkpoint-28',\n",
        "                        stop={\"timesteps_total\": max_step * episode},\n",
        "                        #stop={\"timesteps_total\": max_step * episode * 2},\n",
        "                        config={\"env\": \"continuousDoubleAuction-v0\",                     \n",
        "                        # Number of rollout worker actors to create for parallel sampling.\n",
        "                        # Setting to 0 will force rollouts to be done in the trainer actor.\n",
        "                        \"num_workers\": 1, # Colab (only 2 CPUs or 1 GPU)\n",
        "                        \"num_envs_per_worker\": 2,\n",
        "                        \"sample_batch_size\": 32, # number of environment steps sampled from each environment\n",
        "                        \"train_batch_size\": 128, # minibatch size must be >= 128, number of environment steps sampled from all available environments\n",
        "                        \"multiagent\": {\"policies_to_train\": [\"policy_0\"],\n",
        "                                       \"policies\": policies,\n",
        "                                       \"policy_mapping_fn\": policy_mapper,\n",
        "                                      },\n",
        "                              },\n",
        "                        )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 1.3/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>     </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-27-16\n",
            "  done: false\n",
            "  episode_len_mean: .nan\n",
            "  episode_reward_max: .nan\n",
            "  episode_reward_mean: .nan\n",
            "  episode_reward_min: .nan\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 0\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 18208.915\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.904226303100586\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.010916304774582386\n",
            "        policy_loss: -0.13474249839782715\n",
            "        total_loss: 43314776.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 43314776.0\n",
            "    load_time_ms: 157.809\n",
            "    num_steps_sampled: 128\n",
            "    num_steps_trained: 128\n",
            "    sample_time_ms: 3493.013\n",
            "    update_time_ms: 2360.7\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 86.63055555555555\n",
            "    ram_util_percent: 17.352777777777774\n",
            "  pid: 483\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf: {}\n",
            "  time_since_restore: 24.40639853477478\n",
            "  time_this_iter_s: 24.40639853477478\n",
            "  time_total_s: 24.40639853477478\n",
            "  timestamp: 1584523636\n",
            "  timesteps_since_restore: 128\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 128\n",
            "  training_iteration: 1\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">         24.4064</td><td style=\"text-align: right;\"> 128</td><td style=\"text-align: right;\">     1</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-27-36\n",
            "  done: false\n",
            "  episode_len_mean: .nan\n",
            "  episode_reward_max: .nan\n",
            "  episode_reward_mean: .nan\n",
            "  episode_reward_min: .nan\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 0\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 17519.119\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.927767276763916\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.01411215029656887\n",
            "        policy_loss: -0.09067018330097198\n",
            "        total_loss: 1233931.75\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 1233931.875\n",
            "    load_time_ms: 79.484\n",
            "    num_steps_sampled: 256\n",
            "    num_steps_trained: 256\n",
            "    sample_time_ms: 3493.135\n",
            "    update_time_ms: 1199.433\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.8\n",
            "    ram_util_percent: 17.441379310344825\n",
            "  pid: 483\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf: {}\n",
            "  time_since_restore: 44.772549629211426\n",
            "  time_this_iter_s: 20.366151094436646\n",
            "  time_total_s: 44.772549629211426\n",
            "  timestamp: 1584523656\n",
            "  timesteps_since_restore: 256\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 256\n",
            "  training_iteration: 2\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">         44.7725</td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">     2</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-27-57\n",
            "  done: false\n",
            "  episode_len_mean: .nan\n",
            "  episode_reward_max: .nan\n",
            "  episode_reward_mean: .nan\n",
            "  episode_reward_min: .nan\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 0\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 17311.541\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.8760457038879395\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.006851342506706715\n",
            "        policy_loss: -0.07030089199542999\n",
            "        total_loss: 96500.09375\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 96500.171875\n",
            "    load_time_ms: 53.407\n",
            "    num_steps_sampled: 384\n",
            "    num_steps_trained: 384\n",
            "    sample_time_ms: 3544.387\n",
            "    update_time_ms: 813.248\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.89666666666668\n",
            "    ram_util_percent: 17.5\n",
            "  pid: 483\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf: {}\n",
            "  time_since_restore: 65.36171698570251\n",
            "  time_this_iter_s: 20.58916735649109\n",
            "  time_total_s: 65.36171698570251\n",
            "  timestamp: 1584523677\n",
            "  timesteps_since_restore: 384\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 384\n",
            "  training_iteration: 3\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">         65.3617</td><td style=\"text-align: right;\"> 384</td><td style=\"text-align: right;\">     3</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-28-18\n",
            "  done: false\n",
            "  episode_len_mean: .nan\n",
            "  episode_reward_max: .nan\n",
            "  episode_reward_mean: .nan\n",
            "  episode_reward_min: .nan\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 0\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 17145.725\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.9506049156188965\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.016575515270233154\n",
            "        policy_loss: -0.0969429761171341\n",
            "        total_loss: 437226.84375\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 437226.9375\n",
            "    load_time_ms: 40.411\n",
            "    num_steps_sampled: 512\n",
            "    num_steps_trained: 512\n",
            "    sample_time_ms: 3609.2\n",
            "    update_time_ms: 617.907\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.23448275862069\n",
            "    ram_util_percent: 17.600000000000005\n",
            "  pid: 483\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf: {}\n",
            "  time_since_restore: 85.85150575637817\n",
            "  time_this_iter_s: 20.48978877067566\n",
            "  time_total_s: 85.85150575637817\n",
            "  timestamp: 1584523698\n",
            "  timesteps_since_restore: 512\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 512\n",
            "  training_iteration: 4\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">         85.8515</td><td style=\"text-align: right;\"> 512</td><td style=\"text-align: right;\">     4</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-28-38\n",
            "  done: false\n",
            "  episode_len_mean: .nan\n",
            "  episode_reward_max: .nan\n",
            "  episode_reward_mean: .nan\n",
            "  episode_reward_min: .nan\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 0\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 17088.527\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.893433094024658\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.011437635868787766\n",
            "        policy_loss: -0.06771819293498993\n",
            "        total_loss: 23091.75\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 23091.81640625\n",
            "    load_time_ms: 32.574\n",
            "    num_steps_sampled: 640\n",
            "    num_steps_trained: 640\n",
            "    sample_time_ms: 3641.82\n",
            "    update_time_ms: 501.297\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.29310344827587\n",
            "    ram_util_percent: 17.7\n",
            "  pid: 483\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf: {}\n",
            "  time_since_restore: 106.52320528030396\n",
            "  time_this_iter_s: 20.67169952392578\n",
            "  time_total_s: 106.52320528030396\n",
            "  timestamp: 1584523718\n",
            "  timesteps_since_restore: 640\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 640\n",
            "  training_iteration: 5\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">         106.523</td><td style=\"text-align: right;\"> 640</td><td style=\"text-align: right;\">     5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-29-00\n",
            "  done: false\n",
            "  episode_len_mean: .nan\n",
            "  episode_reward_max: .nan\n",
            "  episode_reward_mean: .nan\n",
            "  episode_reward_min: .nan\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 0\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 17115.527\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.94932746887207\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.014233730733394623\n",
            "        policy_loss: -0.10452572256326675\n",
            "        total_loss: 1175628.25\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 1175628.375\n",
            "    load_time_ms: 27.341\n",
            "    num_steps_sampled: 768\n",
            "    num_steps_trained: 768\n",
            "    sample_time_ms: 3729.046\n",
            "    update_time_ms: 423.069\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.3516129032258\n",
            "    ram_util_percent: 17.799999999999997\n",
            "  pid: 483\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf: {}\n",
            "  time_since_restore: 127.97670531272888\n",
            "  time_this_iter_s: 21.453500032424927\n",
            "  time_total_s: 127.97670531272888\n",
            "  timestamp: 1584523740\n",
            "  timesteps_since_restore: 768\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 768\n",
            "  training_iteration: 6\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">         127.977</td><td style=\"text-align: right;\"> 768</td><td style=\"text-align: right;\">     6</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-29-20\n",
            "  done: false\n",
            "  episode_len_mean: .nan\n",
            "  episode_reward_max: .nan\n",
            "  episode_reward_mean: .nan\n",
            "  episode_reward_min: .nan\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 0\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 17034.306\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.90479040145874\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.018047384917736053\n",
            "        policy_loss: -0.11793791502714157\n",
            "        total_loss: 1158135.75\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 1158135.875\n",
            "    load_time_ms: 23.677\n",
            "    num_steps_sampled: 896\n",
            "    num_steps_trained: 896\n",
            "    sample_time_ms: 3761.382\n",
            "    update_time_ms: 369.022\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.03103448275861\n",
            "    ram_util_percent: 17.9\n",
            "  pid: 483\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf: {}\n",
            "  time_since_restore: 148.52969193458557\n",
            "  time_this_iter_s: 20.55298662185669\n",
            "  time_total_s: 148.52969193458557\n",
            "  timestamp: 1584523760\n",
            "  timesteps_since_restore: 896\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 896\n",
            "  training_iteration: 7\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">          148.53</td><td style=\"text-align: right;\"> 896</td><td style=\"text-align: right;\">     7</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-29-41\n",
            "  done: false\n",
            "  episode_len_mean: .nan\n",
            "  episode_reward_max: .nan\n",
            "  episode_reward_mean: .nan\n",
            "  episode_reward_min: .nan\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 0\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16956.061\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.887696266174316\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.012592809274792671\n",
            "        policy_loss: -0.0860450491309166\n",
            "        total_loss: 2803738.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 2803738.0\n",
            "    load_time_ms: 20.881\n",
            "    num_steps_sampled: 1024\n",
            "    num_steps_trained: 1024\n",
            "    sample_time_ms: 3777.768\n",
            "    update_time_ms: 326.32\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.31333333333335\n",
            "    ram_util_percent: 17.996666666666666\n",
            "  pid: 483\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf: {}\n",
            "  time_since_restore: 168.86362767219543\n",
            "  time_this_iter_s: 20.333935737609863\n",
            "  time_total_s: 168.86362767219543\n",
            "  timestamp: 1584523781\n",
            "  timesteps_since_restore: 1024\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 1024\n",
            "  training_iteration: 8\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">         168.864</td><td style=\"text-align: right;\">1024</td><td style=\"text-align: right;\">     8</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-30-01\n",
            "  done: false\n",
            "  episode_len_mean: .nan\n",
            "  episode_reward_max: .nan\n",
            "  episode_reward_mean: .nan\n",
            "  episode_reward_min: .nan\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 0\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16917.392\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.859147071838379\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.011647248640656471\n",
            "        policy_loss: -0.09702916443347931\n",
            "        total_loss: 2077316.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 2077316.375\n",
            "    load_time_ms: 18.687\n",
            "    num_steps_sampled: 1152\n",
            "    num_steps_trained: 1152\n",
            "    sample_time_ms: 3798.587\n",
            "    update_time_ms: 293.516\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 89.49655172413793\n",
            "    ram_util_percent: 18.1\n",
            "  pid: 483\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf: {}\n",
            "  time_since_restore: 189.47360730171204\n",
            "  time_this_iter_s: 20.6099796295166\n",
            "  time_total_s: 189.47360730171204\n",
            "  timestamp: 1584523801\n",
            "  timesteps_since_restore: 1152\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 1152\n",
            "  training_iteration: 9\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">         189.474</td><td style=\"text-align: right;\">1152</td><td style=\"text-align: right;\">     9</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-30-23\n",
            "  done: false\n",
            "  episode_len_mean: .nan\n",
            "  episode_reward_max: .nan\n",
            "  episode_reward_mean: .nan\n",
            "  episode_reward_min: .nan\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 0\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16943.182\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.906188011169434\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.012287764810025692\n",
            "        policy_loss: -0.0782194435596466\n",
            "        total_loss: 4268303.5\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 4268303.5\n",
            "    load_time_ms: 16.945\n",
            "    num_steps_sampled: 1280\n",
            "    num_steps_trained: 1280\n",
            "    sample_time_ms: 3828.186\n",
            "    update_time_ms: 267.434\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 89.80999999999999\n",
            "    ram_util_percent: 18.2\n",
            "  pid: 483\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf: {}\n",
            "  time_since_restore: 210.7815465927124\n",
            "  time_this_iter_s: 21.307939291000366\n",
            "  time_total_s: 210.7815465927124\n",
            "  timestamp: 1584523823\n",
            "  timesteps_since_restore: 1280\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 1280\n",
            "  training_iteration: 10\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">         210.782</td><td style=\"text-align: right;\">1280</td><td style=\"text-align: right;\">    10</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-30-44\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 2\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16812.635\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.20000000298023224\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.912109375\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.024017099291086197\n",
            "        policy_loss: -0.07953615486621857\n",
            "        total_loss: 4344333.5\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 4344333.5\n",
            "    load_time_ms: 1.284\n",
            "    num_steps_sampled: 1408\n",
            "    num_steps_trained: 1408\n",
            "    sample_time_ms: 3875.766\n",
            "    update_time_ms: 33.301\n",
            "  iterations_since_restore: 11\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 89.82\n",
            "    ram_util_percent: 18.296666666666667\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 231.67911553382874\n",
            "  time_this_iter_s: 20.897568941116333\n",
            "  time_total_s: 231.67911553382874\n",
            "  timestamp: 1584523844\n",
            "  timesteps_since_restore: 1408\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 1408\n",
            "  training_iteration: 11\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         231.679</td><td style=\"text-align: right;\">1408</td><td style=\"text-align: right;\">    11</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-31-04\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16787.187\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.30000001192092896\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.919506072998047\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.016398677602410316\n",
            "        policy_loss: -0.14067333936691284\n",
            "        total_loss: 1318445568.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 1318445568.0\n",
            "    load_time_ms: 1.283\n",
            "    num_steps_sampled: 1536\n",
            "    num_steps_trained: 1536\n",
            "    sample_time_ms: 3853.289\n",
            "    update_time_ms: 32.551\n",
            "  iterations_since_restore: 12\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 91.09310344827587\n",
            "    ram_util_percent: 18.39655172413793\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 251.55883121490479\n",
            "  time_this_iter_s: 19.87971568107605\n",
            "  time_total_s: 251.55883121490479\n",
            "  timestamp: 1584523864\n",
            "  timesteps_since_restore: 1536\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 1536\n",
            "  training_iteration: 12\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         251.559</td><td style=\"text-align: right;\">1536</td><td style=\"text-align: right;\">    12</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-31-24\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16752.593\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.30000001192092896\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.898088455200195\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.016038579866290092\n",
            "        policy_loss: -0.07882095873355865\n",
            "        total_loss: 255653008.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 255653008.0\n",
            "    load_time_ms: 1.541\n",
            "    num_steps_sampled: 1664\n",
            "    num_steps_trained: 1664\n",
            "    sample_time_ms: 3854.244\n",
            "    update_time_ms: 31.61\n",
            "  iterations_since_restore: 13\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.30689655172412\n",
            "    ram_util_percent: 18.489655172413794\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 271.8056809902191\n",
            "  time_this_iter_s: 20.24684977531433\n",
            "  time_total_s: 271.8056809902191\n",
            "  timestamp: 1584523884\n",
            "  timesteps_since_restore: 1664\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 1664\n",
            "  training_iteration: 13\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         271.806</td><td style=\"text-align: right;\">1664</td><td style=\"text-align: right;\">    13</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-31-44\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16739.325\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.30000001192092896\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.948204040527344\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.00947587937116623\n",
            "        policy_loss: -0.07183794677257538\n",
            "        total_loss: 100156888.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 100156888.0\n",
            "    load_time_ms: 1.58\n",
            "    num_steps_sampled: 1792\n",
            "    num_steps_trained: 1792\n",
            "    sample_time_ms: 3833.924\n",
            "    update_time_ms: 31.144\n",
            "  iterations_since_restore: 14\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.84482758620689\n",
            "    ram_util_percent: 18.5\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 291.9555778503418\n",
            "  time_this_iter_s: 20.14989686012268\n",
            "  time_total_s: 291.9555778503418\n",
            "  timestamp: 1584523904\n",
            "  timesteps_since_restore: 1792\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 1792\n",
            "  training_iteration: 14\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         291.956</td><td style=\"text-align: right;\">1792</td><td style=\"text-align: right;\">    14</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-32-05\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16710.966\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.30000001192092896\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.947474479675293\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.012017954140901566\n",
            "        policy_loss: -0.06998876482248306\n",
            "        total_loss: 16531180.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 16531180.0\n",
            "    load_time_ms: 1.601\n",
            "    num_steps_sampled: 1920\n",
            "    num_steps_trained: 1920\n",
            "    sample_time_ms: 3828.917\n",
            "    update_time_ms: 30.538\n",
            "  iterations_since_restore: 15\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.47586206896553\n",
            "    ram_util_percent: 18.6\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 312.28877806663513\n",
            "  time_this_iter_s: 20.333200216293335\n",
            "  time_total_s: 312.28877806663513\n",
            "  timestamp: 1584523925\n",
            "  timesteps_since_restore: 1920\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 1920\n",
            "  training_iteration: 15\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         312.289</td><td style=\"text-align: right;\">1920</td><td style=\"text-align: right;\">    15</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-32-25\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16648.913\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.30000001192092896\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 8.04981517791748\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.027000175788998604\n",
            "        policy_loss: -0.10138528048992157\n",
            "        total_loss: 6614764.5\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 6614764.5\n",
            "    load_time_ms: 1.605\n",
            "    num_steps_sampled: 2048\n",
            "    num_steps_trained: 2048\n",
            "    sample_time_ms: 3794.095\n",
            "    update_time_ms: 30.359\n",
            "  iterations_since_restore: 16\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 89.9241379310345\n",
            "    ram_util_percent: 18.7\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 332.77252745628357\n",
            "  time_this_iter_s: 20.483749389648438\n",
            "  time_total_s: 332.77252745628357\n",
            "  timestamp: 1584523945\n",
            "  timesteps_since_restore: 2048\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 2048\n",
            "  training_iteration: 16\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         332.773</td><td style=\"text-align: right;\">2048</td><td style=\"text-align: right;\">    16</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-32-46\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16664.009\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.44999998807907104\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 8.001445770263672\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.016622409224510193\n",
            "        policy_loss: -0.09361018985509872\n",
            "        total_loss: 10067482.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 10067482.0\n",
            "    load_time_ms: 1.545\n",
            "    num_steps_sampled: 2176\n",
            "    num_steps_trained: 2176\n",
            "    sample_time_ms: 3778.008\n",
            "    update_time_ms: 27.962\n",
            "  iterations_since_restore: 17\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.3103448275862\n",
            "    ram_util_percent: 18.8\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 353.291827917099\n",
            "  time_this_iter_s: 20.51930046081543\n",
            "  time_total_s: 353.291827917099\n",
            "  timestamp: 1584523966\n",
            "  timesteps_since_restore: 2176\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 2176\n",
            "  training_iteration: 17\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         353.292</td><td style=\"text-align: right;\">2176</td><td style=\"text-align: right;\">    17</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-33-06\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16704.591\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.44999998807907104\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.992142677307129\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.014264887198805809\n",
            "        policy_loss: -0.09568486362695694\n",
            "        total_loss: 24178544.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 24178544.0\n",
            "    load_time_ms: 1.565\n",
            "    num_steps_sampled: 2304\n",
            "    num_steps_trained: 2304\n",
            "    sample_time_ms: 3767.713\n",
            "    update_time_ms: 28.196\n",
            "  iterations_since_restore: 18\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.64999999999999\n",
            "    ram_util_percent: 18.889999999999993\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 373.93210554122925\n",
            "  time_this_iter_s: 20.64027762413025\n",
            "  time_total_s: 373.93210554122925\n",
            "  timestamp: 1584523986\n",
            "  timesteps_since_restore: 2304\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 2304\n",
            "  training_iteration: 18\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         373.932</td><td style=\"text-align: right;\">2304</td><td style=\"text-align: right;\">    18</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-33-27\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16740.876\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.44999998807907104\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.943445205688477\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.013654019683599472\n",
            "        policy_loss: -0.0772119015455246\n",
            "        total_loss: 11097018.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 11097019.0\n",
            "    load_time_ms: 1.587\n",
            "    num_steps_sampled: 2432\n",
            "    num_steps_trained: 2432\n",
            "    sample_time_ms: 3762.501\n",
            "    update_time_ms: 27.879\n",
            "  iterations_since_restore: 19\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.62666666666665\n",
            "    ram_util_percent: 18.899999999999995\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 394.85028648376465\n",
            "  time_this_iter_s: 20.9181809425354\n",
            "  time_total_s: 394.85028648376465\n",
            "  timestamp: 1584524007\n",
            "  timesteps_since_restore: 2432\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 2432\n",
            "  training_iteration: 19\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          394.85</td><td style=\"text-align: right;\">2432</td><td style=\"text-align: right;\">    19</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-33-49\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16794.798\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.44999998807907104\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 8.011999130249023\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.01932268962264061\n",
            "        policy_loss: -0.09672635048627853\n",
            "        total_loss: 13826895.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 13826895.0\n",
            "    load_time_ms: 1.686\n",
            "    num_steps_sampled: 2560\n",
            "    num_steps_trained: 2560\n",
            "    sample_time_ms: 3755.816\n",
            "    update_time_ms: 27.493\n",
            "  iterations_since_restore: 20\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.23225806451613\n",
            "    ram_util_percent: 19.0\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 416.62852573394775\n",
            "  time_this_iter_s: 21.778239250183105\n",
            "  time_total_s: 416.62852573394775\n",
            "  timestamp: 1584524029\n",
            "  timesteps_since_restore: 2560\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 2560\n",
            "  training_iteration: 20\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         416.629</td><td style=\"text-align: right;\">2560</td><td style=\"text-align: right;\">    20</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-34-11\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 2\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16827.951\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.44999998807907104\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.920506477355957\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.015123406425118446\n",
            "        policy_loss: -0.07769985496997833\n",
            "        total_loss: 14394086.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 14394087.0\n",
            "    load_time_ms: 1.716\n",
            "    num_steps_sampled: 2688\n",
            "    num_steps_trained: 2688\n",
            "    sample_time_ms: 3781.389\n",
            "    update_time_ms: 27.707\n",
            "  iterations_since_restore: 21\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 89.80322580645162\n",
            "    ram_util_percent: 19.100000000000005\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 12469.0\n",
            "    policy_1: 15313.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 7369.0\n",
            "    policy_1: 6294.0\n",
            "    policy_2: -4060.5\n",
            "    policy_3: -9602.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -19325.0\n",
            "    policy_3: -10748.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.05259367760191\n",
            "    mean_inference_ms: 6.711686925685152\n",
            "    mean_processing_ms: 1.6639279981031485\n",
            "  time_since_restore: 438.1157329082489\n",
            "  time_this_iter_s: 21.487207174301147\n",
            "  time_total_s: 438.1157329082489\n",
            "  timestamp: 1584524051\n",
            "  timesteps_since_restore: 2688\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 2688\n",
            "  training_iteration: 21\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         438.116</td><td style=\"text-align: right;\">2688</td><td style=\"text-align: right;\">    21</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-34-32\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 2\n",
            "  episodes_total: 4\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16855.772\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.44999998807907104\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.931643486022949\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.019159650430083275\n",
            "        policy_loss: -0.10858838260173798\n",
            "        total_loss: 20315320.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 20315320.0\n",
            "    load_time_ms: 1.734\n",
            "    num_steps_sampled: 2816\n",
            "    num_steps_trained: 2816\n",
            "    sample_time_ms: 3842.257\n",
            "    update_time_ms: 27.829\n",
            "  iterations_since_restore: 22\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.29310344827587\n",
            "    ram_util_percent: 19.200000000000003\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 85357.0\n",
            "    policy_1: 18442.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 29202.25\n",
            "    policy_1: 11551.25\n",
            "    policy_2: -26298.0\n",
            "    policy_3: -14455.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -75106.0\n",
            "    policy_3: -25426.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.02839081587968\n",
            "    mean_inference_ms: 6.60440523669099\n",
            "    mean_processing_ms: 1.6563065581783531\n",
            "  time_since_restore: 458.8852970600128\n",
            "  time_this_iter_s: 20.769564151763916\n",
            "  time_total_s: 458.8852970600128\n",
            "  timestamp: 1584524072\n",
            "  timesteps_since_restore: 2816\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 2816\n",
            "  training_iteration: 22\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         458.885</td><td style=\"text-align: right;\">2816</td><td style=\"text-align: right;\">    22</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-34-52\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 4\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16882.905\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.44999998807907104\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.903593063354492\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.018068283796310425\n",
            "        policy_loss: -0.14136949181556702\n",
            "        total_loss: 1044572928.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 1044572928.0\n",
            "    load_time_ms: 1.493\n",
            "    num_steps_sampled: 2944\n",
            "    num_steps_trained: 2944\n",
            "    sample_time_ms: 3807.82\n",
            "    update_time_ms: 27.437\n",
            "  iterations_since_restore: 23\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 91.04137931034481\n",
            "    ram_util_percent: 19.299999999999997\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 85357.0\n",
            "    policy_1: 18442.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 29202.25\n",
            "    policy_1: 11551.25\n",
            "    policy_2: -26298.0\n",
            "    policy_3: -14455.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -75106.0\n",
            "    policy_3: -25426.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.028390815879675\n",
            "    mean_inference_ms: 6.604405236690991\n",
            "    mean_processing_ms: 1.656306558178353\n",
            "  time_since_restore: 479.05276131629944\n",
            "  time_this_iter_s: 20.16746425628662\n",
            "  time_total_s: 479.05276131629944\n",
            "  timestamp: 1584524092\n",
            "  timesteps_since_restore: 2944\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 2944\n",
            "  training_iteration: 23\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         479.053</td><td style=\"text-align: right;\">2944</td><td style=\"text-align: right;\">    23</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-35-12\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 4\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16898.602\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.44999998807907104\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.9377899169921875\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.01909896731376648\n",
            "        policy_loss: -0.12052980065345764\n",
            "        total_loss: 878409088.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 878409088.0\n",
            "    load_time_ms: 1.443\n",
            "    num_steps_sampled: 3072\n",
            "    num_steps_trained: 3072\n",
            "    sample_time_ms: 3790.762\n",
            "    update_time_ms: 27.793\n",
            "  iterations_since_restore: 24\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.89655172413792\n",
            "    ram_util_percent: 19.4\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 85357.0\n",
            "    policy_1: 18442.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 29202.25\n",
            "    policy_1: 11551.25\n",
            "    policy_2: -26298.0\n",
            "    policy_3: -14455.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -75106.0\n",
            "    policy_3: -25426.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.028390815879675\n",
            "    mean_inference_ms: 6.604405236690991\n",
            "    mean_processing_ms: 1.656306558178353\n",
            "  time_since_restore: 499.1920166015625\n",
            "  time_this_iter_s: 20.13925528526306\n",
            "  time_total_s: 499.1920166015625\n",
            "  timestamp: 1584524112\n",
            "  timesteps_since_restore: 3072\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 3072\n",
            "  training_iteration: 24\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         499.192</td><td style=\"text-align: right;\">3072</td><td style=\"text-align: right;\">    24</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-35-33\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 4\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16946.881\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.44999998807907104\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.959592819213867\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.022776860743761063\n",
            "        policy_loss: -0.09756298363208771\n",
            "        total_loss: 110201616.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 110201616.0\n",
            "    load_time_ms: 1.458\n",
            "    num_steps_sampled: 3200\n",
            "    num_steps_trained: 3200\n",
            "    sample_time_ms: 3789.914\n",
            "    update_time_ms: 27.808\n",
            "  iterations_since_restore: 25\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.64666666666668\n",
            "    ram_util_percent: 19.5\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 85357.0\n",
            "    policy_1: 18442.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 29202.25\n",
            "    policy_1: 11551.25\n",
            "    policy_2: -26298.0\n",
            "    policy_3: -14455.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -75106.0\n",
            "    policy_3: -25426.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.028390815879675\n",
            "    mean_inference_ms: 6.604405236690991\n",
            "    mean_processing_ms: 1.656306558178353\n",
            "  time_since_restore: 520.0001218318939\n",
            "  time_this_iter_s: 20.80810523033142\n",
            "  time_total_s: 520.0001218318939\n",
            "  timestamp: 1584524133\n",
            "  timesteps_since_restore: 3200\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 3200\n",
            "  training_iteration: 25\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">             520</td><td style=\"text-align: right;\">3200</td><td style=\"text-align: right;\">    25</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-35-53\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 4\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16971.923\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.675000011920929\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.952639579772949\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.013001829385757446\n",
            "        policy_loss: -0.08109887689352036\n",
            "        total_loss: 99123440.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 99123440.0\n",
            "    load_time_ms: 1.479\n",
            "    num_steps_sampled: 3328\n",
            "    num_steps_trained: 3328\n",
            "    sample_time_ms: 3770.51\n",
            "    update_time_ms: 27.671\n",
            "  iterations_since_restore: 26\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.50689655172415\n",
            "    ram_util_percent: 19.6\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 85357.0\n",
            "    policy_1: 18442.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 29202.25\n",
            "    policy_1: 11551.25\n",
            "    policy_2: -26298.0\n",
            "    policy_3: -14455.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -75106.0\n",
            "    policy_3: -25426.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.028390815879675\n",
            "    mean_inference_ms: 6.604405236690991\n",
            "    mean_processing_ms: 1.656306558178353\n",
            "  time_since_restore: 540.5387532711029\n",
            "  time_this_iter_s: 20.538631439208984\n",
            "  time_total_s: 540.5387532711029\n",
            "  timestamp: 1584524153\n",
            "  timesteps_since_restore: 3328\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 3328\n",
            "  training_iteration: 26\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         540.539</td><td style=\"text-align: right;\">3328</td><td style=\"text-align: right;\">    26</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-36-14\n",
            "  done: false\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 4\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16934.771\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.675000011920929\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.900189399719238\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.011303318664431572\n",
            "        policy_loss: -0.07291771471500397\n",
            "        total_loss: 62445220.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 62445220.0\n",
            "    load_time_ms: 1.491\n",
            "    num_steps_sampled: 3456\n",
            "    num_steps_trained: 3456\n",
            "    sample_time_ms: 3771.017\n",
            "    update_time_ms: 28.609\n",
            "  iterations_since_restore: 27\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.14827586206896\n",
            "    ram_util_percent: 19.700000000000003\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 85357.0\n",
            "    policy_1: 18442.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 29202.25\n",
            "    policy_1: 11551.25\n",
            "    policy_2: -26298.0\n",
            "    policy_3: -14455.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -75106.0\n",
            "    policy_3: -25426.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.028390815879675\n",
            "    mean_inference_ms: 6.604405236690991\n",
            "    mean_processing_ms: 1.656306558178353\n",
            "  time_since_restore: 560.7014710903168\n",
            "  time_this_iter_s: 20.162717819213867\n",
            "  time_total_s: 560.7014710903168\n",
            "  timestamp: 1584524174\n",
            "  timesteps_since_restore: 3456\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 3456\n",
            "  training_iteration: 27\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         560.701</td><td style=\"text-align: right;\">3456</td><td style=\"text-align: right;\">    27</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_continuousDoubleAuction-v0_8e49eea8:\n",
            "  custom_metrics: {}\n",
            "  date: 2020-03-18_09-36-34\n",
            "  done: true\n",
            "  episode_len_mean: 701.0\n",
            "  episode_reward_max: 0.0\n",
            "  episode_reward_mean: 0.0\n",
            "  episode_reward_min: 0.0\n",
            "  episodes_this_iter: 0\n",
            "  episodes_total: 4\n",
            "  experiment_id: a1a6cb68061649539c6b88410a8c5ee3\n",
            "  experiment_tag: '0'\n",
            "  hostname: 171ebb90f431\n",
            "  info:\n",
            "    grad_time_ms: 16927.445\n",
            "    learner:\n",
            "      policy_0:\n",
            "        cur_kl_coeff: 0.675000011920929\n",
            "        cur_lr: 4.999999873689376e-05\n",
            "        entropy: 7.938020706176758\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.013972057029604912\n",
            "        policy_loss: -0.060210853815078735\n",
            "        total_loss: 32535596.0\n",
            "        vf_explained_var: 0.0\n",
            "        vf_loss: 32535596.0\n",
            "    load_time_ms: 1.464\n",
            "    num_steps_sampled: 3584\n",
            "    num_steps_trained: 3584\n",
            "    sample_time_ms: 3776.396\n",
            "    update_time_ms: 28.529\n",
            "  iterations_since_restore: 28\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 90.1\n",
            "    ram_util_percent: 19.789655172413788\n",
            "  pid: 483\n",
            "  policy_reward_max:\n",
            "    policy_0: 85357.0\n",
            "    policy_1: 18442.0\n",
            "    policy_2: 11204.0\n",
            "    policy_3: -8457.0\n",
            "  policy_reward_mean:\n",
            "    policy_0: 29202.25\n",
            "    policy_1: 11551.25\n",
            "    policy_2: -26298.0\n",
            "    policy_3: -14455.5\n",
            "  policy_reward_min:\n",
            "    policy_0: 2269.0\n",
            "    policy_1: -2725.0\n",
            "    policy_2: -75106.0\n",
            "    policy_3: -25426.0\n",
            "  sampler_perf:\n",
            "    mean_env_wait_ms: 51.028390815879675\n",
            "    mean_inference_ms: 6.604405236690991\n",
            "    mean_processing_ms: 1.656306558178353\n",
            "  time_since_restore: 581.3208396434784\n",
            "  time_this_iter_s: 20.61936855316162\n",
            "  time_total_s: 581.3208396434784\n",
            "  timestamp: 1584524194\n",
            "  timesteps_since_restore: 3584\n",
            "  timesteps_this_iter: 128\n",
            "  timesteps_total: 3584\n",
            "  training_iteration: 28\n",
            "  trial_id: 8e49eea8\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>RUNNING </td><td>172.28.0.2:483</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         581.321</td><td style=\"text-align: right;\">3584</td><td style=\"text-align: right;\">    28</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/PPO<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_continuousDoubleAuction-v0_8e49eea8</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">         581.321</td><td style=\"text-align: right;\">3584</td><td style=\"text-align: right;\">    28</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-18 09:36:35,187\tINFO tune.py:352 -- Returning an analysis object by default. You can call `analysis.trials` to retrieve a list of trials. This message will be removed in future versions of Tune.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgOQLnuOFsiJ",
        "colab_type": "code",
        "outputId": "f0472a04-0524-4570-bc31-631e4496852d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "df = analysis_obj.dataframe()\n",
        "print(df.T)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                                                        0\n",
            "episode_reward_max                                                                      0\n",
            "episode_reward_min                                                                      0\n",
            "episode_reward_mean                                                                     0\n",
            "episode_len_mean                                                                      701\n",
            "episodes_this_iter                                                                      0\n",
            "timesteps_this_iter                                                                   128\n",
            "done                                                                                 True\n",
            "timesteps_total                                                                      3584\n",
            "episodes_total                                                                          4\n",
            "training_iteration                                                                     28\n",
            "experiment_id                                            a1a6cb68061649539c6b88410a8c5ee3\n",
            "date                                                                  2020-03-18_09-36-34\n",
            "timestamp                                                                      1584524194\n",
            "time_this_iter_s                                                                  20.6194\n",
            "time_total_s                                                                      581.321\n",
            "pid                                                                                   483\n",
            "hostname                                                                     171ebb90f431\n",
            "node_ip                                                                        172.28.0.2\n",
            "time_since_restore                                                                581.321\n",
            "timesteps_since_restore                                                              3584\n",
            "iterations_since_restore                                                               28\n",
            "num_healthy_workers                                                                     1\n",
            "trial_id                                                                         8e49eea8\n",
            "experiment_tag                                                                          0\n",
            "hist_stats/episode_reward                                            [0.0, 0.0, 0.0, 0.0]\n",
            "hist_stats/episode_lengths                                           [701, 701, 701, 701]\n",
            "info/num_steps_trained                                                               3584\n",
            "info/num_steps_sampled                                                               3584\n",
            "info/sample_time_ms                                                                3776.4\n",
            "info/load_time_ms                                                                   1.464\n",
            "info/grad_time_ms                                                                 16927.4\n",
            "info/update_time_ms                                                                28.529\n",
            "perf/cpu_util_percent                                                                90.1\n",
            "perf/ram_util_percent                                                             19.7897\n",
            "info/learner/policy_0/cur_kl_coeff                                                  0.675\n",
            "info/learner/policy_0/cur_lr                                                        5e-05\n",
            "info/learner/policy_0/total_loss                                              3.25356e+07\n",
            "info/learner/policy_0/policy_loss                                              -0.0602109\n",
            "info/learner/policy_0/vf_loss                                                 3.25356e+07\n",
            "info/learner/policy_0/vf_explained_var                                                  0\n",
            "info/learner/policy_0/kl                                                        0.0139721\n",
            "info/learner/policy_0/entropy                                                     7.93802\n",
            "info/learner/policy_0/entropy_coeff                                                     0\n",
            "config/env                                                     continuousDoubleAuction-v0\n",
            "config/multiagent                       {'policies': {'policy_0': [None, 'Box(4, 10)',...\n",
            "config/num_envs_per_worker                                                              2\n",
            "config/num_workers                                                                      1\n",
            "config/sample_batch_size                                                               32\n",
            "config/train_batch_size                                                               128\n",
            "logdir                                  /content/gdrive/My Drive/Colab Notebooks/gym-c...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}