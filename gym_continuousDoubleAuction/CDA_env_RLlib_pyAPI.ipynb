{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CDA_env_RLlib_pyAPI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAqVG2cqjLXM",
        "colab_type": "code",
        "outputId": "5df76b67-b484-450b-f175-ba2212d6b145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Needed to switch directory in Google drive so as to import MARL env.\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "%cd \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/\"\n",
        "!pwd\n",
        "!pip install -r requirements.txt\n",
        "!pip show tensorflow\n",
        "!pip show ray"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction\n",
            "/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction\n",
            "Requirement already satisfied: absl-py==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: aiohttp==3.6.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (3.6.2)\n",
            "Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: async-timeout==3.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (3.0.1)\n",
            "Requirement already satisfied: atari-py==0.2.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.2.6)\n",
            "Requirement already satisfied: attrs==19.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (19.3.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.8.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (4.8.2)\n",
            "Requirement already satisfied: cachetools==4.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (4.0.0)\n",
            "Requirement already satisfied: certifi==2019.11.28 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (2019.11.28)\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: Click==7.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (7.0)\n",
            "Requirement already satisfied: cloudpickle==1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: colorama==0.4.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (0.4.3)\n",
            "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (3.0.12)\n",
            "Requirement already satisfied: funcsigs==1.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (1.0.2)\n",
            "Requirement already satisfied: future==0.18.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (0.18.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (0.2.2)\n",
            "Requirement already satisfied: google==2.0.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (2.0.3)\n",
            "Requirement already satisfied: google-auth==1.11.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (1.11.2)\n",
            "Requirement already satisfied: google-auth-oauthlib==0.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (0.4.1)\n",
            "Requirement already satisfied: google-pasta==0.1.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 21)) (0.1.8)\n",
            "Requirement already satisfied: grpcio==1.27.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 22)) (1.27.2)\n",
            "Requirement already satisfied: gym==0.17.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 23)) (0.17.0)\n",
            "Obtaining gym_continuousDoubleAuction from git+https://github.com/ChuaCheowHuan/gym-continuousDoubleAuction.git@c897137cbcc93ca71cbd51c27e683c3298f6562d#egg=gym_continuousDoubleAuction (from -r requirements.txt (line 24))\n",
            "  Skipping because already up-to-date.\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 25)) (2.10.0)\n",
            "Requirement already satisfied: idna==2.9 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 26)) (2.9)\n",
            "Requirement already satisfied: importlib-metadata==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 27)) (1.5.0)\n",
            "Requirement already satisfied: joblib==0.14.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 28)) (0.14.1)\n",
            "Requirement already satisfied: jsonschema==3.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 29)) (3.2.0)\n",
            "Requirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 30)) (1.0.8)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 31)) (1.1.0)\n",
            "Requirement already satisfied: lz4==3.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 32)) (3.0.2)\n",
            "Requirement already satisfied: Markdown==3.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 33)) (3.2.1)\n",
            "Requirement already satisfied: more-itertools==8.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 34)) (8.2.0)\n",
            "Requirement already satisfied: multidict==4.7.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 35)) (4.7.5)\n",
            "Requirement already satisfied: numpy==1.18.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 36)) (1.18.1)\n",
            "Requirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 37)) (3.1.0)\n",
            "Requirement already satisfied: opencv-python==4.2.0.32 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 38)) (4.2.0.32)\n",
            "Requirement already satisfied: opencv-python-headless==4.2.0.32 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 39)) (4.2.0.32)\n",
            "Requirement already satisfied: opt-einsum==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 40)) (3.1.0)\n",
            "Requirement already satisfied: packaging==20.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 41)) (20.1)\n",
            "Requirement already satisfied: pandas==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 42)) (1.0.1)\n",
            "Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 43)) (7.0.0)\n",
            "Requirement already satisfied: pluggy==0.13.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 44)) (0.13.1)\n",
            "Requirement already satisfied: protobuf==3.11.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 45)) (3.11.3)\n",
            "Requirement already satisfied: py==1.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 46)) (1.8.1)\n",
            "Requirement already satisfied: py-spy==0.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 47)) (0.3.3)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 48)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 49)) (0.2.8)\n",
            "Requirement already satisfied: pyglet==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 50)) (1.5.0)\n",
            "Requirement already satisfied: pyparsing==2.4.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 51)) (2.4.6)\n",
            "Requirement already satisfied: pyrsistent==0.15.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 52)) (0.15.7)\n",
            "Requirement already satisfied: pytest==5.3.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 53)) (5.3.5)\n",
            "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 54)) (2.8.1)\n",
            "Requirement already satisfied: pytz==2019.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 55)) (2019.3)\n",
            "Requirement already satisfied: PyYAML==5.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 56)) (5.3)\n",
            "Requirement already satisfied: ray==0.8.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 57)) (0.8.2)\n",
            "Requirement already satisfied: redis==3.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 58)) (3.4.1)\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 59)) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 60)) (1.3.0)\n",
            "Requirement already satisfied: rsa==4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 61)) (4.0)\n",
            "Requirement already satisfied: scikit-learn==0.22.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 62)) (0.22.2)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 63)) (1.4.1)\n",
            "Requirement already satisfied: six==1.14.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 64)) (1.14.0)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 65)) (0.0)\n",
            "Requirement already satisfied: sortedcontainers==2.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 66)) (2.1.0)\n",
            "Requirement already satisfied: soupsieve==2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 67)) (2.0)\n",
            "Requirement already satisfied: tabulate==0.8.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 68)) (0.8.6)\n",
            "Requirement already satisfied: tensorboard==2.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 69)) (2.1.0)\n",
            "Requirement already satisfied: tensorboardX==2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 70)) (2.0)\n",
            "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 71)) (2.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator==2.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 72)) (2.1.0)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 73)) (1.1.0)\n",
            "Requirement already satisfied: urllib3==1.25.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 74)) (1.25.8)\n",
            "Requirement already satisfied: wcwidth==0.1.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 75)) (0.1.8)\n",
            "Requirement already satisfied: Werkzeug==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 76)) (1.0.0)\n",
            "Requirement already satisfied: wrapt==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 77)) (1.12.0)\n",
            "Requirement already satisfied: yarl==1.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 78)) (1.4.2)\n",
            "Requirement already satisfied: zipp==3.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 79)) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp==3.6.2->-r requirements.txt (line 2)) (3.6.6)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp==3.6.2->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth==1.11.2->-r requirements.txt (line 19)) (45.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0->-r requirements.txt (line 69)) (0.34.2)\n",
            "Installing collected packages: gym-continuousDoubleAuction\n",
            "  Found existing installation: gym-continuousDoubleAuction 0.0.1\n",
            "    Can't uninstall 'gym-continuousDoubleAuction'. No files were found to uninstall.\n",
            "  Running setup.py develop for gym-continuousDoubleAuction\n",
            "Successfully installed gym-continuousDoubleAuction\n",
            "Name: tensorflow\n",
            "Version: 2.1.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: gast, opt-einsum, protobuf, tensorflow-estimator, google-pasta, keras-applications, tensorboard, six, wrapt, astor, grpcio, wheel, scipy, termcolor, numpy, absl-py, keras-preprocessing\n",
            "Required-by: tensorflow-federated, stable-baselines, magenta, fancyimpute\n",
            "Name: ray\n",
            "Version: 0.8.2\n",
            "Summary: A system for parallel and distributed Python that unifies the ML ecosystem.\n",
            "Home-page: https://github.com/ray-project/ray\n",
            "Author: Ray Team\n",
            "Author-email: ray-dev@googlegroups.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: pyyaml, click, six, py-spy, funcsigs, pytest, filelock, colorama, aiohttp, numpy, google, grpcio, protobuf, jsonschema, cloudpickle, redis, packaging\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UW3INjDipTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "os.environ['RAY_DEBUG_DISABLE_MEMORY_MONITOR'] = \"True\"\n",
        "\n",
        "import argparse\n",
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.rllib.utils import try_import_tf\n",
        "from ray.tune.registry import register_env\n",
        "from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n",
        "from ray.rllib.models.tf.fcnet_v2 import FullyConnectedNetwork\n",
        "from ray.rllib.models import Model, ModelCatalog\n",
        "from ray.rllib.policy.policy import Policy\n",
        "from ray.rllib.agents.ppo import ppo\n",
        "from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
        "from ray.rllib.agents.ppo.ppo_tf_policy import PPOTFPolicy\n",
        "from ray.tune.logger import pretty_print\n",
        "\n",
        "\n",
        "import sys\n",
        "if \"../\" not in sys.path:\n",
        "    sys.path.append(\"../\")\n",
        "\n",
        "from gym_continuousDoubleAuction.envs.continuousDoubleAuction_env import continuousDoubleAuctionEnv\n",
        "\n",
        "tf = try_import_tf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIYT1UTxiQcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomModel_1(Model):\n",
        "    def _lstm(self, Inputs, cell_size):\n",
        "        s = tf.expand_dims(Inputs, axis=1, name='time_major')  # [time_step, feature] => [time_step, batch, feature]\n",
        "        lstm_cell = tf.nn.rnn_cell.LSTMCell(cell_size)\n",
        "        self.init_state = lstm_cell.zero_state(batch_size=1, dtype=tf.float32)\n",
        "        # time_major means [time_step, batch, feature] while batch major means [batch, time_step, feature]\n",
        "        outputs, self.final_state = tf.nn.dynamic_rnn(cell=lstm_cell, inputs=s, initial_state=self.init_state, time_major=True)\n",
        "        lstm_out = tf.reshape(outputs, [-1, cell_size], name='flatten_rnn_outputs')  # joined state representation\n",
        "        return lstm_out\n",
        "\n",
        "    def _build_layers_v2(self, input_dict, num_outputs, options):\n",
        "        hidden = 512\n",
        "        cell_size = 256\n",
        "        #S = input_dict[\"obs\"]\n",
        "        S = tf.layers.flatten(input_dict[\"obs\"])\n",
        "        with tf.variable_scope(tf.VariableScope(tf.AUTO_REUSE, \"shared\"),\n",
        "                               reuse=tf.AUTO_REUSE,\n",
        "                               auxiliary_name_scope=False):\n",
        "            last_layer = tf.layers.dense(S, hidden, activation=tf.nn.relu, name=\"fc1\")\n",
        "        last_layer = tf.layers.dense(last_layer, hidden, activation=tf.nn.relu, name=\"fc2\")\n",
        "        last_layer = tf.layers.dense(last_layer, hidden, activation=tf.nn.relu, name=\"fc3\")\n",
        "\n",
        "        last_layer = self._lstm(last_layer, cell_size)\n",
        "\n",
        "        output = tf.layers.dense(last_layer, num_outputs, activation=tf.nn.softmax, name=\"mu\")\n",
        "\n",
        "        return output, last_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cijiMv-ti1SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_RandomPolicy(_seed):\n",
        "\n",
        "    # a hand-coded policy that acts at random in the env (doesn't learn)\n",
        "    class RandomPolicy(Policy):\n",
        "        \"\"\"Hand-coded policy that returns random actions.\"\"\"\n",
        "        def __init__(self, observation_space, action_space, config):\n",
        "            self.observation_space = observation_space\n",
        "            self.action_space = action_space\n",
        "            self.action_space.seed(_seed)\n",
        "\n",
        "        def compute_actions(self,\n",
        "                            obs_batch,\n",
        "                            state_batches,\n",
        "                            prev_action_batch=None,\n",
        "                            prev_reward_batch=None,\n",
        "                            info_batch=None,\n",
        "                            episodes=None,\n",
        "                            **kwargs):\n",
        "            \"\"\"Compute actions on a batch of observations.\"\"\"\n",
        "            return [self.action_space.sample() for _ in obs_batch], [], {}\n",
        "\n",
        "        def learn_on_batch(self, samples):\n",
        "            \"\"\"No learning.\"\"\"\n",
        "            #return {}\n",
        "            pass\n",
        "\n",
        "        def get_weights(self):\n",
        "            pass\n",
        "\n",
        "        def set_weights(self, weights):\n",
        "            pass\n",
        "\n",
        "    return RandomPolicy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ASMamrPoh3",
        "colab_type": "code",
        "outputId": "21acbe67-2d10-4753-f132-6f484e1ee4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "ray.init(ignore_reinit_error=True, log_to_driver=False, webui_host='127.0.0.1', num_cpus=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 07:55:30,680\tWARNING services.py:586 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
            "2020-03-19 07:55:30,681\tINFO resource_spec.py:212 -- Starting Ray with 6.74 GiB memory available for workers and up to 3.37 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
            "2020-03-19 07:55:31,198\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32m127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'node_ip_address': '172.28.0.2',\n",
              " 'object_store_address': '/tmp/ray/session_2020-03-19_07-55-30_679121_5591/sockets/plasma_store',\n",
              " 'raylet_socket_name': '/tmp/ray/session_2020-03-19_07-55-30_679121_5591/sockets/raylet',\n",
              " 'redis_address': '172.28.0.2:38993',\n",
              " 'session_dir': '/tmp/ray/session_2020-03-19_07-55-30_679121_5591',\n",
              " 'webui_url': '127.0.0.1:8265'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqzjVWUsPykm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_agents = 4\n",
        "num_policies = num_agents\n",
        "num_iters = 3\n",
        "simple = False #store_true\n",
        "num_of_traders = num_agents\n",
        "tape_display_length = 10 \n",
        "tick_size = 1\n",
        "init_cash = 1000000\n",
        "max_step = 700 # per episode \n",
        "episode = 5 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To995IZanbGx",
        "colab_type": "code",
        "outputId": "2b2cae7c-7bef-484f-ee35-2910a7e3c18d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "single_CDA_env = continuousDoubleAuctionEnv(num_of_traders, init_cash, tick_size, tape_display_length, max_step)\n",
        "obs_space = single_CDA_env.observation_space\n",
        "act_space = single_CDA_env.action_space\n",
        "register_env(\"continuousDoubleAuction-v0\", lambda _: continuousDoubleAuctionEnv(num_of_traders, init_cash, tick_size, tape_display_length, max_step))\n",
        "ModelCatalog.register_custom_model(\"model_disc\", CustomModel_1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN5IfMMvP4VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Each policy can have a different configuration (including custom model)\n",
        "def gen_policy(i):\n",
        "    config = {\"model\": {\"custom_model\": \"model_disc\"},\n",
        "              \"gamma\": 0.99,}\n",
        "    return (None, obs_space, act_space, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7KFjAxGP6en",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def policy_mapper(agent_id):\n",
        "    for i in range(num_agents):\n",
        "        if agent_id == i:\n",
        "            return \"policy_{}\".format(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXrTPRQDP8of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary of policies\n",
        "policies = {\"policy_{}\".format(i): gen_policy(i) for i in range(num_policies)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsbblOn-P_eA",
        "colab_type": "code",
        "outputId": "5e072152-f817-474d-e2d8-38b425d11cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# override policy with random policy\n",
        "\n",
        "def set_RandomPolicy(policies):\n",
        "    \"\"\"\n",
        "    Set 1st policy as PPO & override all other policies as RandomPolicy with\n",
        "    different seed.\n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(num_agents):\n",
        "        if i == num_agents-1:\n",
        "            break\n",
        "        x = i + 1\n",
        "        policies[\"policy_{}\".format(num_policies-x)] = (make_RandomPolicy(num_policies-x), obs_space, act_space, {})\n",
        "\n",
        "    print('policies:', policies)\n",
        "    return 0\n",
        "\n",
        "set_RandomPolicy(policies)\n",
        "\n",
        "policy_ids = list(policies.keys())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "policies: {'policy_0': (None, Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), {'model': {'custom_model': 'model_disc'}, 'gamma': 0.99}), 'policy_1': (<class '__main__.make_RandomPolicy.<locals>.RandomPolicy'>, Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), {}), 'policy_2': (<class '__main__.make_RandomPolicy.<locals>.RandomPolicy'>, Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), {}), 'policy_3': (<class '__main__.make_RandomPolicy.<locals>.RandomPolicy'>, Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), {})}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyMEBA0uC8ZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc0762d0-9853-479e-9cd0-1958786a3b9f"
      },
      "source": [
        "def main(args):    \n",
        "    config = ppo.DEFAULT_CONFIG.copy()\n",
        "    config[\"log_level\"] = \"DEBUG\"\n",
        "    config[\"multiagent\"] = {\"policies_to_train\": [\"policy_0\"],\n",
        "                            \"policies\": policies,\n",
        "                            \"policy_mapping_fn\": policy_mapper,\n",
        "                           }\n",
        "    config[\"num_workers\"] = 1\n",
        "    config[\"num_envs_per_worker\"] = 4   \n",
        "    config[\"train_batch_size\"] = 128\n",
        "    config[\"batch_mode\"] = \"complete_episodes\"\n",
        "    config[\"sample_batch_size\"] = 32\n",
        "\n",
        "    local_dir=\"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/\" # dir where your chkpts are saved\n",
        "    chkpt = 59 # set the restore chkpt\n",
        "    restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n",
        "\n",
        "    trainer = ppo.PPOTrainer(config=config, \n",
        "                             env=\"continuousDoubleAuction-v0\")    \n",
        "    #trainer.restore(restore_path) # uncomment this to restore from chkpt\n",
        "\n",
        "    for i in range(30):\n",
        "        # Perform one iteration of training the policy with PPO\n",
        "        result = trainer.train()\n",
        "        print(pretty_print(result))\n",
        "     \n",
        "        if i % 3 == 0:\n",
        "            checkpoint = trainer.save(local_dir)\n",
        "            print(\"checkpoint saved at\", checkpoint)\n",
        "\n",
        "    checkpoint = trainer.save(local_dir)\n",
        "    print(\"checkpoint saved at\", checkpoint)\n",
        "\n",
        "\n",
        "# run main\n",
        "main(None)            "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 07:55:32,298\tINFO trainer.py:420 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
            "2020-03-19 07:55:32,477\tINFO ppo.py:165 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "2020-03-19 07:55:32,539\tDEBUG worker_set.py:179 -- Creating TF session {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}\n",
            "2020-03-19 07:55:32,619\tDEBUG rollout_worker.py:791 -- Creating policy for policy_0\n",
            "2020-03-19 07:55:32,640\tDEBUG catalog.py:406 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fdac77f9e48>: Box(4, 10) -> (4, 10)\n",
            "2020-03-19 07:55:32,668\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:33,549\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdac7808d68>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>, 'is_training': <tf.Tensor 'policy_0/is_training:0' shape=() dtype=bool>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), [], Tensor(\"policy_0/seq_lens:0\", shape=(?,), dtype=int32)) -> Tensor(\"policy_0/default_model_1/mu/Softmax:0\", shape=(?, 23), dtype=float32), []\n",
            "/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/from_config.py:134: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  obj = yaml.load(type_)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method DiagGaussian.logp of <ray.rllib.models.tf.tf_action_dist.DiagGaussian object at 0x7fdba6e07470>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: unexpected EOF while parsing (<unknown>, line 5)\n",
            "WARNING: AutoGraph could not transform <bound method DiagGaussian.logp of <ray.rllib.models.tf.tf_action_dist.DiagGaussian object at 0x7fdab8d6a940>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: unexpected EOF while parsing (<unknown>, line 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 07:55:35,484\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:35,594\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab6c5dda0>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>, 'is_training': <tf.Tensor 'policy_0/is_training:0' shape=() dtype=bool>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), None, None) -> Tensor(\"policy_0/default_model_2/value_function/mu/Softmax:0\", shape=(?, 1), dtype=float32), []\n",
            "2020-03-19 07:55:35,671\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:35,756\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab6bac5f8>: ({'obs': <tf.Tensor 'policy_0/packed:0' shape=(1, 4, 10) dtype=float32>, 'prev_actions': <tf.Tensor 'policy_0/packed_1:0' shape=(1, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/packed_2:0' shape=(1,) dtype=float32>, 'is_training': <tf.Tensor 'policy_0/Const_3:0' shape=() dtype=bool>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), [], Tensor(\"policy_0/Const_4:0\", shape=(1,), dtype=int32)) -> Tensor(\"policy_0/default_model_3/mu/Softmax:0\", shape=(1, 23), dtype=float32), []\n",
            "2020-03-19 07:55:35,757\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:35,841\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab6bd24a8>: ({'obs': <tf.Tensor 'policy_0/packed:0' shape=(1, 4, 10) dtype=float32>, 'prev_actions': <tf.Tensor 'policy_0/packed_1:0' shape=(1, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/packed_2:0' shape=(1,) dtype=float32>, 'is_training': <tf.Tensor 'policy_0/Const_3:0' shape=() dtype=bool>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), None, None) -> Tensor(\"policy_0/default_model_4/value_function/mu/Softmax:0\", shape=(1, 1), dtype=float32), []\n",
            "2020-03-19 07:55:35,903\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:35,984\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab6bcb860>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>, 'is_training': <tf.Tensor 'policy_0/is_training:0' shape=() dtype=bool>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), [], Tensor(\"policy_0/seq_lens:0\", shape=(?,), dtype=int32)) -> Tensor(\"policy_0/default_model_5/mu/Softmax:0\", shape=(?, 23), dtype=float32), []\n",
            "2020-03-19 07:55:35,992\tDEBUG dynamic_tf_policy.py:347 -- Initializing loss function with dummy input:\n",
            "\n",
            "{ 'action_logp': <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "  'action_prob': <tf.Tensor 'policy_0/action_prob:0' shape=(?,) dtype=float32>,\n",
            "  'actions': <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "  'advantages': <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "  'behaviour_logits': <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "  'dones': <tf.Tensor 'policy_0/dones:0' shape=(?,) dtype=bool>,\n",
            "  'new_obs': <tf.Tensor 'policy_0/new_obs:0' shape=(?, 4, 10) dtype=float32>,\n",
            "  'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "  'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "  'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "  'rewards': <tf.Tensor 'policy_0/rewards:0' shape=(?,) dtype=float32>,\n",
            "  'seq_lens': <tf.Tensor 'policy_0/seq_lens:0' shape=(?,) dtype=int32>,\n",
            "  'value_targets': <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "  'vf_preds': <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>}\n",
            "\n",
            "2020-03-19 07:55:35,995\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:36,085\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab6307da0>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'is_training': True, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), [], Tensor(\"policy_0/seq_lens:0\", shape=(?,), dtype=int32)) -> Tensor(\"policy_0/default_model_6/mu/Softmax:0\", shape=(?, 23), dtype=float32), []\n",
            "2020-03-19 07:55:36,105\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:36,186\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab62674a8>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'is_training': True, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), None, None) -> Tensor(\"policy_0/default_model_7/value_function/mu/Softmax:0\", shape=(?, 1), dtype=float32), []\n",
            "2020-03-19 07:55:36,309\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:36,391\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab61b0f60>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'is_training': True, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), None, None) -> Tensor(\"policy_0/default_model_8/value_function/mu/Softmax:0\", shape=(?, 1), dtype=float32), []\n",
            "2020-03-19 07:55:37,517\tDEBUG tf_policy.py:229 -- These tensors were used in the loss_fn:\n",
            "\n",
            "{ 'action_logp': <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "  'actions': <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "  'advantages': <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "  'behaviour_logits': <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "  'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "  'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "  'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "  'value_targets': <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "  'vf_preds': <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>}\n",
            "\n",
            "2020-03-19 07:55:38,018\tDEBUG rollout_worker.py:791 -- Creating policy for policy_1\n",
            "2020-03-19 07:55:38,024\tDEBUG catalog.py:406 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fdab5d897b8>: Box(4, 10) -> (4, 10)\n",
            "2020-03-19 07:55:38,035\tDEBUG rollout_worker.py:791 -- Creating policy for policy_2\n",
            "2020-03-19 07:55:38,040\tDEBUG catalog.py:406 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fdab6185b38>: Box(4, 10) -> (4, 10)\n",
            "2020-03-19 07:55:38,047\tDEBUG rollout_worker.py:791 -- Creating policy for policy_3\n",
            "2020-03-19 07:55:38,051\tDEBUG catalog.py:406 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fdc480050b8>: Box(4, 10) -> (4, 10)\n",
            "2020-03-19 07:55:38,057\tINFO rollout_worker.py:824 -- Built policy map: {'policy_0': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7fdac77f9f60>, 'policy_1': <__main__.make_RandomPolicy.<locals>.RandomPolicy object at 0x7fdab5dcc7b8>, 'policy_2': <__main__.make_RandomPolicy.<locals>.RandomPolicy object at 0x7fdac77f9d68>, 'policy_3': <__main__.make_RandomPolicy.<locals>.RandomPolicy object at 0x7fdab5d46828>}\n",
            "2020-03-19 07:55:38,058\tINFO rollout_worker.py:825 -- Built preprocessor map: {'policy_0': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fdac77f9e48>, 'policy_1': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fdab5d897b8>, 'policy_2': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fdab6185b38>, 'policy_3': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fdc480050b8>}\n",
            "2020-03-19 07:55:38,059\tDEBUG rollout_worker.py:362 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
            "2020-03-19 07:55:38,061\tINFO rollout_worker.py:389 -- Built filter map: {'policy_0': <ray.rllib.utils.filter.NoFilter object at 0x7fdab5dc8ba8>, 'policy_1': <ray.rllib.utils.filter.NoFilter object at 0x7fdab61cb748>, 'policy_2': <ray.rllib.utils.filter.NoFilter object at 0x7fdab5dcc710>, 'policy_3': <ray.rllib.utils.filter.NoFilter object at 0x7fdab5dcc780>}\n",
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "2020-03-19 07:55:38,252\tDEBUG rollout_worker.py:471 -- Created rollout worker with env <ray.rllib.env.base_env._MultiAgentEnvToBaseEnv object at 0x7fdab5d2f550> (<continuousDoubleAuctionEnv instance>), policies {'policy_0': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7fdac77f9f60>, 'policy_1': <__main__.make_RandomPolicy.<locals>.RandomPolicy object at 0x7fdab5dcc7b8>, 'policy_2': <__main__.make_RandomPolicy.<locals>.RandomPolicy object at 0x7fdac77f9d68>, 'policy_3': <__main__.make_RandomPolicy.<locals>.RandomPolicy object at 0x7fdab5d46828>}\n",
            "2020-03-19 07:55:38,296\tINFO multi_gpu_optimizer.py:90 -- LocalMultiGPUOptimizer devices ['/cpu:0']\n",
            "2020-03-19 07:55:38,297\tDEBUG multi_gpu_optimizer.py:94 -- Policies to train: {'policy_0': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7fdac77f9f60>}\n",
            "2020-03-19 07:55:38,305\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:38,417\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab6c316a0>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>, 'is_training': <tf.Tensor 'policy_0_1/tower/is_training:0' shape=() dtype=bool>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), [], Tensor(\"policy_0_1/tower/seq_lens:0\", shape=(?,), dtype=int32)) -> Tensor(\"policy_0_1/tower/default_model/mu/Softmax:0\", shape=(?, 23), dtype=float32), []\n",
            "2020-03-19 07:55:38,568\tDEBUG catalog.py:532 -- Using custom model model_disc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method DiagGaussian.logp of <ray.rllib.models.tf.tf_action_dist.DiagGaussian object at 0x7fdab6c836d8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: unexpected EOF while parsing (<unknown>, line 5)\n",
            "WARNING: AutoGraph could not transform <bound method DiagGaussian.logp of <ray.rllib.models.tf.tf_action_dist.DiagGaussian object at 0x7fdab6ca2668>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: unexpected EOF while parsing (<unknown>, line 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 07:55:38,673\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab5c8d3c8>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>, 'is_training': <tf.Tensor 'policy_0_1/tower/is_training:0' shape=() dtype=bool>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), None, None) -> Tensor(\"policy_0_1/tower/default_model_1/value_function/mu/Softmax:0\", shape=(?, 1), dtype=float32), []\n",
            "2020-03-19 07:55:38,677\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:38,790\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab5da7c88>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'is_training': True, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), [], None) -> Tensor(\"policy_0_1/tower/default_model_2/mu/Softmax:0\", shape=(?, 23), dtype=float32), []\n",
            "2020-03-19 07:55:38,815\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:38,929\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab5baaf98>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'is_training': True, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), None, None) -> Tensor(\"policy_0_1/tower/default_model_3/value_function/mu/Softmax:0\", shape=(?, 1), dtype=float32), []\n",
            "2020-03-19 07:55:39,112\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:39,234\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab5afbcf8>: ({'obs': <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>, 'is_training': True, 'prev_actions': <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), None, None) -> Tensor(\"policy_0_1/tower/default_model_4/value_function/mu/Softmax:0\", shape=(?, 1), dtype=float32), []\n",
            "2020-03-19 07:55:41,379\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:41,511\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab56c6198>: ({'obs': <tf.Tensor 'policy_0_1/tower_1/Slice_7:0' shape=(?, 4, 10) dtype=float32>, 'prev_actions': <tf.Tensor 'policy_0_1/tower_1/Slice_8:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0_1/tower_1/Slice_9:0' shape=(?,) dtype=float32>, 'is_training': <tf.Tensor 'policy_0_1/tower_1/is_training:0' shape=() dtype=bool>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), [], Tensor(\"policy_0_1/tower_1/seq_lens:0\", shape=(?,), dtype=int32, device=/device:CPU:0)) -> Tensor(\"policy_0_1/tower_1/default_model/mu/Softmax:0\", shape=(?, 23), dtype=float32, device=/device:CPU:0), []\n",
            "2020-03-19 07:55:41,681\tDEBUG catalog.py:532 -- Using custom model model_disc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method DiagGaussian.logp of <ray.rllib.models.tf.tf_action_dist.DiagGaussian object at 0x7fdab568d320>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: unexpected EOF while parsing (<unknown>, line 5)\n",
            "WARNING: AutoGraph could not transform <bound method DiagGaussian.logp of <ray.rllib.models.tf.tf_action_dist.DiagGaussian object at 0x7fdab568d5f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: unexpected EOF while parsing (<unknown>, line 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 07:55:41,807\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab55b9fd0>: ({'obs': <tf.Tensor 'policy_0_1/tower_1/Slice_7:0' shape=(?, 4, 10) dtype=float32>, 'prev_actions': <tf.Tensor 'policy_0_1/tower_1/Slice_8:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0_1/tower_1/Slice_9:0' shape=(?,) dtype=float32>, 'is_training': <tf.Tensor 'policy_0_1/tower_1/is_training:0' shape=() dtype=bool>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), None, None) -> Tensor(\"policy_0_1/tower_1/default_model_1/value_function/mu/Softmax:0\", shape=(?, 1), dtype=float32, device=/device:CPU:0), []\n",
            "2020-03-19 07:55:41,810\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:41,930\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab5572908>: ({'obs': <tf.Tensor 'policy_0_1/tower_1/Slice_7:0' shape=(?, 4, 10) dtype=float32>, 'is_training': True, 'prev_actions': <tf.Tensor 'policy_0_1/tower_1/Slice_8:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0_1/tower_1/Slice_9:0' shape=(?,) dtype=float32>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), [], None) -> Tensor(\"policy_0_1/tower_1/default_model_2/mu/Softmax:0\", shape=(?, 23), dtype=float32, device=/device:CPU:0), []\n",
            "2020-03-19 07:55:41,957\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:42,080\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab54e9dd8>: ({'obs': <tf.Tensor 'policy_0_1/tower_1/Slice_7:0' shape=(?, 4, 10) dtype=float32>, 'is_training': True, 'prev_actions': <tf.Tensor 'policy_0_1/tower_1/Slice_8:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0_1/tower_1/Slice_9:0' shape=(?,) dtype=float32>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), None, None) -> Tensor(\"policy_0_1/tower_1/default_model_3/value_function/mu/Softmax:0\", shape=(?, 1), dtype=float32, device=/device:CPU:0), []\n",
            "2020-03-19 07:55:42,281\tDEBUG catalog.py:532 -- Using custom model model_disc\n",
            "2020-03-19 07:55:42,414\tDEBUG catalog.py:522 -- Created model <__main__.CustomModel_1 object at 0x7fdab54567f0>: ({'obs': <tf.Tensor 'policy_0_1/tower_1/Slice_7:0' shape=(?, 4, 10) dtype=float32>, 'is_training': True, 'prev_actions': <tf.Tensor 'policy_0_1/tower_1/Slice_8:0' shape=(?, 5) dtype=float32>, 'prev_rewards': <tf.Tensor 'policy_0_1/tower_1/Slice_9:0' shape=(?,) dtype=float32>} of Box(4, 10), Tuple(Discrete(3), Discrete(4), Box(1,), Box(1,), Discrete(12)), None, None) -> Tensor(\"policy_0_1/tower_1/default_model_4/value_function/mu/Softmax:0\", shape=(?, 1), dtype=float32, device=/device:CPU:0), []\n",
            "2020-03-19 07:55:47,646\tINFO trainable.py:178 -- _setup took 15.197 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
            "2020-03-19 07:55:47,648\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
            "2020-03-19 07:55:47,941\tWARNING trainable.py:210 -- Getting current IP.\n",
            "2020-03-19 07:55:47,943\tINFO trainable.py:416 -- Restored on 172.28.0.2 from checkpoint: /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_29/checkpoint-29\n",
            "2020-03-19 07:55:47,948\tINFO trainable.py:423 -- Current state after restoring: {'_iteration': 29, '_timesteps_total': 20329, '_time_total': 3060.4263772964478, '_episodes_total': 29}\n",
            "2020-03-19 07:55:48,320\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 20329}\n",
            "2020-03-19 07:57:08,207\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 07:57:08,209\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,212\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,214\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,217\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,218\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,219\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,220\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,222\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,223\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,224\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,224\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,226\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,227\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,229\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,230\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,231\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 07:57:08,236\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.249, max=11.0, mean=1.643),\n",
            "              np.ndarray((701,), dtype=float32, min=-78131.0, max=79672.0, mean=21.816),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3073.0, max=2950.0, mean=-10.395),\n",
            "              np.ndarray((701,), dtype=float32, min=-13.293, max=-6.535, mean=-7.857),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.249, max=11.0, mean=1.645),\n",
            "              np.ndarray((701,), dtype=float32, min=-5.609, max=2.355, mean=-0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.65, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3073.0, max=2950.0, mean=-10.395),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.249, max=11.0, mean=1.643),\n",
            "              np.ndarray((701,), dtype=float32, min=-78131.0, max=79672.0, mean=21.816),\n",
            "              np.ndarray((701,), dtype=float32, min=-58324.523, max=24005.932, mean=-339.018),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 07:57:08,237\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 07:57:08,388\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n",
            "2020-03-19 07:57:12,107\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': 0.02544739, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.049325638, 'entropy': 7.9801345, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:14,735\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': 0.0020587356, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.04126719, 'entropy': 7.95349, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:17,279\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.01032843, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.036583245, 'entropy': 7.9364715, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:19,833\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.017291278, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.032050837, 'entropy': 7.9359727, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:22,454\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.022028778, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.029680273, 'entropy': 7.936714, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:25,049\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.026923368, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.029208073, 'entropy': 7.9289155, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:27,655\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.02872917, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.02822579, 'entropy': 7.9526343, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:30,329\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.0338796, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.027180925, 'entropy': 7.962125, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:32,984\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.037671573, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.025263216, 'entropy': 7.938193, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:35,675\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.03941857, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.025240526, 'entropy': 7.9323335, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:38,298\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.042520206, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.02442346, 'entropy': 7.9312606, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:40,906\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.04479481, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.024721393, 'entropy': 7.9371367, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:43,484\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.047818255, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.025618205, 'entropy': 7.951085, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:46,050\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.04965157, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.024771195, 'entropy': 7.947038, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:48,637\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.050248493, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.024755469, 'entropy': 7.943137, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:51,196\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.051504344, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.024282185, 'entropy': 7.9346914, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:53,789\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.053510834, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.0240294, 'entropy': 7.934558, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:56,371\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.054783165, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.023543704, 'entropy': 7.9414015, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:57:58,960\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.053476937, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.023417916, 'entropy': 7.9403267, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:01,543\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.054270934, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.022790758, 'entropy': 7.936914, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:04,091\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.054715168, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.022708632, 'entropy': 7.9390383, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:06,694\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.056379456, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.023679262, 'entropy': 7.9348516, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:09,241\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.058049846, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.023044271, 'entropy': 7.9343705, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:11,802\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.05905993, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.022516541, 'entropy': 7.93733, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:14,371\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.059122205, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.022204643, 'entropy': 7.9318695, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:16,931\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.06047948, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.023054799, 'entropy': 7.9314985, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:19,459\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.06187119, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.022675503, 'entropy': 7.934825, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:22,053\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.063145235, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.022416549, 'entropy': 7.935216, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:24,589\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.063159205, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.023096982, 'entropy': 7.937529, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:27,229\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 109154050.0, 'policy_loss': -0.06438011, 'vf_loss': 109154050.0, 'vf_explained_var': 0.0, 'kl': 0.023239201, 'entropy': 7.9368324, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:27,460\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 21030}\n",
            "2020-03-19 07:58:27,497\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 07:58:27,502\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.474, max=11.0, mean=1.632),\n",
            "              np.ndarray((701,), dtype=float32, min=-22192.0, max=7592.0, mean=-18.228),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3701.0, max=2889.0, mean=-15.962),\n",
            "              np.ndarray((701,), dtype=float32, min=-13.443, max=-6.515, mean=-7.866),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.474, max=11.0, mean=1.635),\n",
            "              np.ndarray((701,), dtype=float32, min=-4.977, max=1.096, mean=-0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.75, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3701.0, max=2889.0, mean=-15.962),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.474, max=11.0, mean=1.632),\n",
            "              np.ndarray((701,), dtype=float32, min=-22192.0, max=7592.0, mean=-18.228),\n",
            "              np.ndarray((701,), dtype=float32, min=-32302.004, max=6686.883, mean=-351.214),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 07:58:27,503\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 07:58:27,505\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_07-58-27\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 30\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78841.899\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.20000000298023224\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.936832427978516\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.023239200934767723\n",
            "      policy_loss: -0.06438010931015015\n",
            "      total_loss: 109154048.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 109154048.0\n",
            "  load_time_ms: 178.916\n",
            "  num_steps_sampled: 21030\n",
            "  num_steps_trained: 19200\n",
            "  sample_time_ms: 77889.172\n",
            "  update_time_ms: 1990.241\n",
            "iterations_since_restore: 1\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 76.99649122807018\n",
            "  ram_util_percent: 16.387719298245617\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 13713.0\n",
            "  policy_1: 15304.0\n",
            "  policy_2: -10671.0\n",
            "  policy_3: -18346.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 13713.0\n",
            "  policy_1: 15304.0\n",
            "  policy_2: -10671.0\n",
            "  policy_3: -18346.0\n",
            "policy_reward_min:\n",
            "  policy_0: 13713.0\n",
            "  policy_1: 15304.0\n",
            "  policy_2: -10671.0\n",
            "  policy_3: -18346.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 100.23798460294718\n",
            "  mean_inference_ms: 8.062010477071475\n",
            "  mean_processing_ms: 2.592512005754346\n",
            "time_since_restore: 159.0456109046936\n",
            "time_this_iter_s: 159.0456109046936\n",
            "time_total_s: 3219.4719882011414\n",
            "timestamp: 1584604707\n",
            "timesteps_since_restore: 701\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 21030\n",
            "training_iteration: 30\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_30/checkpoint-30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 07:58:30,104\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': 0.01968052, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.026977161, 'entropy': 7.9116945, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:32,717\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.009047096, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.020211179, 'entropy': 7.8842125, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:35,313\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.021288987, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.019801695, 'entropy': 7.871657, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:37,878\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.029392188, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.020227801, 'entropy': 7.8762345, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:40,423\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014264.0, 'policy_loss': -0.035977297, 'vf_loss': 44014264.0, 'vf_explained_var': 0.0, 'kl': 0.019849902, 'entropy': 7.8792543, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:43,078\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.039933905, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.019674327, 'entropy': 7.87317, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:45,650\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.04602719, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.019856628, 'entropy': 7.8729033, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:48,177\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.05122758, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.019631255, 'entropy': 7.8775597, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:50,752\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.05574944, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.020130415, 'entropy': 7.8775277, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:53,348\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.059828747, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.020098004, 'entropy': 7.8816175, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:55,883\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.06372706, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.020294003, 'entropy': 7.8805475, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:58:58,436\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014264.0, 'policy_loss': -0.066098325, 'vf_loss': 44014264.0, 'vf_explained_var': 0.0, 'kl': 0.020621678, 'entropy': 7.8752046, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:00,989\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.06662182, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.020933067, 'entropy': 7.877426, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:03,552\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.07044166, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.02086482, 'entropy': 7.877604, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:06,149\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.07188065, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.020414183, 'entropy': 7.88143, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:08,705\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.07438248, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.020725908, 'entropy': 7.8786745, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:11,272\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.07656647, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.021139434, 'entropy': 7.874495, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:13,835\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.0775012, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.021012861, 'entropy': 7.8754606, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:16,403\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.07865043, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.021254487, 'entropy': 7.8715096, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:18,960\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014264.0, 'policy_loss': -0.079851106, 'vf_loss': 44014264.0, 'vf_explained_var': 0.0, 'kl': 0.021670442, 'entropy': 7.8706217, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:21,508\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014264.0, 'policy_loss': -0.08161441, 'vf_loss': 44014264.0, 'vf_explained_var': 0.0, 'kl': 0.021484025, 'entropy': 7.8723207, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:24,062\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.082447425, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.021448633, 'entropy': 7.8713746, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:26,644\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014264.0, 'policy_loss': -0.08322669, 'vf_loss': 44014264.0, 'vf_explained_var': 0.0, 'kl': 0.021671098, 'entropy': 7.871218, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:29,218\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.08362685, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.021654304, 'entropy': 7.867121, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:31,785\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.08404074, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.021250632, 'entropy': 7.8679366, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:34,350\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.08537492, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.021213342, 'entropy': 7.8696356, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:36,968\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014264.0, 'policy_loss': -0.0856839, 'vf_loss': 44014264.0, 'vf_explained_var': 0.0, 'kl': 0.021385659, 'entropy': 7.8691926, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:39,539\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.08724837, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.021561466, 'entropy': 7.8681974, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:42,137\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014264.0, 'policy_loss': -0.08799888, 'vf_loss': 44014264.0, 'vf_explained_var': 0.0, 'kl': 0.021862645, 'entropy': 7.8670835, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:44,699\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 44014260.0, 'policy_loss': -0.08853279, 'vf_loss': 44014260.0, 'vf_explained_var': 0.0, 'kl': 0.021517266, 'entropy': 7.8675756, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:44,739\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 21731}\n",
            "2020-03-19 07:59:44,781\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 07:59:44,783\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,786\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,788\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,789\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,791\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,794\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,796\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,797\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,798\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,800\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,801\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,804\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,806\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,807\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,809\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,811\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 07:59:44,816\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_07-59-44\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 31\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78018.323\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.30000001192092896\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.867575645446777\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.02151726558804512\n",
            "      policy_loss: -0.08853279054164886\n",
            "      total_loss: 44014260.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 44014260.0\n",
            "  load_time_ms: 92.757\n",
            "  num_steps_sampled: 21731\n",
            "  num_steps_trained: 19840\n",
            "  sample_time_ms: 38953.712\n",
            "  update_time_ms: 1004.438\n",
            "iterations_since_restore: 2\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.46666666666665\n",
            "  ram_util_percent: 16.59999999999999\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 13713.0\n",
            "  policy_1: 15304.0\n",
            "  policy_2: -4770.0\n",
            "  policy_3: 14625.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 467.5\n",
            "  policy_1: 9113.5\n",
            "  policy_2: -7720.5\n",
            "  policy_3: -1860.5\n",
            "policy_reward_min:\n",
            "  policy_0: -12778.0\n",
            "  policy_1: 2923.0\n",
            "  policy_2: -10671.0\n",
            "  policy_3: -18346.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 100.23798460294718\n",
            "  mean_inference_ms: 8.062010477071475\n",
            "  mean_processing_ms: 2.592512005754346\n",
            "time_since_restore: 236.29362893104553\n",
            "time_this_iter_s: 77.24801802635193\n",
            "time_total_s: 3296.7200062274933\n",
            "timestamp: 1584604784\n",
            "timesteps_since_restore: 1402\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 21731\n",
            "training_iteration: 31\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 07:59:47,387\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': 0.0202053, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.019114908, 'entropy': 7.8755827, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:49,958\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.0009257272, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.018304283, 'entropy': 7.875163, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:52,503\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.014823252, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.017951032, 'entropy': 7.896291, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:55,055\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.02156127, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.018326256, 'entropy': 7.901784, 'entropy_coeff': 0.0}\n",
            "2020-03-19 07:59:57,668\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.031050092, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.018699287, 'entropy': 7.8981056, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:00,208\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.041139178, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.020194445, 'entropy': 7.9025507, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:02,771\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.047733564, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.020115498, 'entropy': 7.9079285, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:05,348\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.05485292, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.020543156, 'entropy': 7.911836, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:07,880\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.06156317, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.021786924, 'entropy': 7.9117174, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:10,457\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.06812172, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.022437822, 'entropy': 7.9152975, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:13,012\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820060.0, 'policy_loss': -0.071885124, 'vf_loss': 386820060.0, 'vf_explained_var': 0.0, 'kl': 0.023841295, 'entropy': 7.924208, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:15,561\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.07652343, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.024107259, 'entropy': 7.931657, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:18,122\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820060.0, 'policy_loss': -0.08210339, 'vf_loss': 386820060.0, 'vf_explained_var': 0.0, 'kl': 0.02462614, 'entropy': 7.93219, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:20,683\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820060.0, 'policy_loss': -0.08517955, 'vf_loss': 386820060.0, 'vf_explained_var': 0.0, 'kl': 0.024594907, 'entropy': 7.927447, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:23,267\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.085327946, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.024759972, 'entropy': 7.93049, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:25,858\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.089137465, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.024950657, 'entropy': 7.9277544, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:28,425\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.092218205, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.025209386, 'entropy': 7.925267, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:31,040\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.09508209, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.025062496, 'entropy': 7.9237146, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:33,649\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.09698288, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.02511521, 'entropy': 7.922806, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:36,281\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.09905962, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.02547161, 'entropy': 7.918914, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:38,880\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.10240351, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.024959993, 'entropy': 7.9164786, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:41,524\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.10417046, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.024241706, 'entropy': 7.9158936, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:44,187\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.10808562, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.025048101, 'entropy': 7.9219465, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:46,863\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820060.0, 'policy_loss': -0.109887384, 'vf_loss': 386820060.0, 'vf_explained_var': 0.0, 'kl': 0.025598073, 'entropy': 7.9257417, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:49,480\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820060.0, 'policy_loss': -0.111708894, 'vf_loss': 386820060.0, 'vf_explained_var': 0.0, 'kl': 0.026365656, 'entropy': 7.9288163, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:52,143\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820060.0, 'policy_loss': -0.1125959, 'vf_loss': 386820060.0, 'vf_explained_var': 0.0, 'kl': 0.026140574, 'entropy': 7.9240556, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:54,805\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.11112785, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.025433412, 'entropy': 7.920677, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:00:57,469\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.11265238, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.025859777, 'entropy': 7.9221573, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:00,164\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.11498459, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.026448404, 'entropy': 7.9226317, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:02,840\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.44999998807907104, 'cur_lr': 4.999999873689376e-05, 'total_loss': 386820100.0, 'policy_loss': -0.11607273, 'vf_loss': 386820100.0, 'vf_explained_var': 0.0, 'kl': 0.02657346, 'entropy': 7.9236364, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:02,883\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 22432}\n",
            "2020-03-19 08:01:02,923\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:01:02,927\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.227, max=11.0, mean=1.65),\n",
            "              np.ndarray((701,), dtype=float32, min=-11676.0, max=16473.0, mean=47.583),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2947.0, max=3345.0, mean=11.69),\n",
            "              np.ndarray((701,), dtype=float32, min=-15.81, max=-6.51, mean=-7.861),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.227, max=11.0, mean=1.652),\n",
            "              np.ndarray((701,), dtype=float32, min=-0.71, max=6.915, mean=-0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.873, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2947.0, max=3345.0, mean=11.69),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.227, max=11.0, mean=1.65),\n",
            "              np.ndarray((701,), dtype=float32, min=-11676.0, max=16473.0, mean=47.583),\n",
            "              np.ndarray((701,), dtype=float32, min=-2144.67, max=29399.814, mean=794.576),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:01:02,929\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:01:02,935\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-01-02\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 32\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78020.689\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.44999998807907104\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.923636436462402\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.026573460549116135\n",
            "      policy_loss: -0.11607272922992706\n",
            "      total_loss: 386820096.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 386820096.0\n",
            "  load_time_ms: 72.731\n",
            "  num_steps_sampled: 22432\n",
            "  num_steps_trained: 20480\n",
            "  sample_time_ms: 25975.872\n",
            "  update_time_ms: 676.315\n",
            "iterations_since_restore: 3\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.70720720720722\n",
            "  ram_util_percent: 16.7\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 15304.0\n",
            "  policy_2: 7681.0\n",
            "  policy_3: 14625.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 43180.666666666664\n",
            "  policy_1: -9770.0\n",
            "  policy_2: -2586.6666666666665\n",
            "  policy_3: -30824.0\n",
            "policy_reward_min:\n",
            "  policy_0: -12778.0\n",
            "  policy_1: -47537.0\n",
            "  policy_2: -10671.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 100.23798460294718\n",
            "  mean_inference_ms: 8.062010477071475\n",
            "  mean_processing_ms: 2.592512005754346\n",
            "time_since_restore: 314.4010155200958\n",
            "time_this_iter_s: 78.1073865890503\n",
            "time_total_s: 3374.8273928165436\n",
            "timestamp: 1584604862\n",
            "timesteps_since_restore: 2103\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 22432\n",
            "training_iteration: 32\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:01:05,565\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.019454587, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.026360055, 'entropy': 7.93011, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:08,166\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.037374903, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.022316437, 'entropy': 7.90038, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:10,810\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.044678174, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.020008132, 'entropy': 7.8777285, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:13,387\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.053796798, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.018684845, 'entropy': 7.8702393, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:16,007\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.06015402, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.0175549, 'entropy': 7.8640532, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:18,664\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.06431059, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.01736431, 'entropy': 7.870375, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:21,209\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.07049419, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.01729231, 'entropy': 7.8605347, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:23,810\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.072775386, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.0166244, 'entropy': 7.8581047, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:26,394\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.072469465, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.01613392, 'entropy': 7.8646955, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:28,981\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.0773307, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.01603059, 'entropy': 7.868647, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:31,598\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.0770265, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.01552064, 'entropy': 7.868811, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:34,190\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.07824217, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.015636453, 'entropy': 7.8710756, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:36,806\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08034904, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.015507966, 'entropy': 7.8814774, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:39,424\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.080670685, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.014695841, 'entropy': 7.882422, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:42,030\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08173402, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.0144069195, 'entropy': 7.883757, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:44,625\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08171437, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.013958469, 'entropy': 7.883138, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:47,303\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.0835484, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.014022997, 'entropy': 7.8818865, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:49,982\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08461778, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.01425573, 'entropy': 7.8845305, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:52,603\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08534355, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.014159953, 'entropy': 7.8866425, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:55,211\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08630807, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.013918124, 'entropy': 7.887639, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:01:57,873\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.085922465, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.013560337, 'entropy': 7.882039, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:02:00,503\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08633017, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.013589529, 'entropy': 7.8839273, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:02:03,153\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.086181715, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.013569224, 'entropy': 7.885604, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:02:05,766\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08655493, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.013378903, 'entropy': 7.885263, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:02:08,482\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08743029, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.013244281, 'entropy': 7.8816895, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:02:11,132\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.088059135, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.01306014, 'entropy': 7.88281, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:02:13,749\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.088288926, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.01291277, 'entropy': 7.8843665, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:02:16,427\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08890216, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.012877325, 'entropy': 7.8806467, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:02:19,073\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.089179896, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.012689568, 'entropy': 7.879599, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:02:21,778\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 19377280.0, 'policy_loss': -0.08991804, 'vf_loss': 19377280.0, 'vf_explained_var': 0.0, 'kl': 0.012726242, 'entropy': 7.882234, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:02:21,900\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 23133}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-02-21\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 33\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78226.561\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.675000011920929\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.8822340965271\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.01272624172270298\n",
            "      policy_loss: -0.08991803973913193\n",
            "      total_loss: 19377280.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 19377280.0\n",
            "  load_time_ms: 57.414\n",
            "  num_steps_sampled: 23133\n",
            "  num_steps_trained: 21120\n",
            "  sample_time_ms: 19485.868\n",
            "  update_time_ms: 512.079\n",
            "iterations_since_restore: 4\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.79823008849559\n",
            "  ram_util_percent: 16.800000000000004\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 15304.0\n",
            "  policy_2: 7681.0\n",
            "  policy_3: 14625.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 40724.5\n",
            "  policy_1: -14787.75\n",
            "  policy_2: -5099.0\n",
            "  policy_3: -20837.75\n",
            "policy_reward_min:\n",
            "  policy_0: -12778.0\n",
            "  policy_1: -47537.0\n",
            "  policy_2: -12636.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 100.23798460294718\n",
            "  mean_inference_ms: 8.062010477071475\n",
            "  mean_processing_ms: 2.592512005754346\n",
            "time_since_restore: 393.30018973350525\n",
            "time_this_iter_s: 78.89917421340942\n",
            "time_total_s: 3453.726567029953\n",
            "timestamp: 1584604941\n",
            "timesteps_since_restore: 2804\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 23133\n",
            "training_iteration: 33\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_33/checkpoint-33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:03:41,625\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:03:41,627\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,631\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,633\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,639\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,640\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,643\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,645\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,646\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,647\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,648\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,649\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,650\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,651\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,652\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,653\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,655\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:03:41,664\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n",
            "2020-03-19 08:03:44,311\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.012826231, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.019896014, 'entropy': 7.877084, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:03:46,932\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.029751647, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.013941169, 'entropy': 7.865161, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:03:49,579\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.036848083, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.010727243, 'entropy': 7.8496375, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:03:52,194\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.045100052, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.010708061, 'entropy': 7.8440924, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:03:54,826\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.055481803, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.011529939, 'entropy': 7.8479614, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:03:57,512\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.0631832, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.011314946, 'entropy': 7.8475733, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:00,163\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.069054164, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.011456853, 'entropy': 7.843947, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:02,801\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.07307635, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.011251809, 'entropy': 7.840911, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:05,457\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.07380857, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.010748034, 'entropy': 7.839553, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:08,090\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.07609161, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.011213824, 'entropy': 7.843627, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:10,698\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.07798855, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.0115608, 'entropy': 7.841243, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:13,297\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.08050128, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.011313129, 'entropy': 7.8396363, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:15,899\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.08061101, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.011533185, 'entropy': 7.840844, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:18,485\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.083629526, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.0119004445, 'entropy': 7.839769, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:21,080\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.08546483, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.011559231, 'entropy': 7.837474, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:23,636\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.086676605, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.011214756, 'entropy': 7.8375487, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:26,169\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.08696618, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.0112337945, 'entropy': 7.8377066, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:28,709\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.088711485, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.011287345, 'entropy': 7.837767, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:31,287\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.0896915, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.0113050025, 'entropy': 7.838042, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:33,888\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.09040294, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.011287302, 'entropy': 7.8380218, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:36,535\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.09109068, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.01131715, 'entropy': 7.8375144, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:39,196\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.0915256, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.011503079, 'entropy': 7.838146, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:41,835\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.09159783, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.01140536, 'entropy': 7.83846, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:44,491\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.09237262, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.01130452, 'entropy': 7.8403015, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:47,122\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.09293988, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.011443714, 'entropy': 7.8426743, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:49,754\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.09314032, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.011426067, 'entropy': 7.843093, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:52,442\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.09379367, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.011563324, 'entropy': 7.84307, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:55,154\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.09439161, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.011684351, 'entropy': 7.842921, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:04:57,813\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049740.0, 'policy_loss': -0.09446438, 'vf_loss': 66049740.0, 'vf_explained_var': 0.0, 'kl': 0.011546882, 'entropy': 7.842508, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:00,476\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 66049736.0, 'policy_loss': -0.09506279, 'vf_loss': 66049736.0, 'vf_explained_var': 0.0, 'kl': 0.011779299, 'entropy': 7.843354, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:00,517\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 23834}\n",
            "2020-03-19 08:05:00,553\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:05:00,557\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.04, max=11.0, mean=1.541),\n",
            "              np.ndarray((701,), dtype=float32, min=-5432.0, max=5685.0, mean=0.827),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3365.0, max=2717.0, mean=-38.879),\n",
            "              np.ndarray((701,), dtype=float32, min=-13.871, max=-6.35, mean=-7.746),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.04, max=11.0, mean=1.541),\n",
            "              np.ndarray((701,), dtype=float32, min=-2.572, max=4.707, mean=0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.937, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3365.0, max=2717.0, mean=-38.879),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.04, max=11.0, mean=1.541),\n",
            "              np.ndarray((701,), dtype=float32, min=-5432.0, max=5685.0, mean=0.827),\n",
            "              np.ndarray((701,), dtype=float32, min=-3701.475, max=6661.54, mean=-39.701),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:05:00,559\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:05:00,565\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-05-00\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 34\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78343.883\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.675000011920929\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.843354225158691\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.01177929900586605\n",
            "      policy_loss: -0.09506279230117798\n",
            "      total_loss: 66049736.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 66049736.0\n",
            "  load_time_ms: 53.205\n",
            "  num_steps_sampled: 23834\n",
            "  num_steps_trained: 21760\n",
            "  sample_time_ms: 31529.595\n",
            "  update_time_ms: 413.121\n",
            "iterations_since_restore: 5\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 77.41592920353982\n",
            "  ram_util_percent: 17.09911504424778\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 15304.0\n",
            "  policy_2: 7681.0\n",
            "  policy_3: 14625.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 45151.0\n",
            "  policy_1: -24213.6\n",
            "  policy_2: -6984.0\n",
            "  policy_3: -13953.4\n",
            "policy_reward_min:\n",
            "  policy_0: -12778.0\n",
            "  policy_1: -61917.0\n",
            "  policy_2: -14524.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 100.53283200229689\n",
            "  mean_inference_ms: 8.028811548877151\n",
            "  mean_processing_ms: 2.605848586520104\n",
            "time_since_restore: 551.8792579174042\n",
            "time_this_iter_s: 158.57906818389893\n",
            "time_total_s: 3612.305635213852\n",
            "timestamp: 1584605100\n",
            "timesteps_since_restore: 3505\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 23834\n",
            "training_iteration: 34\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:05:03,216\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.6, 'policy_loss': 0.0036339473, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.012216893, 'entropy': 7.8294554, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:05,875\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.013700339, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.0072521544, 'entropy': 7.7860136, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:08,536\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.6, 'policy_loss': -0.022161266, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.0065895454, 'entropy': 7.7798223, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:11,205\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.028015679, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.006463769, 'entropy': 7.7832766, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:13,878\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.03278494, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.0069383355, 'entropy': 7.78507, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:16,535\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.038113005, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.0068071582, 'entropy': 7.7896013, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:19,203\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.038509075, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.006367074, 'entropy': 7.786126, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:21,878\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.043487657, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.0066140383, 'entropy': 7.787394, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:24,541\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.046651028, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.0069247363, 'entropy': 7.7867584, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:27,214\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.049764812, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.0070188744, 'entropy': 7.7857423, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:29,817\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.05149162, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.0075889146, 'entropy': 7.790325, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:32,461\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.05299322, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.007606458, 'entropy': 7.7930174, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:35,122\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.6, 'policy_loss': -0.056336164, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.007710869, 'entropy': 7.7926164, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:37,777\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.05841761, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.008009288, 'entropy': 7.793167, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:40,422\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.060643263, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.00829169, 'entropy': 7.7947907, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:43,046\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.6, 'policy_loss': -0.06282584, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.008288008, 'entropy': 7.796457, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:45,686\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.06336348, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.008371925, 'entropy': 7.7969017, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:48,306\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.0659839, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.008849904, 'entropy': 7.7974253, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:50,945\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.06800616, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.008865241, 'entropy': 7.79711, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:53,608\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.06845708, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.0087902695, 'entropy': 7.7974653, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:56,293\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.0701516, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.009161681, 'entropy': 7.7983246, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:05:58,897\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.0712255, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.009194495, 'entropy': 7.797845, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:01,544\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.07146935, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.0091883205, 'entropy': 7.7972145, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:04,151\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.07047948, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.008705032, 'entropy': 7.7949576, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:06,768\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.07155988, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.008725182, 'entropy': 7.796111, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:09,391\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.0728422, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.009650251, 'entropy': 7.8025017, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:12,000\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.07197041, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.010595137, 'entropy': 7.8086076, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:14,626\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.07334629, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.010227644, 'entropy': 7.804971, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:17,291\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.07548763, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.010418666, 'entropy': 7.803401, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:19,936\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 2016908.4, 'policy_loss': -0.07592215, 'vf_loss': 2016908.4, 'vf_explained_var': 0.0, 'kl': 0.010201131, 'entropy': 7.802002, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:19,984\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 24535}\n",
            "2020-03-19 08:06:20,028\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:06:20,029\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,031\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,032\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,035\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,036\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,038\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,040\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,042\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,043\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,045\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,047\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,049\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,051\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,052\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,054\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,056\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:06:20,063\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-06-19\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 35\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78515.328\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.675000011920929\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.802001953125\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.010201130993664265\n",
            "      policy_loss: -0.07592214643955231\n",
            "      total_loss: 2016908.375\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 2016908.375\n",
            "  load_time_ms: 46.066\n",
            "  num_steps_sampled: 24535\n",
            "  num_steps_trained: 22400\n",
            "  sample_time_ms: 26277.395\n",
            "  update_time_ms: 347.462\n",
            "iterations_since_restore: 6\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.9300884955752\n",
            "  ram_util_percent: 17.230088495575217\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 15304.0\n",
            "  policy_2: 7681.0\n",
            "  policy_3: 14625.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 37722.5\n",
            "  policy_1: -19251.666666666668\n",
            "  policy_2: -6181.833333333333\n",
            "  policy_3: -12289.0\n",
            "policy_reward_min:\n",
            "  policy_0: -12778.0\n",
            "  policy_1: -61917.0\n",
            "  policy_2: -14524.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 100.7293969351967\n",
            "  mean_inference_ms: 8.006678930080936\n",
            "  mean_processing_ms: 2.614739640363943\n",
            "time_since_restore: 631.306079864502\n",
            "time_this_iter_s: 79.42682194709778\n",
            "time_total_s: 3691.7324571609497\n",
            "timestamp: 1584605179\n",
            "timesteps_since_restore: 4206\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 24535\n",
            "training_iteration: 35\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:06:22,748\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.0, 'policy_loss': -0.0073422743, 'vf_loss': 7977289.0, 'vf_explained_var': 0.0, 'kl': 0.009117768, 'entropy': 7.793579, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:25,419\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.018997353, 'vf_loss': 7977289.0, 'vf_explained_var': 0.0, 'kl': 0.008179818, 'entropy': 7.7844415, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:28,010\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.028338963, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.008176775, 'entropy': 7.783399, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:30,638\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.03241187, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.008405371, 'entropy': 7.7896624, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:33,265\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.040449552, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.011093628, 'entropy': 7.8056183, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:35,897\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.0, 'policy_loss': -0.04393492, 'vf_loss': 7977289.0, 'vf_explained_var': 0.0, 'kl': 0.013084663, 'entropy': 7.813842, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:38,535\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.046671215, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.011896902, 'entropy': 7.8078423, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:41,189\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.050512873, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.009919189, 'entropy': 7.799534, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:43,824\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.0, 'policy_loss': -0.054360885, 'vf_loss': 7977289.0, 'vf_explained_var': 0.0, 'kl': 0.011035599, 'entropy': 7.8021073, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:46,491\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.0, 'policy_loss': -0.051491804, 'vf_loss': 7977289.0, 'vf_explained_var': 0.0, 'kl': 0.008720101, 'entropy': 7.791345, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:49,140\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.05753358, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.01092636, 'entropy': 7.79888, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:51,798\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.0, 'policy_loss': -0.059759386, 'vf_loss': 7977289.0, 'vf_explained_var': 0.0, 'kl': 0.010988062, 'entropy': 7.801671, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:54,412\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.0, 'policy_loss': -0.061417125, 'vf_loss': 7977289.0, 'vf_explained_var': 0.0, 'kl': 0.010762185, 'entropy': 7.8008323, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:57,038\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.06349354, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.0112456065, 'entropy': 7.8028183, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:06:59,693\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.06619005, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.011484162, 'entropy': 7.802658, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:02,362\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.06863402, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.011489208, 'entropy': 7.80272, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:05,023\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.07005005, 'vf_loss': 7977289.0, 'vf_explained_var': 0.0, 'kl': 0.01143804, 'entropy': 7.8032036, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:07,728\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.06977383, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.0108281, 'entropy': 7.801188, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:10,375\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.07151098, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.011411208, 'entropy': 7.801898, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:13,027\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.07342769, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.011858643, 'entropy': 7.802848, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:15,684\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.07471353, 'vf_loss': 7977289.0, 'vf_explained_var': 0.0, 'kl': 0.0120068, 'entropy': 7.8041296, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:18,352\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.0754046, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.012364882, 'entropy': 7.8029737, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:20,984\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.07727835, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.012414274, 'entropy': 7.803108, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:23,628\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.0767856, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.012372458, 'entropy': 7.8035126, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:26,326\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.07742002, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.012647396, 'entropy': 7.804667, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:28,972\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.07767819, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.012743568, 'entropy': 7.8054733, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:31,623\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.078887336, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.013255736, 'entropy': 7.8059816, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:34,240\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.0789353, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.012764384, 'entropy': 7.804445, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:36,912\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.0, 'policy_loss': -0.07976453, 'vf_loss': 7977289.0, 'vf_explained_var': 0.0, 'kl': 0.012692983, 'entropy': 7.80365, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:39,613\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 7977289.5, 'policy_loss': -0.080249354, 'vf_loss': 7977289.5, 'vf_explained_var': 0.0, 'kl': 0.012971622, 'entropy': 7.8045907, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:39,718\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 25236}\n",
            "2020-03-19 08:07:39,757\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:07:39,762\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.641, max=11.0, mean=1.593),\n",
            "              np.ndarray((701,), dtype=float32, min=-100405.0, max=100405.0, mean=-104.883),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2652.0, max=3338.0, mean=23.711),\n",
            "              np.ndarray((701,), dtype=float32, min=-14.72, max=-6.361, mean=-7.774),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.641, max=11.0, mean=1.597),\n",
            "              np.ndarray((701,), dtype=float32, min=-4.904, max=1.885, mean=-0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.958, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2652.0, max=3338.0, mean=23.711),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.641, max=11.0, mean=1.593),\n",
            "              np.ndarray((701,), dtype=float32, min=-100405.0, max=100405.0, mean=-104.883),\n",
            "              np.ndarray((701,), dtype=float32, min=-109302.617, max=33564.137, mean=-6108.785),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:07:39,764\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:07:39,767\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-07-39\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 36\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78663.347\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.675000011920929\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.804590702056885\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.012971621938049793\n",
            "      policy_loss: -0.0802493542432785\n",
            "      total_loss: 7977289.5\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 7977289.5\n",
            "  load_time_ms: 44.356\n",
            "  num_steps_sampled: 25236\n",
            "  num_steps_trained: 23040\n",
            "  sample_time_ms: 22526.259\n",
            "  update_time_ms: 300.811\n",
            "iterations_since_restore: 7\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.77456140350877\n",
            "  ram_util_percent: 17.300000000000004\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 15304.0\n",
            "  policy_2: 7681.0\n",
            "  policy_3: 14625.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 34145.57142857143\n",
            "  policy_1: -16876.428571428572\n",
            "  policy_2: -4261.142857142857\n",
            "  policy_3: -13008.0\n",
            "policy_reward_min:\n",
            "  policy_0: -12778.0\n",
            "  policy_1: -61917.0\n",
            "  policy_2: -14524.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 100.86980045869657\n",
            "  mean_inference_ms: 7.9908699166550665\n",
            "  mean_processing_ms: 2.6210903931095424\n",
            "time_since_restore: 710.9405303001404\n",
            "time_this_iter_s: 79.63445043563843\n",
            "time_total_s: 3771.366907596588\n",
            "timestamp: 1584605259\n",
            "timesteps_since_restore: 4907\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 25236\n",
            "training_iteration: 36\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_36/checkpoint-36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:07:42,481\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': 0.010329889, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.011420257, 'entropy': 7.8162575, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:45,194\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.0075361123, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.006000401, 'entropy': 7.7978578, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:47,894\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.018078428, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.0046164775, 'entropy': 7.776094, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:50,577\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.023529176, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.0051697684, 'entropy': 7.7713385, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:53,295\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.028190618, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.0054773367, 'entropy': 7.775412, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:56,027\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.032582074, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.0057649105, 'entropy': 7.777131, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:07:58,759\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.03539866, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.0057339985, 'entropy': 7.775995, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:01,520\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.037706025, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.005724299, 'entropy': 7.77705, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:04,185\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.040888067, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.005761781, 'entropy': 7.778987, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:06,847\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.042844765, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.0057075033, 'entropy': 7.7791457, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:09,544\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.04582295, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.0059646936, 'entropy': 7.7811522, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:12,211\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.04810375, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.0064553237, 'entropy': 7.7841873, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:14,824\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.050052203, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.007190092, 'entropy': 7.7880554, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:17,491\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.052147627, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.0073940856, 'entropy': 7.7878737, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:20,147\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.05443118, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.008044824, 'entropy': 7.791171, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:22,828\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.05507667, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.007853783, 'entropy': 7.7911696, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:25,542\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.05643747, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.007981244, 'entropy': 7.790283, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:28,216\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.05760637, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.008377692, 'entropy': 7.7925463, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:30,906\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.05946105, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.009851885, 'entropy': 7.804273, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:33,618\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.060886286, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.009479205, 'entropy': 7.803045, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:36,274\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.061471738, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.009163221, 'entropy': 7.7993836, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:38,964\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.06077876, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.008870388, 'entropy': 7.797087, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:41,642\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.06264307, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.00966545, 'entropy': 7.8006644, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:44,294\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.06400594, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.009436136, 'entropy': 7.7980742, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:46,989\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.06480153, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.009516811, 'entropy': 7.7980475, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:49,694\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.06608792, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.009840222, 'entropy': 7.8001885, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:52,359\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.06702562, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.009682408, 'entropy': 7.7979293, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:55,007\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.06855388, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.0100755235, 'entropy': 7.798027, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:08:57,695\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.06950219, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.010082036, 'entropy': 7.796954, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:09:00,367\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 465797120.0, 'policy_loss': -0.07004827, 'vf_loss': 465797120.0, 'vf_explained_var': 0.0, 'kl': 0.009653293, 'entropy': 7.7962737, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:09:00,417\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 25937}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-09-00\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 37\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78905.681\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.675000011920929\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.796273708343506\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.00965329259634018\n",
            "      policy_loss: -0.0700482726097107\n",
            "      total_loss: 465797120.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 465797120.0\n",
            "  load_time_ms: 39.791\n",
            "  num_steps_sampled: 25937\n",
            "  num_steps_trained: 23680\n",
            "  sample_time_ms: 19712.517\n",
            "  update_time_ms: 265.936\n",
            "iterations_since_restore: 8\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.76695652173913\n",
            "  ram_util_percent: 17.400000000000006\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 40708.0\n",
            "  policy_2: 11736.0\n",
            "  policy_3: 21079.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 20687.0\n",
            "  policy_1: -9678.375\n",
            "  policy_2: -2261.5\n",
            "  policy_3: -8747.125\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -61917.0\n",
            "  policy_2: -14524.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 100.97510310132148\n",
            "  mean_inference_ms: 7.979013156585665\n",
            "  mean_processing_ms: 2.6258534576687413\n",
            "time_since_restore: 791.5958573818207\n",
            "time_this_iter_s: 80.6553270816803\n",
            "time_total_s: 3852.0222346782684\n",
            "timestamp: 1584605340\n",
            "timesteps_since_restore: 5608\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 25937\n",
            "training_iteration: 37\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:10:19,574\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:10:19,576\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,577\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,578\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,578\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,579\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,580\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,581\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,582\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,583\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,584\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,585\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,586\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,587\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,588\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,589\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,590\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:10:19,593\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n",
            "2020-03-19 08:10:22,283\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.016363917, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.007855988, 'entropy': 7.793025, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:24,960\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.02881012, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.0065063895, 'entropy': 7.773164, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:27,586\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.033992875, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.006353639, 'entropy': 7.7679825, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:30,213\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.04141168, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.0065667317, 'entropy': 7.7775726, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:32,847\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.0470424, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.00711953, 'entropy': 7.7834587, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:35,517\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.049297616, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.00750463, 'entropy': 7.7813997, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:38,153\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.052985586, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.0072843386, 'entropy': 7.777063, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:40,828\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.05627529, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.0072963377, 'entropy': 7.779414, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:43,506\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.058359414, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.007467015, 'entropy': 7.779898, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:46,208\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.06026872, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.007466755, 'entropy': 7.781494, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:48,836\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.063229986, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.0076893494, 'entropy': 7.785666, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:51,484\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.06503908, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.007596641, 'entropy': 7.786335, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:54,124\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.06621291, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.0073234616, 'entropy': 7.788493, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:56,797\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.06729178, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.007671675, 'entropy': 7.795083, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:10:59,398\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.06833756, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.007917991, 'entropy': 7.799985, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:02,050\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.06888833, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.007925717, 'entropy': 7.8036523, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:04,717\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.06969809, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.0074492516, 'entropy': 7.798527, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:07,336\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.07097862, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.007414994, 'entropy': 7.800097, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:09,988\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.07215796, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.007659875, 'entropy': 7.7997375, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:12,635\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.07306024, 'vf_loss': 5800195.0, 'vf_explained_var': 0.0, 'kl': 0.007322237, 'entropy': 7.7959366, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:15,288\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.07330885, 'vf_loss': 5800195.0, 'vf_explained_var': 0.0, 'kl': 0.0073681264, 'entropy': 7.795961, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:17,885\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.0747627, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.007643029, 'entropy': 7.798818, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:20,501\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.075708635, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.0075012133, 'entropy': 7.7984977, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:23,186\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.07664235, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.007429508, 'entropy': 7.798085, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:25,853\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.07684332, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.0073259906, 'entropy': 7.7988825, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:28,545\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.07727626, 'vf_loss': 5800196.0, 'vf_explained_var': 0.0, 'kl': 0.007758335, 'entropy': 7.80293, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:31,170\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.078019455, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.007850449, 'entropy': 7.8025217, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:33,812\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.077762716, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.007823816, 'entropy': 7.8017335, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:36,486\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800196.0, 'policy_loss': -0.07840635, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.0077974014, 'entropy': 7.8023844, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:39,190\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5800195.5, 'policy_loss': -0.07860682, 'vf_loss': 5800195.5, 'vf_explained_var': 0.0, 'kl': 0.008046375, 'entropy': 7.8046556, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:39,238\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 26638}\n",
            "2020-03-19 08:11:39,279\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:11:39,284\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.541, max=11.0, mean=1.599),\n",
            "              np.ndarray((701,), dtype=float32, min=-19206.0, max=17237.0, mean=-2.596),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2574.0, max=3165.0, mean=-0.75),\n",
            "              np.ndarray((701,), dtype=float32, min=-15.273, max=-6.323, mean=-7.854),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.541, max=11.0, mean=1.601),\n",
            "              np.ndarray((701,), dtype=float32, min=-3.596, max=1.987, mean=0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.972, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2574.0, max=3165.0, mean=-0.75),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.541, max=11.0, mean=1.599),\n",
            "              np.ndarray((701,), dtype=float32, min=-19206.0, max=17237.0, mean=-2.596),\n",
            "              np.ndarray((701,), dtype=float32, min=-13694.566, max=7720.485, mean=98.554),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:11:39,286\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:11:39,289\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-11-39\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 38\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78982.782\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.675000011920929\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.8046555519104\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.008046374656260014\n",
            "      policy_loss: -0.07860682159662247\n",
            "      total_loss: 5800195.5\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 5800195.5\n",
            "  load_time_ms: 37.342\n",
            "  num_steps_sampled: 26638\n",
            "  num_steps_trained: 24320\n",
            "  sample_time_ms: 26315.255\n",
            "  update_time_ms: 238.677\n",
            "iterations_since_restore: 9\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 77.49030837004406\n",
            "  ram_util_percent: 17.762114537444933\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 40708.0\n",
            "  policy_2: 11736.0\n",
            "  policy_3: 21079.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 19079.777777777777\n",
            "  policy_1: -8688.333333333334\n",
            "  policy_2: -3939.0\n",
            "  policy_3: -6452.444444444444\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -61917.0\n",
            "  policy_2: -17359.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.08621865329651\n",
            "  mean_inference_ms: 7.9597753494871295\n",
            "  mean_processing_ms: 2.6314759660948375\n",
            "time_since_restore: 950.3787889480591\n",
            "time_this_iter_s: 158.7829315662384\n",
            "time_total_s: 4010.805166244507\n",
            "timestamp: 1584605499\n",
            "timesteps_since_restore: 6309\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 26638\n",
            "training_iteration: 38\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:11:41,937\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453640.0, 'policy_loss': -0.003817226, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.008973213, 'entropy': 7.8121734, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:44,621\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.01525601, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.005230055, 'entropy': 7.783909, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:47,268\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.01898318, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.003899961, 'entropy': 7.7694106, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:49,885\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.024212468, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.004172084, 'entropy': 7.7694983, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:52,547\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453640.0, 'policy_loss': -0.03280987, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.006026556, 'entropy': 7.7784996, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:55,202\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.036966488, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.006107648, 'entropy': 7.782805, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:11:57,910\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453640.0, 'policy_loss': -0.039193742, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.006731647, 'entropy': 7.785693, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:00,570\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.044764616, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.0069039417, 'entropy': 7.7836747, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:03,220\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.047957975, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.007658951, 'entropy': 7.786386, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:05,838\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.04963366, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.007545563, 'entropy': 7.7877984, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:08,501\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453640.0, 'policy_loss': -0.05290123, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.00829238, 'entropy': 7.7909575, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:11,154\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.054573126, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.008503745, 'entropy': 7.7924776, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:13,832\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.055496603, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.008039993, 'entropy': 7.790357, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:16,452\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.058240086, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.008631552, 'entropy': 7.794492, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:19,106\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.05865013, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.0094126575, 'entropy': 7.7989073, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:21,734\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453640.0, 'policy_loss': -0.05943075, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.008943848, 'entropy': 7.7953043, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:24,447\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.060629793, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.008759305, 'entropy': 7.7933173, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:27,069\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.06228172, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.009223488, 'entropy': 7.7950716, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:29,702\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.06375947, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.009478564, 'entropy': 7.795273, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:32,299\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453640.0, 'policy_loss': -0.065292396, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.009627318, 'entropy': 7.7960663, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:34,904\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.06665775, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.009958284, 'entropy': 7.798841, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:37,518\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453640.0, 'policy_loss': -0.06801178, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.010123645, 'entropy': 7.798215, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:40,164\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.0685762, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.010284221, 'entropy': 7.798108, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:42,855\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.068705775, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.009816544, 'entropy': 7.796205, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:45,450\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453640.0, 'policy_loss': -0.069464624, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.010107425, 'entropy': 7.7978225, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:48,093\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453640.0, 'policy_loss': -0.07068485, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.010440317, 'entropy': 7.7989144, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:50,678\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453640.0, 'policy_loss': -0.071524434, 'vf_loss': 14453640.0, 'vf_explained_var': 0.0, 'kl': 0.010495733, 'entropy': 7.7982802, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:53,299\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.072316036, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.011044903, 'entropy': 7.799978, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:55,917\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.07271442, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.010645269, 'entropy': 7.7976127, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:58,550\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 14453638.0, 'policy_loss': -0.072761334, 'vf_loss': 14453638.0, 'vf_explained_var': 0.0, 'kl': 0.011507502, 'entropy': 7.8010406, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:12:58,651\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 27339}\n",
            "2020-03-19 08:12:58,695\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:12:58,697\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,697\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,700\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,700\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,702\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,702\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,703\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,704\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,705\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,706\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,707\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,708\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,709\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,710\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,710\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,711\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:12:58,714\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-12-58\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 39\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 79010.709\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.675000011920929\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.8010406494140625\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.01150750182569027\n",
            "      policy_loss: -0.07276133447885513\n",
            "      total_loss: 14453638.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 14453638.0\n",
            "  load_time_ms: 34.482\n",
            "  num_steps_sampled: 27339\n",
            "  num_steps_trained: 24960\n",
            "  sample_time_ms: 23685.367\n",
            "  update_time_ms: 217.201\n",
            "iterations_since_restore: 10\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.68407079646018\n",
            "  ram_util_percent: 17.90088495575222\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 40708.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 16989.8\n",
            "  policy_1: -18919.0\n",
            "  policy_2: 3166.4\n",
            "  policy_3: -1237.2\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -17359.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.17511109487654\n",
            "  mean_inference_ms: 7.944385103808303\n",
            "  mean_processing_ms: 2.6359739728357137\n",
            "time_since_restore: 1029.6989629268646\n",
            "time_this_iter_s: 79.32017397880554\n",
            "time_total_s: 4090.1253402233124\n",
            "timestamp: 1584605578\n",
            "timesteps_since_restore: 7010\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 27339\n",
            "training_iteration: 39\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_39/checkpoint-39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:13:01,391\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': 0.01271175, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.008063286, 'entropy': 7.7931366, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:04,098\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.008268451, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0031562995, 'entropy': 7.7639527, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:06,828\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.012903045, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0017027734, 'entropy': 7.7436905, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:09,546\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.015908295, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0016607639, 'entropy': 7.7382255, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:12,198\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.019317258, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0018493601, 'entropy': 7.7415876, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:14,841\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.022951476, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.002083982, 'entropy': 7.745865, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:17,462\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.025514781, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0024138526, 'entropy': 7.7516, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:20,039\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.028421333, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0027363878, 'entropy': 7.753714, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:22,651\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.03167167, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0028581764, 'entropy': 7.752098, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:25,254\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.033702563, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.00296957, 'entropy': 7.7517257, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:27,821\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.03568413, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0033378776, 'entropy': 7.7552605, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:30,458\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.03642111, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0031172107, 'entropy': 7.7539263, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:33,106\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.0374545, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0031393352, 'entropy': 7.75327, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:35,747\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.03860023, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0033053993, 'entropy': 7.7543693, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:38,350\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.03958694, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0034374266, 'entropy': 7.7545776, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:40,991\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.040626157, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.003693904, 'entropy': 7.755812, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:43,612\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.041388106, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0036973935, 'entropy': 7.755769, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:46,236\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.041806944, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.003690549, 'entropy': 7.755965, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:48,829\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.042502962, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0038562329, 'entropy': 7.7575774, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:51,393\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.0434846, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0041795117, 'entropy': 7.759159, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:54,012\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.043333124, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0040329965, 'entropy': 7.7574883, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:56,647\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.04391814, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.003941045, 'entropy': 7.7568536, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:13:59,297\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.04419353, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.004073101, 'entropy': 7.758513, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:01,931\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.044527642, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0040998245, 'entropy': 7.758685, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:04,553\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.04492856, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.004248295, 'entropy': 7.7595963, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:07,174\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.045157023, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.004371631, 'entropy': 7.760685, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:09,815\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.045706593, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0042639156, 'entropy': 7.759469, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:12,435\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.04591422, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0042220666, 'entropy': 7.759205, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:15,050\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.04624399, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0042200163, 'entropy': 7.759166, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:17,647\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.675000011920929, 'cur_lr': 4.999999873689376e-05, 'total_loss': 145525140.0, 'policy_loss': -0.04669625, 'vf_loss': 145525140.0, 'vf_explained_var': 0.0, 'kl': 0.0042507173, 'entropy': 7.7593026, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:17,690\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 28040}\n",
            "2020-03-19 08:14:17,726\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:14:17,732\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.553, max=11.0, mean=1.629),\n",
            "              np.ndarray((701,), dtype=float32, min=-21054.0, max=20779.0, mean=36.144),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2992.0, max=3135.0, mean=-16.371),\n",
            "              np.ndarray((701,), dtype=float32, min=-14.706, max=-6.28, mean=-7.772),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.553, max=11.0, mean=1.633),\n",
            "              np.ndarray((701,), dtype=float32, min=-2.835, max=2.225, mean=0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.979, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2992.0, max=3135.0, mean=-16.371),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.553, max=11.0, mean=1.629),\n",
            "              np.ndarray((701,), dtype=float32, min=-21054.0, max=20779.0, mean=36.144),\n",
            "              np.ndarray((701,), dtype=float32, min=-11269.45, max=14357.479, mean=3088.744),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:14:17,733\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:14:17,736\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-14-17\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 40\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 79019.941\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.675000011920929\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.759302616119385\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.004250717349350452\n",
            "      policy_loss: -0.0466962493956089\n",
            "      total_loss: 145525136.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 145525136.0\n",
            "  load_time_ms: 18.365\n",
            "  num_steps_sampled: 28040\n",
            "  num_steps_trained: 25600\n",
            "  sample_time_ms: 15898.687\n",
            "  update_time_ms: 20.034\n",
            "iterations_since_restore: 11\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.58230088495574\n",
            "  ram_util_percent: 18.0\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 19892.18181818182\n",
            "  policy_1: -10114.0\n",
            "  policy_2: -5228.454545454545\n",
            "  policy_3: -4549.727272727273\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -89177.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.24784127435113\n",
            "  mean_inference_ms: 7.931793084616535\n",
            "  mean_processing_ms: 2.639654160169158\n",
            "time_since_restore: 1108.7001793384552\n",
            "time_this_iter_s: 79.00121641159058\n",
            "time_total_s: 4169.126556634903\n",
            "timestamp: 1584605657\n",
            "timesteps_since_restore: 7711\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 28040\n",
            "training_iteration: 40\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:14:20,353\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': 0.010938791, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.0031302269, 'entropy': 7.7521334, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:22,954\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': 0.0022052466, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.0031652835, 'entropy': 7.751616, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:25,576\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.00259652, 'vf_loss': 35650436.0, 'vf_explained_var': 0.0, 'kl': 0.0036345695, 'entropy': 7.7560577, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:28,189\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.006526211, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.00438431, 'entropy': 7.761678, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:30,830\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.013130692, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.005576967, 'entropy': 7.7657576, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:33,437\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.017568858, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.007271661, 'entropy': 7.7723136, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:36,009\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.022267226, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.009154489, 'entropy': 7.780513, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:38,555\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.026350457, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.00968608, 'entropy': 7.7822633, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:41,165\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.030947287, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.010102056, 'entropy': 7.780182, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:43,756\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.034936525, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.010359364, 'entropy': 7.781938, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:46,399\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.038820762, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.011351503, 'entropy': 7.787413, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:48,960\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.04053564, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.011685466, 'entropy': 7.7854185, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:51,537\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.044189762, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.013283491, 'entropy': 7.78846, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:54,089\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.046222515, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.012885174, 'entropy': 7.7863207, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:56,697\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.049818836, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.013524202, 'entropy': 7.786658, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:14:59,336\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.050512623, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.015133003, 'entropy': 7.789309, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:01,940\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650440.0, 'policy_loss': -0.050107468, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.016447823, 'entropy': 7.790521, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:04,499\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.048472296, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.012928469, 'entropy': 7.7878175, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:07,075\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.05011346, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.016203705, 'entropy': 7.797928, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:09,626\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.05153374, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.015902389, 'entropy': 7.796469, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:12,198\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.05227512, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.013801013, 'entropy': 7.791312, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:14,805\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.05562544, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.01796626, 'entropy': 7.8004217, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:17,371\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.05902242, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.017452683, 'entropy': 7.796328, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:19,908\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.06024612, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.016300367, 'entropy': 7.7928557, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:22,480\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.062519655, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.01719091, 'entropy': 7.7921247, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:25,068\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.06417455, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.01857324, 'entropy': 7.793895, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:27,631\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.064701095, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.018505702, 'entropy': 7.7930093, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:30,207\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.06538506, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.018261673, 'entropy': 7.7927575, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:32,775\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650436.0, 'policy_loss': -0.06702077, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.017938588, 'entropy': 7.7917223, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:35,369\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35650430.0, 'policy_loss': -0.06792062, 'vf_loss': 35650430.0, 'vf_explained_var': 0.0, 'kl': 0.017055655, 'entropy': 7.7909346, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:15:35,412\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 28741}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-15-35\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 41\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 79063.921\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.3375000059604645\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.7909345626831055\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.017055654898285866\n",
            "      policy_loss: -0.06792061775922775\n",
            "      total_loss: 35650432.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 35650432.0\n",
            "  load_time_ms: 18.537\n",
            "  num_steps_sampled: 28741\n",
            "  num_steps_trained: 26240\n",
            "  sample_time_ms: 15898.448\n",
            "  update_time_ms: 20.091\n",
            "iterations_since_restore: 12\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.73153153153154\n",
            "  ram_util_percent: 18.09999999999999\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 20345.916666666668\n",
            "  policy_1: -10548.666666666666\n",
            "  policy_2: -4754.833333333333\n",
            "  policy_3: -5042.416666666667\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -89177.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.3084497572466\n",
            "  mean_inference_ms: 7.921299735290062\n",
            "  mean_processing_ms: 2.6427209829470284\n",
            "time_since_restore: 1186.3864660263062\n",
            "time_this_iter_s: 77.68628668785095\n",
            "time_total_s: 4246.812843322754\n",
            "timestamp: 1584605735\n",
            "timesteps_since_restore: 8412\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 28741\n",
            "training_iteration: 41\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:16:52,511\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:16:52,512\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,513\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,514\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,515\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,516\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,517\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,517\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,518\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,519\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,520\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,521\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,522\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,523\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,524\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,524\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,525\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:16:52,529\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n",
            "2020-03-19 08:16:55,159\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': 0.004503125, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.012935874, 'entropy': 7.8033624, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:16:57,751\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.010257919, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.011115367, 'entropy': 7.8005576, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:00,354\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950460.0, 'policy_loss': -0.015477525, 'vf_loss': 562950460.0, 'vf_explained_var': 0.0, 'kl': 0.007678787, 'entropy': 7.7855406, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:02,920\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.01782449, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.007108056, 'entropy': 7.7810783, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:05,446\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.024809394, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.007593033, 'entropy': 7.786191, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:08,002\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.02839135, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.007983925, 'entropy': 7.7876143, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:10,641\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.030392095, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.008317805, 'entropy': 7.7857447, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:13,201\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.032122154, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.00872022, 'entropy': 7.7880073, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:15,754\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.03473752, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.008813227, 'entropy': 7.789725, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:18,343\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950460.0, 'policy_loss': -0.03583932, 'vf_loss': 562950460.0, 'vf_explained_var': 0.0, 'kl': 0.009194551, 'entropy': 7.7941046, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:20,936\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.037149053, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.010409487, 'entropy': 7.798846, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:23,514\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.03930729, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.010929907, 'entropy': 7.7997613, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:26,035\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.04158927, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.012465331, 'entropy': 7.8067627, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:28,587\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.04315415, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.01242101, 'entropy': 7.8081713, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:31,200\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.043710817, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.011527061, 'entropy': 7.8046417, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:33,762\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.045713905, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.011675584, 'entropy': 7.8056045, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:36,315\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.04677405, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.011953443, 'entropy': 7.8070955, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:38,883\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.048263203, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.0124459, 'entropy': 7.809247, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:41,451\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.04856653, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.012747237, 'entropy': 7.811165, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:44,005\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.04921966, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.013351373, 'entropy': 7.8144646, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:46,565\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.050712287, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.014160864, 'entropy': 7.818301, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:49,106\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.050611056, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.013651739, 'entropy': 7.817285, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:51,612\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.05259186, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.013797981, 'entropy': 7.816021, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:54,174\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.05396676, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.014110039, 'entropy': 7.815103, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:56,766\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.055373184, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.014398366, 'entropy': 7.815709, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:17:59,378\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.056388505, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.01463004, 'entropy': 7.817482, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:01,970\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950460.0, 'policy_loss': -0.057378054, 'vf_loss': 562950460.0, 'vf_explained_var': 0.0, 'kl': 0.015003669, 'entropy': 7.8183517, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:04,561\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.058324825, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.014723295, 'entropy': 7.8169928, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:07,120\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950400.0, 'policy_loss': -0.058950804, 'vf_loss': 562950400.0, 'vf_explained_var': 0.0, 'kl': 0.014620217, 'entropy': 7.8172884, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:09,691\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 562950460.0, 'policy_loss': -0.059372813, 'vf_loss': 562950460.0, 'vf_explained_var': 0.0, 'kl': 0.0151076, 'entropy': 7.8191137, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:09,798\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 29442}\n",
            "2020-03-19 08:18:09,835\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:18:09,839\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-2.999, max=11.0, mean=1.628),\n",
            "              np.ndarray((701,), dtype=float32, min=-33033.0, max=51667.0, mean=3.124),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2880.0, max=3598.0, mean=19.545),\n",
            "              np.ndarray((701,), dtype=float32, min=-13.463, max=-6.29, mean=-7.736),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-2.999, max=11.0, mean=1.63),\n",
            "              np.ndarray((701,), dtype=float32, min=-2.612, max=10.736, mean=0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.992, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2880.0, max=3598.0, mean=19.545),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-2.999, max=11.0, mean=1.628),\n",
            "              np.ndarray((701,), dtype=float32, min=-33033.0, max=51667.0, mean=3.124),\n",
            "              np.ndarray((701,), dtype=float32, min=-10154.811, max=41714.27, mean=-4.802),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:18:09,841\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:18:09,844\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-18-09\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 42\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78977.74\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.3375000059604645\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.819113731384277\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.015107600018382072\n",
            "      policy_loss: -0.05937281250953674\n",
            "      total_loss: 562950464.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 562950464.0\n",
            "  load_time_ms: 16.911\n",
            "  num_steps_sampled: 29442\n",
            "  num_steps_trained: 26880\n",
            "  sample_time_ms: 23604.176\n",
            "  update_time_ms: 20.217\n",
            "iterations_since_restore: 13\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 77.50818181818182\n",
            "  ram_util_percent: 18.35045454545455\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 26874.53846153846\n",
            "  policy_1: -8104.384615384615\n",
            "  policy_2: -13875.461538461539\n",
            "  policy_3: -4894.692307692308\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.31931301965756\n",
            "  mean_inference_ms: 7.905287138421011\n",
            "  mean_processing_ms: 2.6437321915144016\n",
            "time_since_restore: 1340.6747131347656\n",
            "time_this_iter_s: 154.28824710845947\n",
            "time_total_s: 4401.101090431213\n",
            "timestamp: 1584605889\n",
            "timesteps_since_restore: 9113\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 29442\n",
            "training_iteration: 42\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_42/checkpoint-42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:18:12,406\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.0020583495, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.013948739, 'entropy': 7.8011045, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:15,094\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.009202952, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.007260305, 'entropy': 7.774273, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:17,729\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.015531704, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.0052677365, 'entropy': 7.760051, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:20,327\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.018978074, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.0040817163, 'entropy': 7.752758, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:22,909\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.023085972, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.005139103, 'entropy': 7.7577004, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:25,543\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.029571181, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.007843653, 'entropy': 7.77101, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:28,094\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.033444714, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.009381063, 'entropy': 7.7746034, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:30,682\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.03576923, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.01000371, 'entropy': 7.772794, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:33,247\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.03929039, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.010286758, 'entropy': 7.772457, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:35,819\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.041169383, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.009996687, 'entropy': 7.771071, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:38,381\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.04262413, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.0093257595, 'entropy': 7.7704377, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:40,976\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.04020207, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.010431306, 'entropy': 7.7698274, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:43,542\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.038504772, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.009264899, 'entropy': 7.7641916, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:46,206\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.04168315, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.009894693, 'entropy': 7.767621, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:48,771\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.043583, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.009926995, 'entropy': 7.7680306, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:51,310\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.045121856, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.009200634, 'entropy': 7.765918, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:53,872\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.045760542, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.011077916, 'entropy': 7.7742934, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:56,534\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.047434643, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.012669837, 'entropy': 7.7780623, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:18:59,125\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.04920274, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.011988664, 'entropy': 7.7758584, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:01,683\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.050885372, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.011853589, 'entropy': 7.776445, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:04,233\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.052021015, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.011978289, 'entropy': 7.7774687, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:06,820\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.053528648, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.01198218, 'entropy': 7.7766085, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:09,406\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.05384487, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.011459277, 'entropy': 7.7714524, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:11,973\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.054400038, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.011204736, 'entropy': 7.7689295, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:14,540\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.055129934, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.01155209, 'entropy': 7.7706466, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:17,143\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.056155384, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.011677717, 'entropy': 7.7717505, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:19,721\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.056508325, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.011617247, 'entropy': 7.7709746, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:22,284\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.057231925, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.011808345, 'entropy': 7.771112, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:24,870\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586542.0, 'policy_loss': -0.05736593, 'vf_loss': 15586542.0, 'vf_explained_var': 0.0, 'kl': 0.011987437, 'entropy': 7.772294, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:27,451\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 15586544.0, 'policy_loss': -0.057997417, 'vf_loss': 15586544.0, 'vf_explained_var': 0.0, 'kl': 0.012002801, 'entropy': 7.7725143, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:27,494\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 30143}\n",
            "2020-03-19 08:19:27,541\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:19:27,542\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,543\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,544\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,545\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,546\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,547\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,550\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,552\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,552\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,556\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,557\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,558\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,560\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,560\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,562\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,562\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:19:27,565\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-19-27\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 43\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78854.345\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.3375000059604645\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.772514343261719\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.012002800591289997\n",
            "      policy_loss: -0.05799741670489311\n",
            "      total_loss: 15586544.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 15586544.0\n",
            "  load_time_ms: 16.559\n",
            "  num_steps_sampled: 30143\n",
            "  num_steps_trained: 27520\n",
            "  sample_time_ms: 23604.176\n",
            "  update_time_ms: 20.246\n",
            "iterations_since_restore: 14\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.57747747747749\n",
            "  ram_util_percent: 18.5\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 25441.285714285714\n",
            "  policy_1: -7602.428571428572\n",
            "  policy_2: -13875.0\n",
            "  policy_3: -3963.8571428571427\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.32862438743837\n",
            "  mean_inference_ms: 7.891562055390396\n",
            "  mean_processing_ms: 2.644598941715007\n",
            "time_since_restore: 1418.3370413780212\n",
            "time_this_iter_s: 77.66232824325562\n",
            "time_total_s: 4478.763418674469\n",
            "timestamp: 1584605967\n",
            "timesteps_since_restore: 9814\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 30143\n",
            "training_iteration: 43\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:19:30,191\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': 0.005563992, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.007120122, 'entropy': 7.756196, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:32,757\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.00546828, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.003955153, 'entropy': 7.742877, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:35,336\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.006851062, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.0019204989, 'entropy': 7.7286897, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:37,864\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.013973853, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.0019412907, 'entropy': 7.727523, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:40,481\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.018003508, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.0024827244, 'entropy': 7.730883, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:43,050\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.0236285, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.003142763, 'entropy': 7.734913, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:45,614\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.028129537, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.004191937, 'entropy': 7.7431564, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:48,167\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.031736888, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.005774184, 'entropy': 7.7525544, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:50,736\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.034944113, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.006642738, 'entropy': 7.755895, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:53,256\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.03787478, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.0078050285, 'entropy': 7.7615786, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:55,804\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.040770374, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.008945347, 'entropy': 7.7682104, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:19:58,394\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.045927726, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.01002751, 'entropy': 7.7749496, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:00,998\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.049408175, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.010250537, 'entropy': 7.777186, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:03,565\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.052592386, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.011403457, 'entropy': 7.781896, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:06,123\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.05516074, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.012668346, 'entropy': 7.7877364, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:08,652\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.05788166, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.013785144, 'entropy': 7.791214, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:11,259\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.05767882, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.012741392, 'entropy': 7.7889624, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:13,810\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.058997385, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.013929499, 'entropy': 7.794606, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:16,351\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.06124261, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.015136669, 'entropy': 7.798976, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:18,909\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.06208101, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.014571341, 'entropy': 7.7969246, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:21,466\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.062482346, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.015555155, 'entropy': 7.797352, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:24,071\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.063579634, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.014792579, 'entropy': 7.795479, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:26,632\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.06482289, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.015097177, 'entropy': 7.7958894, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:29,195\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997040.0, 'policy_loss': -0.06565757, 'vf_loss': 128997040.0, 'vf_explained_var': 0.0, 'kl': 0.015390028, 'entropy': 7.7974715, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:31,755\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997040.0, 'policy_loss': -0.066775724, 'vf_loss': 128997040.0, 'vf_explained_var': 0.0, 'kl': 0.015340364, 'entropy': 7.7980385, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:34,345\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.06651666, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.014808476, 'entropy': 7.7955084, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:36,891\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.066213086, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.01478803, 'entropy': 7.795475, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:39,433\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.067058004, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.016185148, 'entropy': 7.8001976, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:42,009\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.06769057, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.016340319, 'entropy': 7.800206, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:44,593\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 128997030.0, 'policy_loss': -0.06822445, 'vf_loss': 128997030.0, 'vf_explained_var': 0.0, 'kl': 0.015593928, 'entropy': 7.7986727, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:44,639\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 30844}\n",
            "2020-03-19 08:20:44,676\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:20:44,681\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.289, max=11.0, mean=1.603),\n",
            "              np.ndarray((701,), dtype=float32, min=-39117.0, max=39000.0, mean=-39.776),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3069.0, max=2855.0, mean=22.464),\n",
            "              np.ndarray((701,), dtype=float32, min=-14.14, max=-6.281, mean=-7.766),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.289, max=11.0, mean=1.606),\n",
            "              np.ndarray((701,), dtype=float32, min=-3.906, max=2.862, mean=0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.994, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3069.0, max=2855.0, mean=22.464),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.289, max=11.0, mean=1.603),\n",
            "              np.ndarray((701,), dtype=float32, min=-39117.0, max=39000.0, mean=-39.776),\n",
            "              np.ndarray((701,), dtype=float32, min=-33594.641, max=21980.318, mean=-1521.272),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:20:44,685\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:20:44,688\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-20-44\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 44\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78675.863\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.3375000059604645\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.798672676086426\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.015593928284943104\n",
            "      policy_loss: -0.0682244524359703\n",
            "      total_loss: 128997032.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 128997032.0\n",
            "  load_time_ms: 15.245\n",
            "  num_steps_sampled: 30844\n",
            "  num_steps_trained: 28160\n",
            "  sample_time_ms: 15635.979\n",
            "  update_time_ms: 20.883\n",
            "iterations_since_restore: 15\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.58545454545458\n",
            "  ram_util_percent: 18.59999999999999\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 29537.0\n",
            "  policy_1: -10356.2\n",
            "  policy_2: -15413.533333333333\n",
            "  policy_3: -3767.266666666667\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.33669423951507\n",
            "  mean_inference_ms: 7.879666983430529\n",
            "  mean_processing_ms: 2.645350125222199\n",
            "time_since_restore: 1495.4437561035156\n",
            "time_this_iter_s: 77.10671472549438\n",
            "time_total_s: 4555.870133399963\n",
            "timestamp: 1584606044\n",
            "timesteps_since_restore: 10515\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 30844\n",
            "training_iteration: 44\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:20:47,267\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': 0.015809702, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.010867467, 'entropy': 7.790448, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:49,802\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': 0.004633525, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.007119385, 'entropy': 7.768338, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:52,358\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.0026842714, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.007861075, 'entropy': 7.7682467, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:54,932\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.008557657, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.010634561, 'entropy': 7.776651, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:20:57,548\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.012779971, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.011663335, 'entropy': 7.782083, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:00,135\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.016632339, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.01096138, 'entropy': 7.779901, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:02,683\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.020894568, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.0114847645, 'entropy': 7.779401, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:05,273\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.024118086, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.014190736, 'entropy': 7.78789, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:07,801\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.027726537, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.013716389, 'entropy': 7.7892327, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:10,377\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.0291264, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.011262929, 'entropy': 7.78219, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:12,918\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.031654004, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.011657332, 'entropy': 7.7833853, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:15,541\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.036549706, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.014882323, 'entropy': 7.7927322, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:18,108\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.03851293, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.0151130855, 'entropy': 7.7936974, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:20,684\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.039719015, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.014724058, 'entropy': 7.7920814, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:23,267\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.04045204, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.013817275, 'entropy': 7.7881727, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:25,832\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.042215563, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.014413126, 'entropy': 7.7894163, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:28,390\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.043161232, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.015496874, 'entropy': 7.7922354, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:30,945\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.042737324, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.017026264, 'entropy': 7.797914, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:33,509\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.04296518, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.014770575, 'entropy': 7.79303, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:36,093\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.04376812, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.01594852, 'entropy': 7.797353, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:38,666\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.0453676, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.015985096, 'entropy': 7.7968473, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:41,272\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.046485413, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.014288725, 'entropy': 7.7909904, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:43,831\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.04871647, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.0150984945, 'entropy': 7.7923574, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:46,408\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.049985718, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.01615375, 'entropy': 7.7949295, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:48,995\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.05057169, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.015526362, 'entropy': 7.7935934, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:51,506\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376880.0, 'policy_loss': -0.05181084, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.016837345, 'entropy': 7.7974443, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:54,065\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.052605875, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.0157123, 'entropy': 7.7943177, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:56,629\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.05334376, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.015891585, 'entropy': 7.794362, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:21:59,242\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.05332931, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.016396385, 'entropy': 7.7951903, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:22:01,792\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 70376890.0, 'policy_loss': -0.05509938, 'vf_loss': 70376890.0, 'vf_explained_var': 0.0, 'kl': 0.01602101, 'entropy': 7.7925835, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:22:01,894\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 31545}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-22-01\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 45\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78449.093\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.3375000059604645\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.792583465576172\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.016021009534597397\n",
            "      policy_loss: -0.055099379271268845\n",
            "      total_loss: 70376888.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 70376888.0\n",
            "  load_time_ms: 15.281\n",
            "  num_steps_sampled: 31545\n",
            "  num_steps_trained: 28800\n",
            "  sample_time_ms: 15636.056\n",
            "  update_time_ms: 20.855\n",
            "iterations_since_restore: 16\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.64272727272729\n",
            "  ram_util_percent: 18.652727272727265\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 26029.0\n",
            "  policy_1: -8312.5\n",
            "  policy_2: -14483.125\n",
            "  policy_3: -3233.375\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.34375536008217\n",
            "  mean_inference_ms: 7.869258795465648\n",
            "  mean_processing_ms: 2.6460074107909914\n",
            "time_since_restore: 1572.604733467102\n",
            "time_this_iter_s: 77.16097736358643\n",
            "time_total_s: 4633.03111076355\n",
            "timestamp: 1584606121\n",
            "timesteps_since_restore: 11216\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 31545\n",
            "training_iteration: 45\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_45/checkpoint-45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:23:21,890\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:23:21,892\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,898\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,899\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,905\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,906\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,907\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,909\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,911\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,912\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,914\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,917\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,920\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,921\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,923\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,924\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,926\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:23:21,932\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n",
            "2020-03-19 08:23:24,727\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': 0.0013368353, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.0068708337, 'entropy': 7.7887015, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:27,489\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.008289745, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.0074245976, 'entropy': 7.7910233, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:30,271\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.013815692, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.00872452, 'entropy': 7.7973223, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:33,060\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.019612174, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.011663226, 'entropy': 7.8156157, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:35,889\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.023642365, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.01429452, 'entropy': 7.8304114, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:38,639\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.029597789, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.018164039, 'entropy': 7.847146, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:41,379\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.032269638, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.015384465, 'entropy': 7.836833, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:44,131\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.032693285, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.013847036, 'entropy': 7.8309693, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:46,907\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.03814451, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.015822735, 'entropy': 7.837596, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:49,655\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951720.0, 'policy_loss': -0.041556995, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.017452514, 'entropy': 7.8434668, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:52,405\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951720.0, 'policy_loss': -0.044199474, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.017845739, 'entropy': 7.843848, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:55,136\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.04593466, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.01784486, 'entropy': 7.846812, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:23:57,924\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.048610598, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.017862294, 'entropy': 7.8446107, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:00,719\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951720.0, 'policy_loss': -0.050590236, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.018457592, 'entropy': 7.846784, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:03,467\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.052230597, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.018412553, 'entropy': 7.8476076, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:06,192\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.05037729, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.017082054, 'entropy': 7.841655, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:08,932\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951720.0, 'policy_loss': -0.05158177, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.017463671, 'entropy': 7.8417077, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:11,685\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951720.0, 'policy_loss': -0.05452016, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.018924579, 'entropy': 7.8498507, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:14,433\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951720.0, 'policy_loss': -0.05607658, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.02025502, 'entropy': 7.854497, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:17,193\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951720.0, 'policy_loss': -0.057220407, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.019110799, 'entropy': 7.848719, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:20,012\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.059577547, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.01987062, 'entropy': 7.850805, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:22,777\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.05999558, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.019839492, 'entropy': 7.8501616, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:25,559\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951720.0, 'policy_loss': -0.062120117, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.020717505, 'entropy': 7.851649, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:28,332\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.06333059, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.021138888, 'entropy': 7.8514023, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:31,130\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.0650401, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.021986905, 'entropy': 7.853733, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:33,871\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.06586026, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.021843504, 'entropy': 7.8511214, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:36,669\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951720.0, 'policy_loss': -0.06651588, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.020756068, 'entropy': 7.8454733, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:39,470\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951720.0, 'policy_loss': -0.06600388, 'vf_loss': 71951720.0, 'vf_explained_var': 0.0, 'kl': 0.018564846, 'entropy': 7.839849, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:42,228\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.06703685, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.019192493, 'entropy': 7.8421288, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:45,025\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.3375000059604645, 'cur_lr': 4.999999873689376e-05, 'total_loss': 71951730.0, 'policy_loss': -0.06826046, 'vf_loss': 71951730.0, 'vf_explained_var': 0.0, 'kl': 0.020146072, 'entropy': 7.843638, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:45,070\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 32246}\n",
            "2020-03-19 08:24:45,108\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:24:45,113\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-2.97, max=11.0, mean=1.595),\n",
            "              np.ndarray((701,), dtype=float32, min=-85419.0, max=98640.0, mean=-12.051),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3111.0, max=2991.0, mean=14.714),\n",
            "              np.ndarray((701,), dtype=float32, min=-12.27, max=-6.277, mean=-7.713),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-2.97, max=11.0, mean=1.597),\n",
            "              np.ndarray((701,), dtype=float32, min=-3.564, max=1.496, mean=0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.995, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3111.0, max=2991.0, mean=14.714),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-2.97, max=11.0, mean=1.595),\n",
            "              np.ndarray((701,), dtype=float32, min=-85419.0, max=98640.0, mean=-12.051),\n",
            "              np.ndarray((701,), dtype=float32, min=-107248.953, max=43835.676, mean=-842.59),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:24:45,113\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:24:45,117\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-24-45\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 46\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78803.44\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.3375000059604645\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.843637943267822\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.020146071910858154\n",
            "      policy_loss: -0.06826046109199524\n",
            "      total_loss: 71951728.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 71951728.0\n",
            "  load_time_ms: 15.88\n",
            "  num_steps_sampled: 32246\n",
            "  num_steps_trained: 29440\n",
            "  sample_time_ms: 23631.496\n",
            "  update_time_ms: 20.863\n",
            "iterations_since_restore: 17\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 78.03347639484979\n",
            "  ram_util_percent: 18.968240343347638\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 25751.529411764706\n",
            "  policy_1: -8689.470588235294\n",
            "  policy_2: -14011.0\n",
            "  policy_3: -3051.0588235294117\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.3777327845384\n",
            "  mean_inference_ms: 7.858098511734473\n",
            "  mean_processing_ms: 2.64683760326151\n",
            "time_since_restore: 1735.742727279663\n",
            "time_this_iter_s: 163.13799381256104\n",
            "time_total_s: 4796.169104576111\n",
            "timestamp: 1584606285\n",
            "timesteps_since_restore: 11917\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 32246\n",
            "training_iteration: 46\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:24:47,868\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.005519976, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.016443033, 'entropy': 7.8103547, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:50,628\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.023771089, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.0069947233, 'entropy': 7.7706757, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:53,363\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541900.0, 'policy_loss': -0.029785141, 'vf_loss': 846541900.0, 'vf_explained_var': 0.0, 'kl': 0.004067362, 'entropy': 7.7505937, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:56,086\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.036808006, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.0049826857, 'entropy': 7.749883, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:24:58,952\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541900.0, 'policy_loss': -0.043344855, 'vf_loss': 846541900.0, 'vf_explained_var': 0.0, 'kl': 0.0069681555, 'entropy': 7.7566385, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:01,700\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.04850451, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.008552143, 'entropy': 7.7620378, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:04,432\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.054188352, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.01018269, 'entropy': 7.7670083, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:07,150\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.05774144, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.010411612, 'entropy': 7.766309, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:09,937\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541900.0, 'policy_loss': -0.06158164, 'vf_loss': 846541900.0, 'vf_explained_var': 0.0, 'kl': 0.011632966, 'entropy': 7.7688546, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:12,765\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541900.0, 'policy_loss': -0.062920876, 'vf_loss': 846541900.0, 'vf_explained_var': 0.0, 'kl': 0.011517213, 'entropy': 7.768445, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:15,475\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.06429835, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011382967, 'entropy': 7.768832, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:18,221\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.06590263, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011436157, 'entropy': 7.7684526, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:20,919\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.06681098, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011318475, 'entropy': 7.768186, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:23,639\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.06754317, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011002345, 'entropy': 7.7659483, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:26,389\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.068333626, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.010755079, 'entropy': 7.764505, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:29,138\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541900.0, 'policy_loss': -0.06828594, 'vf_loss': 846541900.0, 'vf_explained_var': 0.0, 'kl': 0.010582243, 'entropy': 7.765123, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:31,828\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.06986658, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011358524, 'entropy': 7.766257, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:34,613\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541900.0, 'policy_loss': -0.07080152, 'vf_loss': 846541900.0, 'vf_explained_var': 0.0, 'kl': 0.011686075, 'entropy': 7.7662416, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:37,343\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.07080074, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011763902, 'entropy': 7.767433, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:40,089\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.07178755, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011712, 'entropy': 7.7678895, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:42,840\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.072805464, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011965172, 'entropy': 7.7679977, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:45,578\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.07353093, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.012020281, 'entropy': 7.7680864, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:48,331\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.07409493, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.012187927, 'entropy': 7.7690325, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:51,055\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.074638285, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011786875, 'entropy': 7.7673035, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:53,805\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.07532107, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011877159, 'entropy': 7.766551, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:56,546\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541900.0, 'policy_loss': -0.07574054, 'vf_loss': 846541900.0, 'vf_explained_var': 0.0, 'kl': 0.0118918475, 'entropy': 7.766982, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:25:59,291\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.07621847, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011809102, 'entropy': 7.7669134, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:01,953\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.07651, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011929473, 'entropy': 7.7672973, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:04,678\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.07686701, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.011998517, 'entropy': 7.767797, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:07,333\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 846541950.0, 'policy_loss': -0.077247135, 'vf_loss': 846541950.0, 'vf_explained_var': 0.0, 'kl': 0.012102311, 'entropy': 7.7685103, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:07,377\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 32947}\n",
            "2020-03-19 08:26:07,425\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:26:07,426\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,428\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,429\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,430\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,431\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,432\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,434\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,435\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,436\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,436\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,438\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,439\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,440\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,442\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,443\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,444\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:26:07,447\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-26-07\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 47\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78965.005\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.768510341644287\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.012102310545742512\n",
            "      policy_loss: -0.07724713534116745\n",
            "      total_loss: 846541952.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 846541952.0\n",
            "  load_time_ms: 15.801\n",
            "  num_steps_sampled: 32947\n",
            "  num_steps_trained: 30080\n",
            "  sample_time_ms: 23631.543\n",
            "  update_time_ms: 20.793\n",
            "iterations_since_restore: 18\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.70854700854701\n",
            "  ram_util_percent: 19.106837606837598\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 23851.555555555555\n",
            "  policy_1: -8944.277777777777\n",
            "  policy_2: -13169.111111111111\n",
            "  policy_3: -1738.1666666666667\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.4079349396106\n",
            "  mean_inference_ms: 7.848178259528983\n",
            "  mean_processing_ms: 2.6475755521241933\n",
            "time_since_restore: 1818.0127561092377\n",
            "time_this_iter_s: 82.27002882957458\n",
            "time_total_s: 4878.439133405685\n",
            "timestamp: 1584606367\n",
            "timesteps_since_restore: 12618\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 32947\n",
            "training_iteration: 47\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:26:10,167\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': 0.008222054, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.0052274303, 'entropy': 7.7595816, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:12,896\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': 0.004718813, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.003118026, 'entropy': 7.746263, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:15,630\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': 0.002694133, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.0022615306, 'entropy': 7.738916, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:18,346\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': 0.0003220804, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.002135578, 'entropy': 7.736951, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:21,065\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.0016716555, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.0024680586, 'entropy': 7.739512, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:23,743\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.003987203, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.0028900278, 'entropy': 7.7419443, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:26,427\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.005802854, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.003403165, 'entropy': 7.744914, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:29,082\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.007291872, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.0037030794, 'entropy': 7.7481093, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:31,757\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.009283641, 'vf_loss': 56873736.0, 'vf_explained_var': 0.0, 'kl': 0.0041400343, 'entropy': 7.7504373, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:34,426\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.011304903, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.0045832307, 'entropy': 7.753287, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:37,123\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.012286922, 'vf_loss': 56873736.0, 'vf_explained_var': 0.0, 'kl': 0.0046828953, 'entropy': 7.755069, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:39,815\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.014041351, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.005329027, 'entropy': 7.7595816, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:42,512\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.015547794, 'vf_loss': 56873736.0, 'vf_explained_var': 0.0, 'kl': 0.0057156705, 'entropy': 7.762445, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:45,144\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.01664494, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.006240099, 'entropy': 7.7643785, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:47,830\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.018196594, 'vf_loss': 56873736.0, 'vf_explained_var': 0.0, 'kl': 0.0066384734, 'entropy': 7.766233, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:50,463\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.019154692, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.0068221153, 'entropy': 7.76754, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:53,106\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.020352174, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.007459908, 'entropy': 7.770772, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:55,713\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.021364402, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.0075960653, 'entropy': 7.7727385, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:26:58,385\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.022383597, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.008753679, 'entropy': 7.7774696, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:01,023\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.023428377, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.0096170055, 'entropy': 7.781099, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:03,669\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.02490355, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.009308622, 'entropy': 7.7794085, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:06,345\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.025466606, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.008714794, 'entropy': 7.7770433, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:09,097\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.025985617, 'vf_loss': 56873736.0, 'vf_explained_var': 0.0, 'kl': 0.00835979, 'entropy': 7.775827, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:11,803\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.026088472, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.008214211, 'entropy': 7.7746797, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:14,490\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.02648883, 'vf_loss': 56873736.0, 'vf_explained_var': 0.0, 'kl': 0.008365735, 'entropy': 7.775266, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:17,145\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.028319132, 'vf_loss': 56873736.0, 'vf_explained_var': 0.0, 'kl': 0.008626005, 'entropy': 7.7760115, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:19,777\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873736.0, 'policy_loss': -0.028551752, 'vf_loss': 56873736.0, 'vf_explained_var': 0.0, 'kl': 0.009176568, 'entropy': 7.778159, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:22,411\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.028901225, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.009273341, 'entropy': 7.7787986, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:25,006\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.030238176, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.009643494, 'entropy': 7.778853, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:27,606\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 56873730.0, 'policy_loss': -0.031003784, 'vf_loss': 56873730.0, 'vf_explained_var': 0.0, 'kl': 0.009931286, 'entropy': 7.778798, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:27,721\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 33648}\n",
            "2020-03-19 08:27:27,767\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:27:27,773\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.085, max=11.0, mean=1.578),\n",
            "              np.ndarray((701,), dtype=float32, min=-58758.0, max=82541.0, mean=24.787),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3524.0, max=3453.0, mean=78.725),\n",
            "              np.ndarray((701,), dtype=float32, min=-12.398, max=-6.271, mean=-7.623),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.085, max=11.0, mean=1.581),\n",
            "              np.ndarray((701,), dtype=float32, min=-5.103, max=3.746, mean=0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.995, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3524.0, max=3453.0, mean=78.725),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.085, max=11.0, mean=1.578),\n",
            "              np.ndarray((701,), dtype=float32, min=-58758.0, max=82541.0, mean=24.787),\n",
            "              np.ndarray((701,), dtype=float32, min=-54787.125, max=38464.422, mean=-1011.492),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:27:27,774\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:27:27,776\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-27-27\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 48\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 79021.06\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.7787981033325195\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.009931285865604877\n",
            "      policy_loss: -0.031003784388303757\n",
            "      total_loss: 56873728.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 56873728.0\n",
            "  load_time_ms: 16.123\n",
            "  num_steps_sampled: 33648\n",
            "  num_steps_trained: 30720\n",
            "  sample_time_ms: 15720.113\n",
            "  update_time_ms: 21.014\n",
            "iterations_since_restore: 19\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.81999999999998\n",
            "  ram_util_percent: 19.199999999999992\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 23900.894736842107\n",
            "  policy_1: -9117.052631578947\n",
            "  policy_2: -12775.421052631578\n",
            "  policy_3: -2008.421052631579\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.43495792046468\n",
            "  mean_inference_ms: 7.839302244397756\n",
            "  mean_processing_ms: 2.6482358221592257\n",
            "time_since_restore: 1898.24707365036\n",
            "time_this_iter_s: 80.23431754112244\n",
            "time_total_s: 4958.673450946808\n",
            "timestamp: 1584606447\n",
            "timesteps_since_restore: 13319\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 33648\n",
            "training_iteration: 48\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_48/checkpoint-48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:27:30,380\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': 0.021937968, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0035199926, 'entropy': 7.751046, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:32,959\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': 0.014660841, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0023605912, 'entropy': 7.7389803, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:35,596\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554010.0, 'policy_loss': 0.009995611, 'vf_loss': 120554010.0, 'vf_explained_var': 0.0, 'kl': 0.002131133, 'entropy': 7.732291, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:38,201\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': 0.005338134, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0026243678, 'entropy': 7.734014, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:40,811\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': 0.0015740826, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0033867452, 'entropy': 7.7381387, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:43,381\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554030.0, 'policy_loss': -0.0010578483, 'vf_loss': 120554030.0, 'vf_explained_var': 0.0, 'kl': 0.003457579, 'entropy': 7.7375855, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:45,964\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.0021373853, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0030108797, 'entropy': 7.7346787, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:48,497\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.0048621236, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0030706357, 'entropy': 7.7336454, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:51,081\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.007674448, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0039689573, 'entropy': 7.7383127, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:53,631\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.009024741, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.004084385, 'entropy': 7.7386475, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:56,210\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554030.0, 'policy_loss': -0.01155223, 'vf_loss': 120554030.0, 'vf_explained_var': 0.0, 'kl': 0.0041108876, 'entropy': 7.738553, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:27:58,805\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.014123736, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0045064082, 'entropy': 7.739726, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:01,416\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.015962109, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0048383633, 'entropy': 7.7402697, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:03,988\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.017396146, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0051786704, 'entropy': 7.7404556, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:06,577\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.018805427, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.005293599, 'entropy': 7.740979, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:09,123\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.019985689, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.005174372, 'entropy': 7.739989, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:11,673\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.021541495, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0054663746, 'entropy': 7.740439, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:14,254\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.02210569, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.005417706, 'entropy': 7.7405024, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:16,800\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.02243112, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0053884136, 'entropy': 7.740407, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:19,340\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.0239567, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0057773413, 'entropy': 7.741693, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:21,893\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.024609491, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0059648645, 'entropy': 7.7423754, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:24,489\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.025401358, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.006298939, 'entropy': 7.743235, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:27,047\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554010.0, 'policy_loss': -0.025171855, 'vf_loss': 120554010.0, 'vf_explained_var': 0.0, 'kl': 0.005798542, 'entropy': 7.741647, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:29,603\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.026177669, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0062564397, 'entropy': 7.7428894, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:32,172\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.026454892, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.006394702, 'entropy': 7.743, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:34,719\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.026848942, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.006386111, 'entropy': 7.743026, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:37,309\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554030.0, 'policy_loss': -0.026792446, 'vf_loss': 120554030.0, 'vf_explained_var': 0.0, 'kl': 0.0068407683, 'entropy': 7.744607, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:39,948\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.025932502, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.006538248, 'entropy': 7.7433867, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:42,544\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.02694415, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0067658783, 'entropy': 7.743773, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:45,139\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 120554024.0, 'policy_loss': -0.027484914, 'vf_loss': 120554024.0, 'vf_explained_var': 0.0, 'kl': 0.0067776083, 'entropy': 7.7438927, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:28:45,181\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 34349}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-28-45\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 49\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78831.302\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.743892669677734\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.006777608301490545\n",
            "      policy_loss: -0.027484914287924767\n",
            "      total_loss: 120554024.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 120554024.0\n",
            "  load_time_ms: 15.749\n",
            "  num_steps_sampled: 34349\n",
            "  num_steps_trained: 31360\n",
            "  sample_time_ms: 15720.54\n",
            "  update_time_ms: 21.099\n",
            "iterations_since_restore: 20\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.57363636363635\n",
            "  ram_util_percent: 19.300000000000008\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 23574.65\n",
            "  policy_1: -9796.45\n",
            "  policy_2: -11862.65\n",
            "  policy_3: -1915.55\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.45927860323334\n",
            "  mean_inference_ms: 7.831313830779652\n",
            "  mean_processing_ms: 2.6488300651907553\n",
            "time_since_restore: 1975.6690084934235\n",
            "time_this_iter_s: 77.42193484306335\n",
            "time_total_s: 5036.095385789871\n",
            "timestamp: 1584606525\n",
            "timesteps_since_restore: 14020\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 34349\n",
            "training_iteration: 49\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:30:01,310\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:30:01,316\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,317\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,324\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,327\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,330\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,331\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,333\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,334\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,335\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,336\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,337\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,338\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,339\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,340\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,342\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,343\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:30:01,346\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n",
            "2020-03-19 08:30:03,895\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.004679823, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.0036640868, 'entropy': 7.7323747, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:06,457\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.011337934, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.0039695455, 'entropy': 7.7344694, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:08,984\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.016041141, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.0043014414, 'entropy': 7.748394, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:11,545\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.022099946, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.0055792937, 'entropy': 7.7682047, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:14,125\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.027414996, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.0058148466, 'entropy': 7.770124, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:16,703\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.030541986, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.005962213, 'entropy': 7.7717466, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:19,283\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.03707968, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.006735931, 'entropy': 7.778257, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:21,810\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.041870154, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.0073906765, 'entropy': 7.785694, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:24,336\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.04420077, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.0076996177, 'entropy': 7.791893, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:26,854\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.047592055, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.007880124, 'entropy': 7.7936006, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:29,409\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.050605334, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.00887131, 'entropy': 7.797679, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:31,934\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.052571636, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.0089971395, 'entropy': 7.798298, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:34,497\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.05612441, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.009977864, 'entropy': 7.803641, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:37,050\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.05801221, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.010276719, 'entropy': 7.8065004, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:39,583\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.06025393, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.010072723, 'entropy': 7.8015037, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:42,180\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.060085, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.010254566, 'entropy': 7.799333, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:44,739\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.06250908, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.010880256, 'entropy': 7.8035746, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:47,267\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.06307107, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.0101293, 'entropy': 7.802901, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:49,800\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.064033605, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.010542697, 'entropy': 7.802031, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:52,375\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.065483615, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.010755105, 'entropy': 7.80165, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:54,911\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.06656158, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.011478671, 'entropy': 7.806501, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:30:57,490\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.06756401, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.0107738245, 'entropy': 7.805969, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:00,069\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.07054313, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.011441439, 'entropy': 7.806015, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:02,624\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.071149744, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.011604004, 'entropy': 7.8050222, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:05,164\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.07358162, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.011489706, 'entropy': 7.804582, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:07,740\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.07668774, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.011967132, 'entropy': 7.806012, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:10,248\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.07909612, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.012808095, 'entropy': 7.8103952, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:12,803\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.07933273, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.012659928, 'entropy': 7.8105226, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:15,333\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.08138429, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.012372357, 'entropy': 7.807602, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:17,866\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 53369036.0, 'policy_loss': -0.08325066, 'vf_loss': 53369036.0, 'vf_explained_var': 0.0, 'kl': 0.013568232, 'entropy': 7.8095307, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:17,911\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 35050}\n",
            "2020-03-19 08:31:17,956\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:31:17,961\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.022, max=11.0, mean=1.598),\n",
            "              np.ndarray((701,), dtype=float32, min=-89984.0, max=89984.0, mean=-49.017),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2857.0, max=3000.0, mean=30.874),\n",
            "              np.ndarray((701,), dtype=float32, min=-12.515, max=-6.295, mean=-7.664),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.022, max=11.0, mean=1.597),\n",
            "              np.ndarray((701,), dtype=float32, min=-2.922, max=2.622, mean=-0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.992, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2857.0, max=3000.0, mean=30.874),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.022, max=11.0, mean=1.598),\n",
            "              np.ndarray((701,), dtype=float32, min=-89984.0, max=89984.0, mean=-49.017),\n",
            "              np.ndarray((701,), dtype=float32, min=-63911.691, max=53620.09, mean=-1966.576),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:31:17,962\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:31:17,965\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-31-17\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 50\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78590.069\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.809530735015869\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.013568231835961342\n",
            "      policy_loss: -0.08325065672397614\n",
            "      total_loss: 53369036.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 53369036.0\n",
            "  load_time_ms: 16.963\n",
            "  num_steps_sampled: 35050\n",
            "  num_steps_trained: 32000\n",
            "  sample_time_ms: 23329.035\n",
            "  update_time_ms: 21.683\n",
            "iterations_since_restore: 21\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 77.35917431192662\n",
            "  ram_util_percent: 19.60550458715596\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 24257.571428571428\n",
            "  policy_1: -10389.42857142857\n",
            "  policy_2: -12096.714285714286\n",
            "  policy_3: -1771.4285714285713\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.45407308544046\n",
            "  mean_inference_ms: 7.8217453587479255\n",
            "  mean_processing_ms: 2.6491376643469007\n",
            "time_since_restore: 2128.35902094841\n",
            "time_this_iter_s: 152.69001245498657\n",
            "time_total_s: 5188.785398244858\n",
            "timestamp: 1584606677\n",
            "timesteps_since_restore: 14721\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 35050\n",
            "training_iteration: 50\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:31:20,545\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.0071105435, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.018279476, 'entropy': 7.8219275, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:23,118\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.018189598, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.00861659, 'entropy': 7.781405, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:25,646\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.02243932, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.0060540186, 'entropy': 7.762108, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:28,177\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.02893221, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.0070757074, 'entropy': 7.762726, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:30,751\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.03718254, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.0086011635, 'entropy': 7.7665963, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:33,352\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.042330224, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.0099888565, 'entropy': 7.7715087, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:35,930\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.047717236, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.011949189, 'entropy': 7.7773924, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:38,541\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.051478125, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.012188578, 'entropy': 7.776005, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:41,154\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.05481293, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.014132619, 'entropy': 7.778366, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:43,762\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.054997496, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.011749863, 'entropy': 7.7741523, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:46,303\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.05648945, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.0114714, 'entropy': 7.7748795, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:48,899\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.057726167, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.012733665, 'entropy': 7.7779183, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:51,480\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.06142979, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.0138361845, 'entropy': 7.781989, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:54,105\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.06381389, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.013601199, 'entropy': 7.782801, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:56,726\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.06555988, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.013987834, 'entropy': 7.7857504, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:31:59,375\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.0670805, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.013868335, 'entropy': 7.784711, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:01,979\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.06843272, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.01395707, 'entropy': 7.784658, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:04,582\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.0696491, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.013877246, 'entropy': 7.7862597, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:07,223\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.071660146, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.0143487435, 'entropy': 7.787314, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:09,800\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.073387586, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.0148492055, 'entropy': 7.7900987, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:12,387\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.07468864, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.01501365, 'entropy': 7.793653, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:15,017\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.07490384, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.014954324, 'entropy': 7.7966337, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:17,616\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.075345196, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.015090013, 'entropy': 7.7939706, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:20,212\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.07677908, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.015784394, 'entropy': 7.795453, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:22,811\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.077078536, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.015818996, 'entropy': 7.795156, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:25,385\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.07819046, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.015925806, 'entropy': 7.794748, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:27,994\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.07869928, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.015891125, 'entropy': 7.79346, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:30,577\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.07895069, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.015677687, 'entropy': 7.790943, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:33,169\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.078817904, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.016271222, 'entropy': 7.7937346, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:35,729\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 456133300.0, 'policy_loss': -0.080438875, 'vf_loss': 456133300.0, 'vf_explained_var': 0.0, 'kl': 0.016187306, 'entropy': 7.7947655, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:35,848\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 35751}\n",
            "2020-03-19 08:32:35,899\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:32:35,900\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,901\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,903\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,904\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,904\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,906\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,906\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,907\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,908\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,909\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,910\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,911\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,911\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,912\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,913\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,914\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:32:35,917\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-32-35\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 51\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78603.155\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.794765472412109\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.016187306493520737\n",
            "      policy_loss: -0.08043887466192245\n",
            "      total_loss: 456133312.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 456133312.0\n",
            "  load_time_ms: 16.92\n",
            "  num_steps_sampled: 35751\n",
            "  num_steps_trained: 32640\n",
            "  sample_time_ms: 23329.181\n",
            "  update_time_ms: 22.457\n",
            "iterations_since_restore: 22\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.618018018018\n",
            "  ram_util_percent: 19.741441441441427\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 21593.090909090908\n",
            "  policy_1: -9237.772727272728\n",
            "  policy_2: -10251.59090909091\n",
            "  policy_3: -2103.7272727272725\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.44934079653784\n",
            "  mean_inference_ms: 7.8130467478099925\n",
            "  mean_processing_ms: 2.649417299943397\n",
            "time_since_restore: 2206.184758901596\n",
            "time_this_iter_s: 77.82573795318604\n",
            "time_total_s: 5266.611136198044\n",
            "timestamp: 1584606755\n",
            "timesteps_since_restore: 15422\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 35751\n",
            "training_iteration: 51\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_51/checkpoint-51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:32:38,578\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654880.0, 'policy_loss': 0.0025431155, 'vf_loss': 267654880.0, 'vf_explained_var': 0.0, 'kl': 0.010113177, 'entropy': 7.7882957, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:41,175\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.0036355257, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.006930546, 'entropy': 7.7720094, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:43,886\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.0065078186, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.004380462, 'entropy': 7.758085, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:46,493\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.009588727, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.0037879043, 'entropy': 7.7532806, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:49,107\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.011871427, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.0047006244, 'entropy': 7.757525, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:51,712\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.015464418, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.0052898964, 'entropy': 7.7640014, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:54,321\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.018343532, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.006620591, 'entropy': 7.775116, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:56,985\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.021359289, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.007823962, 'entropy': 7.786251, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:32:59,655\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.02446573, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.0089459745, 'entropy': 7.793171, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:02,268\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.028141594, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.008399014, 'entropy': 7.7901983, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:04,863\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654880.0, 'policy_loss': -0.027012855, 'vf_loss': 267654880.0, 'vf_explained_var': 0.0, 'kl': 0.0065929415, 'entropy': 7.782073, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:07,487\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.027964186, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.0066753007, 'entropy': 7.7822623, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:10,095\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.030017087, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.007272354, 'entropy': 7.7890654, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:12,670\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.03344411, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.009562842, 'entropy': 7.8034544, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:15,297\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.035602592, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.010541914, 'entropy': 7.8095093, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:17,899\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.03805583, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.01017152, 'entropy': 7.8075905, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:20,506\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.038521945, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.009310236, 'entropy': 7.8012247, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:23,102\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654880.0, 'policy_loss': -0.04009304, 'vf_loss': 267654880.0, 'vf_explained_var': 0.0, 'kl': 0.009256506, 'entropy': 7.801543, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:25,687\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.040157717, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.009249156, 'entropy': 7.800855, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:28,219\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.042916916, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.009850455, 'entropy': 7.802395, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:30,821\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.044239298, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.0096501475, 'entropy': 7.79975, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:33,394\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654880.0, 'policy_loss': -0.043244123, 'vf_loss': 267654880.0, 'vf_explained_var': 0.0, 'kl': 0.008789371, 'entropy': 7.7967424, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:35,998\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.045449335, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.009261866, 'entropy': 7.7985916, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:38,646\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.04792627, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.010111099, 'entropy': 7.802401, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:41,261\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.047716696, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.0099025415, 'entropy': 7.802207, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:43,877\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.048609853, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.009916644, 'entropy': 7.8016396, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:46,498\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.049610786, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.010216388, 'entropy': 7.802003, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:49,150\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.049766578, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.010156499, 'entropy': 7.801085, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:51,781\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.051941246, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.009771876, 'entropy': 7.7990427, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:54,400\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 267654860.0, 'policy_loss': -0.053031407, 'vf_loss': 267654860.0, 'vf_explained_var': 0.0, 'kl': 0.010191596, 'entropy': 7.799254, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:54,445\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 36452}\n",
            "2020-03-19 08:33:54,485\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:33:54,489\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.002, max=11.0, mean=1.594),\n",
            "              np.ndarray((701,), dtype=float32, min=-15073.0, max=18582.0, mean=-5.886),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3872.0, max=3540.0, mean=-6.248),\n",
            "              np.ndarray((701,), dtype=float32, min=-16.576, max=-6.288, mean=-7.702),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.002, max=11.0, mean=1.597),\n",
            "              np.ndarray((701,), dtype=float32, min=-4.98, max=2.154, mean=-0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.991, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3872.0, max=3540.0, mean=-6.248),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.002, max=11.0, mean=1.594),\n",
            "              np.ndarray((701,), dtype=float32, min=-15073.0, max=18582.0, mean=-5.886),\n",
            "              np.ndarray((701,), dtype=float32, min=-34912.738, max=15630.757, mean=372.455),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:33:54,492\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:33:54,497\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-33-54\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 52\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78735.244\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.799253940582275\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.010191596113145351\n",
            "      policy_loss: -0.05303140729665756\n",
            "      total_loss: 267654864.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 267654864.0\n",
            "  load_time_ms: 16.97\n",
            "  num_steps_sampled: 36452\n",
            "  num_steps_trained: 33280\n",
            "  sample_time_ms: 15623.65\n",
            "  update_time_ms: 22.861\n",
            "iterations_since_restore: 23\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.65357142857144\n",
            "  ram_util_percent: 19.811607142857145\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 19587.956521739132\n",
            "  policy_1: -8581.130434782608\n",
            "  policy_2: -9585.391304347826\n",
            "  policy_3: -1421.4347826086957\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.44502001101804\n",
            "  mean_inference_ms: 7.805104537823184\n",
            "  mean_processing_ms: 2.649672619401067\n",
            "time_since_restore: 2284.741381883621\n",
            "time_this_iter_s: 78.55662298202515\n",
            "time_total_s: 5345.167759180069\n",
            "timestamp: 1584606834\n",
            "timesteps_since_restore: 16123\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 36452\n",
            "training_iteration: 52\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:33:57,190\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427024.0, 'policy_loss': 0.004306498, 'vf_loss': 51427024.0, 'vf_explained_var': 0.0, 'kl': 0.0072600865, 'entropy': 7.789557, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:33:59,837\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.0053658546, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.0037237878, 'entropy': 7.7592344, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:02,425\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.008382696, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.0026941982, 'entropy': 7.7444153, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:05,027\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427024.0, 'policy_loss': -0.013662957, 'vf_loss': 51427024.0, 'vf_explained_var': 0.0, 'kl': 0.0033288859, 'entropy': 7.7483, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:07,603\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.017505562, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.004577647, 'entropy': 7.758457, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:10,206\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.021334145, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.005466906, 'entropy': 7.764894, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:12,805\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.02415965, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.0052989554, 'entropy': 7.7642426, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:15,411\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427024.0, 'policy_loss': -0.026072562, 'vf_loss': 51427024.0, 'vf_explained_var': 0.0, 'kl': 0.0054543717, 'entropy': 7.766267, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:18,004\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.029705536, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.0063427845, 'entropy': 7.7693915, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:20,633\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.03297569, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.008178813, 'entropy': 7.778624, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:23,192\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.035607103, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.010182826, 'entropy': 7.7868323, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:25,759\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.037845038, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.009576877, 'entropy': 7.7821517, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:28,320\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.03877568, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.008716258, 'entropy': 7.7759047, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:30,902\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.041154593, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.009330835, 'entropy': 7.776468, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:33,489\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.042918902, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.01017313, 'entropy': 7.779414, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:36,088\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.044287447, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.010083027, 'entropy': 7.7786803, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:38,687\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427024.0, 'policy_loss': -0.04508109, 'vf_loss': 51427024.0, 'vf_explained_var': 0.0, 'kl': 0.010321924, 'entropy': 7.77979, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:41,284\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.046024073, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.010280697, 'entropy': 7.7793045, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:43,880\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.046779357, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.01033213, 'entropy': 7.779545, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:46,513\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.048608102, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.010957111, 'entropy': 7.780741, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:49,137\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.05027678, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.011117909, 'entropy': 7.781034, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:51,754\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427024.0, 'policy_loss': -0.05086126, 'vf_loss': 51427024.0, 'vf_explained_var': 0.0, 'kl': 0.010900776, 'entropy': 7.7797327, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:54,349\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.051226586, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.01089265, 'entropy': 7.7802467, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:57,009\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.05290828, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.01241787, 'entropy': 7.7847795, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:34:59,659\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.052928902, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.011934468, 'entropy': 7.78243, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:35:02,252\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427024.0, 'policy_loss': -0.05286042, 'vf_loss': 51427024.0, 'vf_explained_var': 0.0, 'kl': 0.011209829, 'entropy': 7.7790184, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:35:04,828\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.05357889, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.012528071, 'entropy': 7.7836595, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:35:07,439\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427024.0, 'policy_loss': -0.053498615, 'vf_loss': 51427024.0, 'vf_explained_var': 0.0, 'kl': 0.012159785, 'entropy': 7.7822275, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:35:10,045\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.05223479, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.011331615, 'entropy': 7.7803283, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:35:12,627\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 51427020.0, 'policy_loss': -0.053331096, 'vf_loss': 51427020.0, 'vf_explained_var': 0.0, 'kl': 0.011742925, 'entropy': 7.7818117, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:35:12,670\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 37153}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-35-12\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 53\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 78787.288\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.781811714172363\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.011742925271391869\n",
            "      policy_loss: -0.05333109572529793\n",
            "      total_loss: 51427020.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 51427020.0\n",
            "  load_time_ms: 17.278\n",
            "  num_steps_sampled: 37153\n",
            "  num_steps_trained: 33920\n",
            "  sample_time_ms: 15623.874\n",
            "  update_time_ms: 23.062\n",
            "iterations_since_restore: 24\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.72767857142857\n",
            "  ram_util_percent: 19.900000000000002\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 18599.875\n",
            "  policy_1: -8282.208333333334\n",
            "  policy_2: -8286.375\n",
            "  policy_3: -2031.2916666666667\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.44105929095822\n",
            "  mean_inference_ms: 7.797824178668608\n",
            "  mean_processing_ms: 2.649906662237266\n",
            "time_since_restore: 2362.931289434433\n",
            "time_this_iter_s: 78.18990755081177\n",
            "time_total_s: 5423.357666730881\n",
            "timestamp: 1584606912\n",
            "timesteps_since_restore: 16824\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 37153\n",
            "training_iteration: 53\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:36:30,321\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:36:30,322\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,328\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,330\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,331\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,331\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,332\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,333\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,334\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,335\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,336\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,336\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,337\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,338\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,339\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,340\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,341\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:36:30,345\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n",
            "2020-03-19 08:36:32,996\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.0073869065, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.007293141, 'entropy': 7.7846804, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:36:35,628\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.020468112, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.0074864244, 'entropy': 7.790624, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:36:38,277\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.030719101, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.008365416, 'entropy': 7.8073225, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:36:40,899\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.038005315, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.010649173, 'entropy': 7.8201647, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:36:43,525\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.04604789, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.014713511, 'entropy': 7.839888, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:36:46,158\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.050812982, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.014242411, 'entropy': 7.83556, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:36:48,803\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.055098284, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.013674736, 'entropy': 7.8345704, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:36:51,505\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.059256215, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.015067582, 'entropy': 7.840692, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:36:54,228\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884382.5, 'policy_loss': -0.06249982, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.014510711, 'entropy': 7.836707, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:36:56,950\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884382.5, 'policy_loss': -0.066067114, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.0152503345, 'entropy': 7.8393974, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:36:59,679\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.07134018, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.016405847, 'entropy': 7.843255, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:02,395\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.072756566, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.015357012, 'entropy': 7.838418, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:05,067\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.07537399, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.015380563, 'entropy': 7.838192, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:07,713\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884382.5, 'policy_loss': -0.07611606, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.015319507, 'entropy': 7.8383765, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:10,454\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.07912477, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.015979873, 'entropy': 7.8406916, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:13,193\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.081547275, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.01578815, 'entropy': 7.8389306, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:15,881\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.08264953, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.015942367, 'entropy': 7.8391676, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:18,571\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884382.5, 'policy_loss': -0.08423026, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.016944066, 'entropy': 7.841217, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:21,302\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884382.5, 'policy_loss': -0.08589658, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.017668605, 'entropy': 7.8450775, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:24,012\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884382.5, 'policy_loss': -0.08706932, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.017617743, 'entropy': 7.846179, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:26,766\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.0889498, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.01699351, 'entropy': 7.842575, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:29,425\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884382.5, 'policy_loss': -0.09036611, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.0179482, 'entropy': 7.84765, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:32,155\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.092429414, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.01860908, 'entropy': 7.8507447, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:34,856\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.08830234, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.015800085, 'entropy': 7.836482, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:37,571\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884382.5, 'policy_loss': -0.09126179, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.018249627, 'entropy': 7.8463492, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:40,275\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.09364932, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.019604504, 'entropy': 7.8497114, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:42,956\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.09519847, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.019512672, 'entropy': 7.847135, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:45,686\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.096394956, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.020048315, 'entropy': 7.849762, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:48,444\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.097279616, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.019309012, 'entropy': 7.846631, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:51,160\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 5884383.0, 'policy_loss': -0.098535836, 'vf_loss': 5884383.0, 'vf_explained_var': 0.0, 'kl': 0.018855652, 'entropy': 7.842481, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:51,267\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 37854}\n",
            "2020-03-19 08:37:51,309\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:37:51,314\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.004, max=11.0, mean=1.596),\n",
            "              np.ndarray((701,), dtype=float32, min=-7360.0, max=7360.0, mean=25.591),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2837.0, max=3528.0, mean=-3.301),\n",
            "              np.ndarray((701,), dtype=float32, min=-12.256, max=-6.298, mean=-7.649),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.004, max=11.0, mean=1.598),\n",
            "              np.ndarray((701,), dtype=float32, min=-1.265, max=4.235, mean=0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.982, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-2837.0, max=3528.0, mean=-3.301),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.004, max=11.0, mean=1.596),\n",
            "              np.ndarray((701,), dtype=float32, min=-7360.0, max=7360.0, mean=25.591),\n",
            "              np.ndarray((701,), dtype=float32, min=-2493.345, max=19127.658, mean=2479.351),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:37:51,316\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:37:51,318\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-37-51\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 54\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 79166.109\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.8424811363220215\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.01885565184056759\n",
            "      policy_loss: -0.09853583574295044\n",
            "      total_loss: 5884383.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 5884383.0\n",
            "  load_time_ms: 17.189\n",
            "  num_steps_sampled: 37854\n",
            "  num_steps_trained: 34560\n",
            "  sample_time_ms: 23384.579\n",
            "  update_time_ms: 22.846\n",
            "iterations_since_restore: 25\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 77.71858407079645\n",
            "  ram_util_percent: 20.329646017699115\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 18335.16\n",
            "  policy_1: -9153.68\n",
            "  policy_2: -7121.04\n",
            "  policy_3: -2060.44\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.43354641298042\n",
            "  mean_inference_ms: 7.789648965379862\n",
            "  mean_processing_ms: 2.6500659610826767\n",
            "time_since_restore: 2521.4310097694397\n",
            "time_this_iter_s: 158.4997203350067\n",
            "time_total_s: 5581.857387065887\n",
            "timestamp: 1584607071\n",
            "timesteps_since_restore: 17525\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 37854\n",
            "training_iteration: 54\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_54/checkpoint-54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:37:54,037\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': 0.0061854436, 'vf_loss': 21763476.0, 'vf_explained_var': 0.0, 'kl': 0.011442553, 'entropy': 7.811034, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:56,746\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': 0.00039393306, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.004990487, 'entropy': 7.7786584, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:37:59,585\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.0022594752, 'vf_loss': 21763476.0, 'vf_explained_var': 0.0, 'kl': 0.0027740828, 'entropy': 7.7564406, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:02,232\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.0046462803, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.002520177, 'entropy': 7.753447, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:04,920\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.007241635, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.002419561, 'entropy': 7.751699, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:07,620\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.010582375, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.00291632, 'entropy': 7.760292, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:10,372\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.014391065, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.0037081416, 'entropy': 7.7690687, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:13,064\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.018003054, 'vf_loss': 21763476.0, 'vf_explained_var': 0.0, 'kl': 0.005194078, 'entropy': 7.7788787, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:15,767\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763474.0, 'policy_loss': -0.021991143, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.0062907385, 'entropy': 7.785263, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:18,495\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.024951672, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.0068057254, 'entropy': 7.7890816, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:21,182\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.026645591, 'vf_loss': 21763476.0, 'vf_explained_var': 0.0, 'kl': 0.00740602, 'entropy': 7.792328, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:23,908\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.02878623, 'vf_loss': 21763476.0, 'vf_explained_var': 0.0, 'kl': 0.008162824, 'entropy': 7.795582, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:26,614\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.030669969, 'vf_loss': 21763474.0, 'vf_explained_var': 0.0, 'kl': 0.008841829, 'entropy': 7.7987585, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:29,284\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.031556614, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.008676849, 'entropy': 7.799103, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:32,003\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.032835282, 'vf_loss': 21763474.0, 'vf_explained_var': 0.0, 'kl': 0.009022525, 'entropy': 7.7976213, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:34,725\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.034683872, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.0094725955, 'entropy': 7.797104, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:37,443\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.036313705, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.010749981, 'entropy': 7.8025384, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:40,131\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.039594688, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.012367398, 'entropy': 7.808563, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:42,890\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.040301688, 'vf_loss': 21763474.0, 'vf_explained_var': 0.0, 'kl': 0.013670879, 'entropy': 7.812438, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:45,625\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.039963204, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.012261359, 'entropy': 7.807873, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:48,345\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.04179656, 'vf_loss': 21763476.0, 'vf_explained_var': 0.0, 'kl': 0.013197087, 'entropy': 7.8100867, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:51,099\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.04222346, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.0134596005, 'entropy': 7.8125963, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:53,781\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.043700714, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.01309963, 'entropy': 7.812228, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:56,479\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.044815626, 'vf_loss': 21763474.0, 'vf_explained_var': 0.0, 'kl': 0.013716346, 'entropy': 7.8137817, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:38:59,273\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.046615954, 'vf_loss': 21763476.0, 'vf_explained_var': 0.0, 'kl': 0.014022751, 'entropy': 7.8129387, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:02,072\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.047785264, 'vf_loss': 21763476.0, 'vf_explained_var': 0.0, 'kl': 0.013417356, 'entropy': 7.81035, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:04,843\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.049139004, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.013981124, 'entropy': 7.813787, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:07,641\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.04997543, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.014386887, 'entropy': 7.815042, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:10,310\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.050460856, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.013826621, 'entropy': 7.8149514, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:13,005\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 21763476.0, 'policy_loss': -0.05105217, 'vf_loss': 21763472.0, 'vf_explained_var': 0.0, 'kl': 0.014014827, 'entropy': 7.816382, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:13,048\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 38555}\n",
            "2020-03-19 08:39:13,094\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:39:13,095\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,096\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,096\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,097\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,098\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,099\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,100\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,101\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,102\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,102\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,103\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,104\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,105\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,106\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,106\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,107\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:39:13,110\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-39-13\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 55\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 79624.496\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.816381931304932\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.014014827087521553\n",
            "      policy_loss: -0.05105217173695564\n",
            "      total_loss: 21763476.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 21763472.0\n",
            "  load_time_ms: 16.876\n",
            "  num_steps_sampled: 38555\n",
            "  num_steps_trained: 35200\n",
            "  sample_time_ms: 23384.63\n",
            "  update_time_ms: 23.342\n",
            "iterations_since_restore: 26\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.77777777777776\n",
            "  ram_util_percent: 20.5\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 18319.80769230769\n",
            "  policy_1: -8910.846153846154\n",
            "  policy_2: -6630.576923076923\n",
            "  policy_3: -2778.3846153846152\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.42661144869322\n",
            "  mean_inference_ms: 7.782102614651789\n",
            "  mean_processing_ms: 2.650213006170748\n",
            "time_since_restore: 2603.176183462143\n",
            "time_this_iter_s: 81.74517369270325\n",
            "time_total_s: 5663.602560758591\n",
            "timestamp: 1584607153\n",
            "timesteps_since_restore: 18226\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 38555\n",
            "training_iteration: 55\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:39:15,894\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': 0.029746776, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.010115964, 'entropy': 7.7992477, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:18,612\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': 0.018841984, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.0073009073, 'entropy': 7.7773185, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:21,338\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': 0.012919143, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.006099367, 'entropy': 7.7673197, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:24,064\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': 0.008238589, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.006546198, 'entropy': 7.766797, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:26,806\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': 0.0018786117, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.0078240065, 'entropy': 7.7678437, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:29,569\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478038.0, 'policy_loss': -0.0029933392, 'vf_loss': 28478038.0, 'vf_explained_var': 0.0, 'kl': 0.009388161, 'entropy': 7.7694345, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:32,304\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.005641438, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.010572964, 'entropy': 7.770471, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:35,056\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.008614423, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.009813767, 'entropy': 7.768199, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:37,805\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.011878312, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.0101887, 'entropy': 7.769039, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:40,547\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.016030505, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.011264827, 'entropy': 7.770976, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:43,280\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.01982545, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.011769203, 'entropy': 7.772873, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:46,098\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.02178763, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.0103179915, 'entropy': 7.7689867, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:48,853\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.02410814, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.010406437, 'entropy': 7.767253, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:51,643\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.028255891, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.011364353, 'entropy': 7.7691016, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:54,390\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478038.0, 'policy_loss': -0.028391382, 'vf_loss': 28478038.0, 'vf_explained_var': 0.0, 'kl': 0.010666679, 'entropy': 7.767644, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:57,153\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.028504461, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.010863366, 'entropy': 7.7680564, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:39:59,844\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.031836625, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.0119138975, 'entropy': 7.7701683, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:02,529\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478038.0, 'policy_loss': -0.033420336, 'vf_loss': 28478038.0, 'vf_explained_var': 0.0, 'kl': 0.012105095, 'entropy': 7.770204, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:05,280\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478038.0, 'policy_loss': -0.034224074, 'vf_loss': 28478038.0, 'vf_explained_var': 0.0, 'kl': 0.0125025455, 'entropy': 7.7695665, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:07,960\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.03520058, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.012249691, 'entropy': 7.769066, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:10,641\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478038.0, 'policy_loss': -0.035361193, 'vf_loss': 28478038.0, 'vf_explained_var': 0.0, 'kl': 0.012653919, 'entropy': 7.76901, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:13,346\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.036348898, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.013456637, 'entropy': 7.7706313, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:16,128\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.036762625, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.013287301, 'entropy': 7.770851, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:18,831\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.03868889, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.013554374, 'entropy': 7.7703505, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:21,546\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.040812112, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.014499652, 'entropy': 7.7713265, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:24,264\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478038.0, 'policy_loss': -0.041198086, 'vf_loss': 28478038.0, 'vf_explained_var': 0.0, 'kl': 0.01403981, 'entropy': 7.769941, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:26,988\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.042276014, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.013861385, 'entropy': 7.7688723, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:29,736\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.043267053, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.014135778, 'entropy': 7.769554, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:32,479\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478042.0, 'policy_loss': -0.042425577, 'vf_loss': 28478042.0, 'vf_explained_var': 0.0, 'kl': 0.014555822, 'entropy': 7.7700844, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:35,248\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 28478038.0, 'policy_loss': -0.040953007, 'vf_loss': 28478038.0, 'vf_explained_var': 0.0, 'kl': 0.013120661, 'entropy': 7.766786, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:35,294\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 39256}\n",
            "2020-03-19 08:40:35,333\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:40:35,340\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-3.482, max=11.0, mean=1.634),\n",
            "              np.ndarray((701,), dtype=float32, min=-8192.0, max=9216.0, mean=7.068),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3443.0, max=2958.0, mean=-21.242),\n",
            "              np.ndarray((701,), dtype=float32, min=-13.321, max=-6.29, mean=-7.717),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.482, max=11.0, mean=1.636),\n",
            "              np.ndarray((701,), dtype=float32, min=-7.605, max=3.812, mean=0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.987, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3443.0, max=2958.0, mean=-21.242),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-3.482, max=11.0, mean=1.634),\n",
            "              np.ndarray((701,), dtype=float32, min=-8192.0, max=9216.0, mean=7.068),\n",
            "              np.ndarray((701,), dtype=float32, min=-6675.796, max=4204.459, mean=571.529),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:40:35,341\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:40:35,343\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-40-35\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 56\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 79528.914\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.766786098480225\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.013120660558342934\n",
            "      policy_loss: -0.040953006595373154\n",
            "      total_loss: 28478038.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 28478038.0\n",
            "  load_time_ms: 14.431\n",
            "  num_steps_sampled: 39256\n",
            "  num_steps_trained: 35840\n",
            "  sample_time_ms: 15389.437\n",
            "  update_time_ms: 23.297\n",
            "iterations_since_restore: 27\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.81452991452991\n",
            "  ram_util_percent: 20.599999999999994\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 18049.59259259259\n",
            "  policy_1: -8996.962962962964\n",
            "  policy_2: -6410.074074074074\n",
            "  policy_3: -2642.5555555555557\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.42019018546434\n",
            "  mean_inference_ms: 7.775115252866537\n",
            "  mean_processing_ms: 2.6503491590300734\n",
            "time_since_restore: 2685.3833363056183\n",
            "time_this_iter_s: 82.20715284347534\n",
            "time_total_s: 5745.809713602066\n",
            "timestamp: 1584607235\n",
            "timesteps_since_restore: 18927\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 39256\n",
            "training_iteration: 56\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:40:38,040\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.9, 'policy_loss': 0.002398199, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.008823524, 'entropy': 7.758541, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:40,715\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.008708214, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0035484496, 'entropy': 7.7364655, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:43,434\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.015359233, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0027115964, 'entropy': 7.7265344, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:46,091\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.9, 'policy_loss': -0.020065557, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.002796717, 'entropy': 7.7261457, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:48,746\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.024303475, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0032930435, 'entropy': 7.730198, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:51,388\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.025069345, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0035761178, 'entropy': 7.732028, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:54,013\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.9, 'policy_loss': -0.029798442, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0042202272, 'entropy': 7.735521, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:56,677\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.031794697, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.005127959, 'entropy': 7.7387733, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:40:59,389\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.035631157, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0061773723, 'entropy': 7.742543, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:02,050\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.03772781, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0068822517, 'entropy': 7.7439704, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:04,727\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.039587546, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.005768289, 'entropy': 7.7384796, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:07,384\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.041200425, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0056430614, 'entropy': 7.738495, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:10,023\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.04397618, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0065276558, 'entropy': 7.7410607, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:12,698\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.046030343, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0074223145, 'entropy': 7.7433205, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:15,349\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.04766334, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0073690875, 'entropy': 7.7431116, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:17,972\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.050027847, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.008376585, 'entropy': 7.7467566, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:20,585\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.050860096, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.008879392, 'entropy': 7.7482405, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:23,247\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.050891787, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.008678883, 'entropy': 7.748046, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:25,849\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.05016302, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.008367893, 'entropy': 7.7458467, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:28,494\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.052910846, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.009494305, 'entropy': 7.7489557, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:31,247\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.054114647, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.009622989, 'entropy': 7.7494926, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:34,044\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.05428023, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.010487317, 'entropy': 7.7518487, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:36,709\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.055349875, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.010646026, 'entropy': 7.7526293, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:39,392\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.9, 'policy_loss': -0.057012595, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.0109605, 'entropy': 7.753198, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:42,087\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.05856838, 'vf_loss': 1244473.9, 'vf_explained_var': 0.0, 'kl': 0.0117601445, 'entropy': 7.7551413, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:44,816\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.058814358, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.010630989, 'entropy': 7.7519655, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:47,511\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.9, 'policy_loss': -0.059057593, 'vf_loss': 1244473.9, 'vf_explained_var': 0.0, 'kl': 0.010959253, 'entropy': 7.752425, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:50,198\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.06109322, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.01147828, 'entropy': 7.7536287, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:52,915\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.061871935, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.011469069, 'entropy': 7.7533827, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:55,610\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 1244473.8, 'policy_loss': -0.0619845, 'vf_loss': 1244473.8, 'vf_explained_var': 0.0, 'kl': 0.012456421, 'entropy': 7.755211, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:41:55,718\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 39957}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-41-55\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 57\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 79334.06\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.755210876464844\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.012456420809030533\n",
            "      policy_loss: -0.06198450177907944\n",
            "      total_loss: 1244473.75\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 1244473.75\n",
            "  load_time_ms: 14.561\n",
            "  num_steps_sampled: 39957\n",
            "  num_steps_trained: 36480\n",
            "  sample_time_ms: 15389.408\n",
            "  update_time_ms: 23.086\n",
            "iterations_since_restore: 28\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.68434782608695\n",
            "  ram_util_percent: 20.699999999999992\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 17613.535714285714\n",
            "  policy_1: -8399.392857142857\n",
            "  policy_2: -5752.678571428572\n",
            "  policy_3: -3461.464285714286\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.41422758389466\n",
            "  mean_inference_ms: 7.76862698835166\n",
            "  mean_processing_ms: 2.650475586685161\n",
            "time_since_restore: 2765.7066168785095\n",
            "time_this_iter_s: 80.32328057289124\n",
            "time_total_s: 5826.132994174957\n",
            "timestamp: 1584607315\n",
            "timesteps_since_restore: 19628\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 39957\n",
            "training_iteration: 57\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_57/checkpoint-57\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:43:15,361\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:43:15,362\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,363\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,364\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,365\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,366\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,367\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,368\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/kernel:0' shape=(256, 23) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,369\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/mu/bias:0' shape=(23,) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,370\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,371\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc2/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,372\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,373\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/fc3/bias:0' shape=(512,) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,373\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/kernel:0' shape=(768, 1024) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,374\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/rnn/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,375\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/kernel:0' shape=(256, 1) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,376\tINFO tf_policy.py:395 -- Optimizing variable <tf.Variable 'policy_0/default_model/value_function/mu/bias:0' shape=(1,) dtype=float32_ref>\n",
            "2020-03-19 08:43:15,379\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n",
            "2020-03-19 08:43:18,114\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': 0.0049203993, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.003140125, 'entropy': 7.745295, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:20,859\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.00410579, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0028046875, 'entropy': 7.740751, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:23,539\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.0073646023, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0027969128, 'entropy': 7.7383623, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:26,286\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.011655432, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0030820852, 'entropy': 7.737287, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:29,006\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.014925653, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0032833517, 'entropy': 7.7385073, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:31,795\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.017242678, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0035846978, 'entropy': 7.740674, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:34,485\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.019841855, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.004149857, 'entropy': 7.7431765, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:37,199\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.021590896, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.004296567, 'entropy': 7.7442846, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:39,941\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.02365693, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0044471817, 'entropy': 7.7449293, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:42,692\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.025072208, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0046702283, 'entropy': 7.745847, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:45,441\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.026365895, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.004803828, 'entropy': 7.746759, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:48,153\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.027883908, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.005077354, 'entropy': 7.7484236, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:50,877\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.028628081, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0052388925, 'entropy': 7.749551, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:53,626\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.02999489, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.005680547, 'entropy': 7.7511992, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:56,382\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.030907566, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0057787728, 'entropy': 7.751503, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:43:59,150\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.031290177, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0057382705, 'entropy': 7.751889, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:01,865\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.03172677, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0060481853, 'entropy': 7.7531843, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:04,593\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.03247031, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.006093324, 'entropy': 7.752865, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:07,288\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.033473335, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0063822516, 'entropy': 7.753732, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:10,002\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.0342465, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.0062956973, 'entropy': 7.7534685, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:12,766\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.034783605, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.006495812, 'entropy': 7.754149, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:15,533\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.03596661, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.006812078, 'entropy': 7.7549124, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:18,215\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.03682332, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.006988409, 'entropy': 7.7555456, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:20,878\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.037668962, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.007258805, 'entropy': 7.75627, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:23,579\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.0387384, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.007495988, 'entropy': 7.757071, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:26,275\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.038905893, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.007346084, 'entropy': 7.756686, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:28,922\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.039899416, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.00774604, 'entropy': 7.758094, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:31,549\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.04036396, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.007914516, 'entropy': 7.75846, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:34,191\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.041044712, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.008114392, 'entropy': 7.759366, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:36,818\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 35709320.0, 'policy_loss': -0.04176145, 'vf_loss': 35709320.0, 'vf_explained_var': 0.0, 'kl': 0.008400293, 'entropy': 7.759871, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:36,869\tDEBUG trainer.py:478 -- updated global vars: {'timestep': 40658}\n",
            "2020-03-19 08:44:36,913\tINFO multi_gpu_optimizer.py:143 -- Collected more training samples than expected (actual=701, train_batch_size=128). This may be because you have many workers or long episodes in 'complete_episodes' batch mode.\n",
            "2020-03-19 08:44:36,918\tINFO multi_gpu_impl.py:142 -- Training on concatenated sample batches:\n",
            "\n",
            "{ 'inputs': [ np.ndarray((701, 5), dtype=float32, min=-2.949, max=11.0, mean=1.605),\n",
            "              np.ndarray((701,), dtype=float32, min=-19346.0, max=19159.0, mean=20.498),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3222.0, max=3064.0, mean=5.165),\n",
            "              np.ndarray((701,), dtype=float32, min=-14.191, max=-6.28, mean=-7.693),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-2.949, max=11.0, mean=1.607),\n",
            "              np.ndarray((701,), dtype=float32, min=-4.749, max=2.432, mean=0.0),\n",
            "              np.ndarray((701, 23), dtype=float32, min=0.0, max=0.995, mean=0.043),\n",
            "              np.ndarray((701, 4, 10), dtype=float32, min=-3222.0, max=3064.0, mean=5.165),\n",
            "              np.ndarray((701, 5), dtype=float32, min=-2.949, max=11.0, mean=1.605),\n",
            "              np.ndarray((701,), dtype=float32, min=-19346.0, max=19159.0, mean=20.498),\n",
            "              np.ndarray((701,), dtype=float32, min=-18964.598, max=12345.44, mean=1742.851),\n",
            "              np.ndarray((701,), dtype=float32, min=1.0, max=1.0, mean=1.0)],\n",
            "  'placeholders': [ <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/action_logp:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/actions:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/advantages:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/behaviour_logits:0' shape=(?, 23) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/observation:0' shape=(?, 4, 10) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_action:0' shape=(?, 5) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/prev_reward:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/value_targets:0' shape=(?,) dtype=float32>,\n",
            "                    <tf.Tensor 'policy_0/vf_preds:0' shape=(?,) dtype=float32>],\n",
            "  'state_inputs': []}\n",
            "\n",
            "2020-03-19 08:44:36,920\tINFO multi_gpu_impl.py:187 -- Divided 701 rollout sequences, each of length 1, among 1 devices.\n",
            "2020-03-19 08:44:36,924\tDEBUG multi_gpu_optimizer.py:194 -- == sgd epochs for policy_0 ==\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-44-36\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 58\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 79462.244\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.759871006011963\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.008400293067097664\n",
            "      policy_loss: -0.041761450469493866\n",
            "      total_loss: 35709320.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 35709320.0\n",
            "  load_time_ms: 14.16\n",
            "  num_steps_sampled: 40658\n",
            "  num_steps_trained: 37120\n",
            "  sample_time_ms: 23349.068\n",
            "  update_time_ms: 23.13\n",
            "iterations_since_restore: 29\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 77.86260869565218\n",
            "  ram_util_percent: 20.86739130434783\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 16933.96551724138\n",
            "  policy_1: -8126.482758620689\n",
            "  policy_2: -5164.793103448276\n",
            "  policy_3: -3642.689655172414\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.41683971524984\n",
            "  mean_inference_ms: 7.762932665354971\n",
            "  mean_processing_ms: 2.6507953184688406\n",
            "time_since_restore: 2926.8150877952576\n",
            "time_this_iter_s: 161.10847091674805\n",
            "time_total_s: 5987.241465091705\n",
            "timestamp: 1584607476\n",
            "timesteps_since_restore: 20329\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 40658\n",
            "training_iteration: 58\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-19 08:44:39,538\tDEBUG multi_gpu_optimizer.py:205 -- 0 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.010612282, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.009538524, 'entropy': 7.758176, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:42,217\tDEBUG multi_gpu_optimizer.py:205 -- 1 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.019643921, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.00422633, 'entropy': 7.740348, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:44,876\tDEBUG multi_gpu_optimizer.py:205 -- 2 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.026252622, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.0025179698, 'entropy': 7.7299843, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:47,570\tDEBUG multi_gpu_optimizer.py:205 -- 3 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.029002002, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.0024498855, 'entropy': 7.728666, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:50,236\tDEBUG multi_gpu_optimizer.py:205 -- 4 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.034730382, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.0031638215, 'entropy': 7.7323885, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:52,910\tDEBUG multi_gpu_optimizer.py:205 -- 5 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.03996908, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.004384385, 'entropy': 7.738408, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:55,593\tDEBUG multi_gpu_optimizer.py:205 -- 6 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.04543611, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.0056943446, 'entropy': 7.744027, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:44:58,264\tDEBUG multi_gpu_optimizer.py:205 -- 7 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.049624994, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.006699682, 'entropy': 7.7473345, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:00,932\tDEBUG multi_gpu_optimizer.py:205 -- 8 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.052606024, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.007235959, 'entropy': 7.748455, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:03,589\tDEBUG multi_gpu_optimizer.py:205 -- 9 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.054393746, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.007091155, 'entropy': 7.748683, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:06,249\tDEBUG multi_gpu_optimizer.py:205 -- 10 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.05744683, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.00729146, 'entropy': 7.7489653, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:08,921\tDEBUG multi_gpu_optimizer.py:205 -- 11 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.05859395, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.007660107, 'entropy': 7.749032, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:11,562\tDEBUG multi_gpu_optimizer.py:205 -- 12 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.06066854, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.0074757943, 'entropy': 7.7482986, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:14,197\tDEBUG multi_gpu_optimizer.py:205 -- 13 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.062327016, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.007787857, 'entropy': 7.749574, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:16,839\tDEBUG multi_gpu_optimizer.py:205 -- 14 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.06280322, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.007422164, 'entropy': 7.7487054, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:19,453\tDEBUG multi_gpu_optimizer.py:205 -- 15 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.062325727, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.006885264, 'entropy': 7.7472825, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:22,039\tDEBUG multi_gpu_optimizer.py:205 -- 16 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.0642398, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.008751513, 'entropy': 7.750918, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:24,659\tDEBUG multi_gpu_optimizer.py:205 -- 17 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.06563886, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.009106858, 'entropy': 7.7512255, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:27,264\tDEBUG multi_gpu_optimizer.py:205 -- 18 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.06644765, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.008748057, 'entropy': 7.749095, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:29,878\tDEBUG multi_gpu_optimizer.py:205 -- 19 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.066965155, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.008821686, 'entropy': 7.7501183, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:32,479\tDEBUG multi_gpu_optimizer.py:205 -- 20 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.06892019, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.009114093, 'entropy': 7.751197, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:35,092\tDEBUG multi_gpu_optimizer.py:205 -- 21 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.07023592, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.008905734, 'entropy': 7.750758, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:37,753\tDEBUG multi_gpu_optimizer.py:205 -- 22 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.07135609, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.009290295, 'entropy': 7.752008, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:40,343\tDEBUG multi_gpu_optimizer.py:205 -- 23 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.07192452, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.009738462, 'entropy': 7.753347, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:42,902\tDEBUG multi_gpu_optimizer.py:205 -- 24 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.07332314, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.009539802, 'entropy': 7.7520156, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:45,509\tDEBUG multi_gpu_optimizer.py:205 -- 25 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.07255242, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.00895517, 'entropy': 7.7503104, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:48,124\tDEBUG multi_gpu_optimizer.py:205 -- 26 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.07306068, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.009570899, 'entropy': 7.7524924, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:50,708\tDEBUG multi_gpu_optimizer.py:205 -- 27 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.07407172, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.00936424, 'entropy': 7.7516594, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:53,287\tDEBUG multi_gpu_optimizer.py:205 -- 28 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.07410787, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.00918066, 'entropy': 7.7508593, 'entropy_coeff': 0.0}\n",
            "2020-03-19 08:45:55,862\tDEBUG multi_gpu_optimizer.py:205 -- 29 {'cur_kl_coeff': 0.5062500238418579, 'cur_lr': 4.999999873689376e-05, 'total_loss': 20945772.0, 'policy_loss': -0.0750935, 'vf_loss': 20945772.0, 'vf_explained_var': 0.0, 'kl': 0.009774331, 'entropy': 7.752534, 'entropy_coeff': 0.0}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2020-03-19_08-45-55\n",
            "done: false\n",
            "episode_len_mean: 701.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 1\n",
            "episodes_total: 59\n",
            "experiment_id: b6d1c176f8974af2bfd45911d6888178\n",
            "hostname: 91380f02bba8\n",
            "info:\n",
            "  grad_time_ms: 79619.822\n",
            "  learner:\n",
            "    policy_0:\n",
            "      cur_kl_coeff: 0.5062500238418579\n",
            "      cur_lr: 4.999999873689376e-05\n",
            "      entropy: 7.752533912658691\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.009774331003427505\n",
            "      policy_loss: -0.07509350031614304\n",
            "      total_loss: 20945772.0\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 20945772.0\n",
            "  load_time_ms: 14.566\n",
            "  num_steps_sampled: 41359\n",
            "  num_steps_trained: 37760\n",
            "  sample_time_ms: 23349.058\n",
            "  update_time_ms: 22.844\n",
            "iterations_since_restore: 30\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 1\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 97.63893805309733\n",
            "  ram_util_percent: 20.900000000000002\n",
            "pid: 5591\n",
            "policy_reward_max:\n",
            "  policy_0: 128607.0\n",
            "  policy_1: 77936.0\n",
            "  policy_2: 67115.0\n",
            "  policy_3: 45700.0\n",
            "policy_reward_mean:\n",
            "  policy_0: 17006.6\n",
            "  policy_1: -9843.0\n",
            "  policy_2: -3464.8\n",
            "  policy_3: -3698.8\n",
            "policy_reward_min:\n",
            "  policy_0: -73523.0\n",
            "  policy_1: -110995.0\n",
            "  policy_2: -123323.0\n",
            "  policy_3: -88751.0\n",
            "sampler_perf:\n",
            "  mean_env_wait_ms: 101.41927770451466\n",
            "  mean_inference_ms: 7.757617963891393\n",
            "  mean_processing_ms: 2.651093734800275\n",
            "time_since_restore: 3005.814729452133\n",
            "time_this_iter_s: 78.99964165687561\n",
            "time_total_s: 6066.241106748581\n",
            "timestamp: 1584607555\n",
            "timesteps_since_restore: 21030\n",
            "timesteps_this_iter: 701\n",
            "timesteps_total: 41359\n",
            "training_iteration: 59\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/chkpt/checkpoint_59/checkpoint-59\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}